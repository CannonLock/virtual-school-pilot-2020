{
    "docs": [
        {
            "location": "/",
            "text": "OSG Virtual School Pilot 2020\n\u00b6\n\n\nA new opportunity for a new time.\n\n\n\nThe \nOSG User School 2020\n has been canceled due to\nthe COVID-19 pandemic.  Some of the applicants who were selected for this year\u2019s User School\nhave chosen to try a new offering: The OSG Virtual School Pilot 2020.  Rather than simply translate\nthe User School for remote participation, the goal is to offer a new consulting and training event\nin which each participant works to get their research computing running within the two week period.\n\n\nThe Pilot will be held the weeks of July 13 and 20.  If successful, OSG may consider offering this\nkind of event again.\n\n\nMore information about the Pilot, including schedule and materials for participants, will be posted\nsoon!\n\n\nContact Us\n\u00b6\n\n\nThe OSG Virtual School Pilot is part of the\n\nOSG Outreach Area\n\u00a0\u2014 please visit that site to\nlearn about other OSG Outreach activities.\n\n\nIf you have any questions about the event, feel free to email us:\n\n\nuser-school@opensciencegrid.org\n\n\n   \n   OSGUserSchool",
            "title": "Virtual School Pilot 2020"
        },
        {
            "location": "/#osg-virtual-school-pilot-2020",
            "text": "A new opportunity for a new time.  The  OSG User School 2020  has been canceled due to\nthe COVID-19 pandemic.  Some of the applicants who were selected for this year\u2019s User School\nhave chosen to try a new offering: The OSG Virtual School Pilot 2020.  Rather than simply translate\nthe User School for remote participation, the goal is to offer a new consulting and training event\nin which each participant works to get their research computing running within the two week period.  The Pilot will be held the weeks of July 13 and 20.  If successful, OSG may consider offering this\nkind of event again.  More information about the Pilot, including schedule and materials for participants, will be posted\nsoon!",
            "title": "OSG Virtual School Pilot 2020"
        },
        {
            "location": "/#contact-us",
            "text": "The OSG Virtual School Pilot is part of the OSG Outreach Area \u00a0\u2014 please visit that site to\nlearn about other OSG Outreach activities.  If you have any questions about the event, feel free to email us:  user-school@opensciencegrid.org         OSGUserSchool",
            "title": "Contact Us"
        },
        {
            "location": "/schedule/",
            "text": "OSG-VSP Schedule\n\u00b6\n\n\nBelow is the schedule for the OSG Virtual School Pilot 2020.  We will probably\nmake small changes up to and even during the event.  However, the overall plan\nwill probably not change much.\n\n\nAll times are U.S. Central Daylight Time.\n\n\nNotes:\n\n\n\n\n\n\nEach lecture is offered twice on the same day.  Choose one time that is\n  convenient for you or, if you like, attend both.  Lectures will be held in the\n  Blackboard Collaborate video conference system; more details will be posted\n  and emailed soon.\n\n\n\n\n\n\nTry to attend at least one Work Time per day.  This is time for you to work on\n  exercises or getting your research code running.  During a Work Time, plan to\n  be on Slack; from there, you can chat with staff and participants and, if\n  needed, arrange individual or group audio/video meetings.\n\n\n\n\n\n\nConsultations are one-on-one meetings with your mentor.  You will work with\n  your mentor to schedule exact times.\n\n\n\n\n\n\nWeek 1: July 13\u201317\n\u00b6\n\n\n\n\nMonday (13th)\n\n\nLecture and discussion: Brief overview of the event and time to meet others (11\u00a0AM and 3\u00a0PM)\n\n\nConsultations with mentors all day (scheduled in advance)\n\n\n\n\n\n\nTuesday (14th)\n\n\nLecture: High Throughput Computing and Running Locally (11\u00a0AM and 3\u00a0PM)\n\n\nWork Time (1\u20133 PM\u00a0\u2014 just one scheduled this day)\n\n\n\n\n\n\nWednesday (15th)\n\n\nLecture: Running on OSG (11\u00a0AM and 3\u00a0PM)\n\n\nWork Time (9\u201311 AM and 1\u20133 PM)\n\n\n\n\n\n\nThursday (16th)\n\n\nLecture: Managing Software (11\u00a0AM and 3\u00a0PM)\n\n\nWork Time (9\u201311 AM and 1\u20133 PM)\n\n\n\n\n\n\nFriday (17th)\n\n\nWork Time (9 AM\u00a0\u2013 12 PM)\n\n\nNothing scheduled in afternoon! (But some staff will be available.)\n\n\n\n\n\n\n\n\nWeek 2: July 20\u201324\n\u00b6\n\n\n\n\nMonday (20th)\n\n\nWork Time (1\u20133 PM)\n\n\nNothing scheduled in morning! (But some staff will be available.)\n\n\n\n\n\n\nTuesday (21st)\n\n\nLecture: Managing Data (11\u00a0AM and 3\u00a0PM)\n\n\nWork Time (9\u201311 AM and 1\u20133 PM)\n\n\n\n\n\n\nWednesday (22nd)\n\n\nShowcase: Other researchers using HTC (11\u00a0AM; only once, sorry!)\n\n\nWork Time (9\u201311 AM and 1\u20133 PM)\n\n\n\n\n\n\nThursday (23rd)\n\n\nConsultations with mentors all day (scheduled in advance)\n\n\n\n\n\n\nFriday (17th)\n\n\nWrap-up: Lightning talks (optional!) and group discussion (11\u00a0AM to ?)\n\n\nConsultations with mentors all day (scheduled in advance)",
            "title": "Schedule"
        },
        {
            "location": "/schedule/#osg-vsp-schedule",
            "text": "Below is the schedule for the OSG Virtual School Pilot 2020.  We will probably\nmake small changes up to and even during the event.  However, the overall plan\nwill probably not change much.  All times are U.S. Central Daylight Time.  Notes:    Each lecture is offered twice on the same day.  Choose one time that is\n  convenient for you or, if you like, attend both.  Lectures will be held in the\n  Blackboard Collaborate video conference system; more details will be posted\n  and emailed soon.    Try to attend at least one Work Time per day.  This is time for you to work on\n  exercises or getting your research code running.  During a Work Time, plan to\n  be on Slack; from there, you can chat with staff and participants and, if\n  needed, arrange individual or group audio/video meetings.    Consultations are one-on-one meetings with your mentor.  You will work with\n  your mentor to schedule exact times.",
            "title": "OSG-VSP Schedule"
        },
        {
            "location": "/schedule/#week-1-july-1317",
            "text": "Monday (13th)  Lecture and discussion: Brief overview of the event and time to meet others (11\u00a0AM and 3\u00a0PM)  Consultations with mentors all day (scheduled in advance)    Tuesday (14th)  Lecture: High Throughput Computing and Running Locally (11\u00a0AM and 3\u00a0PM)  Work Time (1\u20133 PM\u00a0\u2014 just one scheduled this day)    Wednesday (15th)  Lecture: Running on OSG (11\u00a0AM and 3\u00a0PM)  Work Time (9\u201311 AM and 1\u20133 PM)    Thursday (16th)  Lecture: Managing Software (11\u00a0AM and 3\u00a0PM)  Work Time (9\u201311 AM and 1\u20133 PM)    Friday (17th)  Work Time (9 AM\u00a0\u2013 12 PM)  Nothing scheduled in afternoon! (But some staff will be available.)",
            "title": "Week 1: July 13\u201317"
        },
        {
            "location": "/schedule/#week-2-july-2024",
            "text": "Monday (20th)  Work Time (1\u20133 PM)  Nothing scheduled in morning! (But some staff will be available.)    Tuesday (21st)  Lecture: Managing Data (11\u00a0AM and 3\u00a0PM)  Work Time (9\u201311 AM and 1\u20133 PM)    Wednesday (22nd)  Showcase: Other researchers using HTC (11\u00a0AM; only once, sorry!)  Work Time (9\u201311 AM and 1\u20133 PM)    Thursday (23rd)  Consultations with mentors all day (scheduled in advance)    Friday (17th)  Wrap-up: Lightning talks (optional!) and group discussion (11\u00a0AM to ?)  Consultations with mentors all day (scheduled in advance)",
            "title": "Week 2: July 20\u201324"
        },
        {
            "location": "/materials/",
            "text": "OSG Virtual School (pilot) Materials\n\u00b6\n\n\nIntro to HTC and HTCondor\n\u00b6\n\n\nLecture recording will be linked here.\n\n\nIntro Exercises 1: Running and Viewing Simple Jobs (Strongly Recommended)\n\u00b6\n\n\n\n\nExercise 1.1: Log in to the local submit machine and look around\n\n\nExercise 1.2: Experiment with HTCondor commands\n\n\nExercise 1.3: Run jobs!\n\n\nExercise 1.4: Read and interpret log files\n\n\nExercise 1.5: Determining Resource Needs\n\n\nExercise 1.6: Remove jobs from the queue\n\n\nBonus Exercise 1.7: Compile and run some C code\n\n\n\n\nIntro Exercises 2: Running Many HTC Jobs\n\u00b6\n\n\n\n\nExercise 2.1: Work with input and output files\n\n\nExercise 2.2: Use \nqueue N\n, \n$(Cluster)\n, and \n$(Process)\n\n\nExercise 2.3: Use \nqueue from\n with custom variables\n\n\nBonus Exercise 2.4: Use \nqueue matching\n with a custom variable\n\n\n\n\nBonus Exercises: Job Attributes and Handling\n\u00b6\n\n\n\n\nBonus Exercise 3.1: Explore \ncondor_q\n\n\nBonus Exercise 3.2: Explore \ncondor_status\n\n\nBonus Exercise 3.3: A job that needs retries\n\n\n\n\nOSG\n\u00b6\n\n\nSoftware\n\u00b6\n\n\nSoftware Exercises 1: Basic Software and Wrapper Script Use (Strongly Recommended)\n\u00b6\n\n\n\n\nExercise 1.1: Work With Downloaded Software\n\n\nExercise 1.2: Use a Wrapper Script To Run Software\n\n\n\n\nSoftware Exercises 2: Specific Software Examples (Pick One)\n\u00b6\n\n\n\n\nExercise 2.1: Compiling and Running a Simple Code\n\n\nExercise 2.2: Compiling a Research Software\n\n\nExercise 2.3: Compiling Python and Running Jobs\n\n\nExercise 2.4: Compiling Matlab and Running Jobs\n\n\n\n\nSoftware Exercises 3: Using Containers in Jobs (Strongly Recommended)\n\u00b6\n\n\n\n\nExercise 3.1: Using Software in a Singularity Container\n\n\n\n\nSoftware Exercises 4: Bonus Exercises\n\u00b6\n\n\n\n\nExercise 4.1: Using Arguments With Wrapper Scripts\n\n\nExercise 4.2: Additional Python \n\n\nExercise 4.3: Using Software in a Docker Container\n\n\n\n\nData\n\u00b6\n\n\nBonus Topics\n\u00b6\n\n\nWorkflows with DAGMan\n\u00b6\n\n\nLecture slides\n(\nPPT\n,\n\nPDF\n)\n\n\nGPUs and Containers\n\u00b6\n\n\nMore Grid\n\u00b6",
            "title": "Overview"
        },
        {
            "location": "/materials/#osg-virtual-school-pilot-materials",
            "text": "",
            "title": "OSG Virtual School (pilot) Materials"
        },
        {
            "location": "/materials/#intro-to-htc-and-htcondor",
            "text": "Lecture recording will be linked here.",
            "title": "Intro to HTC and HTCondor"
        },
        {
            "location": "/materials/#intro-exercises-1-running-and-viewing-simple-jobs-strongly-recommended",
            "text": "Exercise 1.1: Log in to the local submit machine and look around  Exercise 1.2: Experiment with HTCondor commands  Exercise 1.3: Run jobs!  Exercise 1.4: Read and interpret log files  Exercise 1.5: Determining Resource Needs  Exercise 1.6: Remove jobs from the queue  Bonus Exercise 1.7: Compile and run some C code",
            "title": "Intro Exercises 1: Running and Viewing Simple Jobs (Strongly Recommended)"
        },
        {
            "location": "/materials/#intro-exercises-2-running-many-htc-jobs",
            "text": "Exercise 2.1: Work with input and output files  Exercise 2.2: Use  queue N ,  $(Cluster) , and  $(Process)  Exercise 2.3: Use  queue from  with custom variables  Bonus Exercise 2.4: Use  queue matching  with a custom variable",
            "title": "Intro Exercises 2: Running Many HTC Jobs"
        },
        {
            "location": "/materials/#bonus-exercises-job-attributes-and-handling",
            "text": "Bonus Exercise 3.1: Explore  condor_q  Bonus Exercise 3.2: Explore  condor_status  Bonus Exercise 3.3: A job that needs retries",
            "title": "Bonus Exercises: Job Attributes and Handling"
        },
        {
            "location": "/materials/#osg",
            "text": "",
            "title": "OSG"
        },
        {
            "location": "/materials/#software",
            "text": "",
            "title": "Software"
        },
        {
            "location": "/materials/#software-exercises-1-basic-software-and-wrapper-script-use-strongly-recommended",
            "text": "Exercise 1.1: Work With Downloaded Software  Exercise 1.2: Use a Wrapper Script To Run Software",
            "title": "Software Exercises 1: Basic Software and Wrapper Script Use (Strongly Recommended)"
        },
        {
            "location": "/materials/#software-exercises-2-specific-software-examples-pick-one",
            "text": "Exercise 2.1: Compiling and Running a Simple Code  Exercise 2.2: Compiling a Research Software  Exercise 2.3: Compiling Python and Running Jobs  Exercise 2.4: Compiling Matlab and Running Jobs",
            "title": "Software Exercises 2: Specific Software Examples (Pick One)"
        },
        {
            "location": "/materials/#software-exercises-3-using-containers-in-jobs-strongly-recommended",
            "text": "Exercise 3.1: Using Software in a Singularity Container",
            "title": "Software Exercises 3: Using Containers in Jobs (Strongly Recommended)"
        },
        {
            "location": "/materials/#software-exercises-4-bonus-exercises",
            "text": "Exercise 4.1: Using Arguments With Wrapper Scripts  Exercise 4.2: Additional Python   Exercise 4.3: Using Software in a Docker Container",
            "title": "Software Exercises 4: Bonus Exercises"
        },
        {
            "location": "/materials/#data",
            "text": "",
            "title": "Data"
        },
        {
            "location": "/materials/#bonus-topics",
            "text": "",
            "title": "Bonus Topics"
        },
        {
            "location": "/materials/#workflows-with-dagman",
            "text": "Lecture slides\n( PPT , PDF )",
            "title": "Workflows with DAGMan"
        },
        {
            "location": "/materials/#gpus-and-containers",
            "text": "",
            "title": "GPUs and Containers"
        },
        {
            "location": "/materials/#more-grid",
            "text": "",
            "title": "More Grid"
        },
        {
            "location": "/materials/htc/part1-ex1-login/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nHTC Exercise 1.1: Log In and Look Around\n\u00b6\n\n\nThe goal of this first exercise is simply to log in to the local submit server and look around a little bit, which will take only a few minutes. \n\n\nIf you have trouble getting SSH access to the submit server, ask the instructors right away! Gaining access is critical for all remaining exercises.\n\n\nLogging In\n\u00b6\n\n\nToday, you will use a submit server named \nlearn.chtc.wisc.edu\n, which will allow you to submit jobs to our local HTCondor pool in CHTC.\n\n\nTo log in, use a \nSecure Shell\n (SSH) client.\n\n\n\n\n\n\nFrom a Mac or Linux computer, run the Terminal app and use the \nssh\n command, like so:\n\n\nusername@learn $\n ssh \n<USERNAME>\n@learn.chtc.wisc.edu\n\n\n\n\n\n\n\n\n\nOn Windows, we recommend a free client called \nPuTTY\n,\n    but any SSH client should be fine.\n\n\n\n\n\n\nIf you need help finding or using an SSH client, ask the instructors for help right away\n!\n\n\nAbout Your Password\n\u00b6\n\n\n\n\n\n\nYour mentor should have given you your username and password.\n    If this is not true or you have lost the password, reach out to any staff member for help.\n\n\n\n\n\n\nWhile the \npasswd\n command will work (and will change your password temporarily),\n    your initial password will be automatically reset for you on an hourly basis.\n    So consider not changing your password and save the one provided in a secure place.\n\n\n\n\n\n\nRunning Commands\n\u00b6\n\n\nIn the exercises, we will show commands that you are supposed to type or copy into the command line, like this:\n\n\nusername@learn $\n hostname\n\nlearn.chtc.wisc.edu\n\n\n\n\n\n\n\n\nNote\n\n\nIn the first line of the example above, the \nusername@learn $\n part is meant to show the Linux command-line prompt.\nYou do not type this part! Further, your actual prompt probably is a bit different, and that is expected.\nSo in the example above, the command that you type at your own prompt is just the eight characters \nhostname\n.\nThe second line of the example, without the prompt, shows the output of the command; you do not type this part,\neither.\n\n\n\n\nHere are a few other commands that you can try (the examples below do not show the output from each command):\n\n\nusername@learn $\n whoami\n\nusername@learn $\n date\n\nusername@learn $\n uname -a\n\n\n\n\n\nA suggestion for the day: try typing into the command line as many of the commands as you can.\nCopy-and-paste is fine, of course, but \nyou WILL learn more if you take the time to type each command yourself.\n\n\nOrganizing Your Workspace\n\u00b6\n\n\nYou will be doing many different exercises over the next few days, many of them on this submit server. Each exercise may use many files, once finished. To avoid confusion, it may be useful to create a separate directory for each exercise.\n\n\nFor instance, for the rest of this exercise, you may wish to create and use a directory named \nintro-1.1-login\n, or something like that.\n\n\nusername@learn $\n mkdir intro-1.1-login\n\nusername@learn $\n \ncd\n intro-1.1-login\n\n\n\n\n\nShowing the Version of HTCondor\n\u00b6\n\n\nHTCondor is installed on this server. But what version? You can ask HTCondor itself:\n\n\nusername@learn $\n condor_version\n\n$\nCondorVersion: \n8\n.9.8 Jun \n29\n \n2020\n BuildID: \n508520\n PackageID: \n8\n.9.8-0.508520 $\n\n$\nCondorPlatform: x86_64_CentOS7 $\n\n\n\n\n\nAs you can see from the output, we are using HTCondor 8.9.8.\n\n\nFYI: Background information about HTCondor version numbers\n\u00b6\n\n\nHTCondor always has two types of releases at one time: stable and development. HTCondor 8.6.x and 8.8.x are considered stable releases, indicated by even-numbered second digits (e.g., 6 or 8 in these cases). Within one stable series, all versions have the same features (for example 8.6.0 and 8.6.8 have the same set of features) and differ only in bug and security fixes.\n\n\nHTCondor 8.9.8 is the latest \ndevelopment\n release series of HTCondor. You know that these are a development release because the second digit (i.e., 9) is an odd number. CHTC is usually running the latest development series as the local CHTC Pool is somewhat of a final testing ground for new features. Other HTCondor pools and submit servers that you use outside of CHTC (including the OSG submit server you'll use later) may run different versions. In general, the user-facing HTCondor features in 8.6 forward are mostly the same, but you may see some differences in the format of output from \ncondor_\n commands or in more advanced or non-user features.\n\n\nReference Materials\n\u00b6\n\n\nHere are a few links to reference materials that might be interesting after the school (or perhaps during).\n\n\n\n\nHTCondor home page\n\n\nHTCondor manuals\n; it is probably best to read the manual corresponding to the version of HTCondor that you use. That link points to the latest version of the manual, but you can switch versions using the toggle in the lower left corner of that page.\n\n\nCenter for High Throughput Computing\n, our campus research computing center, and home to HTCondor and other development of distributed computing tools.",
            "title": "Exercise 1.1"
        },
        {
            "location": "/materials/htc/part1-ex1-login/#htc-exercise-11-log-in-and-look-around",
            "text": "The goal of this first exercise is simply to log in to the local submit server and look around a little bit, which will take only a few minutes.   If you have trouble getting SSH access to the submit server, ask the instructors right away! Gaining access is critical for all remaining exercises.",
            "title": "HTC Exercise 1.1: Log In and Look Around"
        },
        {
            "location": "/materials/htc/part1-ex1-login/#logging-in",
            "text": "Today, you will use a submit server named  learn.chtc.wisc.edu , which will allow you to submit jobs to our local HTCondor pool in CHTC.  To log in, use a  Secure Shell  (SSH) client.    From a Mac or Linux computer, run the Terminal app and use the  ssh  command, like so:  username@learn $  ssh  <USERNAME> @learn.chtc.wisc.edu    On Windows, we recommend a free client called  PuTTY ,\n    but any SSH client should be fine.    If you need help finding or using an SSH client, ask the instructors for help right away !",
            "title": "Logging In"
        },
        {
            "location": "/materials/htc/part1-ex1-login/#about-your-password",
            "text": "Your mentor should have given you your username and password.\n    If this is not true or you have lost the password, reach out to any staff member for help.    While the  passwd  command will work (and will change your password temporarily),\n    your initial password will be automatically reset for you on an hourly basis.\n    So consider not changing your password and save the one provided in a secure place.",
            "title": "About Your Password"
        },
        {
            "location": "/materials/htc/part1-ex1-login/#running-commands",
            "text": "In the exercises, we will show commands that you are supposed to type or copy into the command line, like this:  username@learn $  hostname learn.chtc.wisc.edu    Note  In the first line of the example above, the  username@learn $  part is meant to show the Linux command-line prompt.\nYou do not type this part! Further, your actual prompt probably is a bit different, and that is expected.\nSo in the example above, the command that you type at your own prompt is just the eight characters  hostname .\nThe second line of the example, without the prompt, shows the output of the command; you do not type this part,\neither.   Here are a few other commands that you can try (the examples below do not show the output from each command):  username@learn $  whoami username@learn $  date username@learn $  uname -a  A suggestion for the day: try typing into the command line as many of the commands as you can.\nCopy-and-paste is fine, of course, but  you WILL learn more if you take the time to type each command yourself.",
            "title": "Running Commands"
        },
        {
            "location": "/materials/htc/part1-ex1-login/#organizing-your-workspace",
            "text": "You will be doing many different exercises over the next few days, many of them on this submit server. Each exercise may use many files, once finished. To avoid confusion, it may be useful to create a separate directory for each exercise.  For instance, for the rest of this exercise, you may wish to create and use a directory named  intro-1.1-login , or something like that.  username@learn $  mkdir intro-1.1-login username@learn $   cd  intro-1.1-login",
            "title": "Organizing Your Workspace"
        },
        {
            "location": "/materials/htc/part1-ex1-login/#showing-the-version-of-htcondor",
            "text": "HTCondor is installed on this server. But what version? You can ask HTCondor itself:  username@learn $  condor_version $ CondorVersion:  8 .9.8 Jun  29   2020  BuildID:  508520  PackageID:  8 .9.8-0.508520 $ $ CondorPlatform: x86_64_CentOS7 $  As you can see from the output, we are using HTCondor 8.9.8.",
            "title": "Showing the Version of HTCondor"
        },
        {
            "location": "/materials/htc/part1-ex1-login/#fyi-background-information-about-htcondor-version-numbers",
            "text": "HTCondor always has two types of releases at one time: stable and development. HTCondor 8.6.x and 8.8.x are considered stable releases, indicated by even-numbered second digits (e.g., 6 or 8 in these cases). Within one stable series, all versions have the same features (for example 8.6.0 and 8.6.8 have the same set of features) and differ only in bug and security fixes.  HTCondor 8.9.8 is the latest  development  release series of HTCondor. You know that these are a development release because the second digit (i.e., 9) is an odd number. CHTC is usually running the latest development series as the local CHTC Pool is somewhat of a final testing ground for new features. Other HTCondor pools and submit servers that you use outside of CHTC (including the OSG submit server you'll use later) may run different versions. In general, the user-facing HTCondor features in 8.6 forward are mostly the same, but you may see some differences in the format of output from  condor_  commands or in more advanced or non-user features.",
            "title": "FYI: Background information about HTCondor version numbers"
        },
        {
            "location": "/materials/htc/part1-ex1-login/#reference-materials",
            "text": "Here are a few links to reference materials that might be interesting after the school (or perhaps during).   HTCondor home page  HTCondor manuals ; it is probably best to read the manual corresponding to the version of HTCondor that you use. That link points to the latest version of the manual, but you can switch versions using the toggle in the lower left corner of that page.  Center for High Throughput Computing , our campus research computing center, and home to HTCondor and other development of distributed computing tools.",
            "title": "Reference Materials"
        },
        {
            "location": "/materials/htc/part1-ex2-commands/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nHTC Exercise 1.2: Experiment With HTCondor Commands\n\u00b6\n\n\nThe goal of this exercise is to learn about two foundational HTCondor commands, \ncondor_q\n and \ncondor_status\n.\nThey will be useful for monitoring your jobs and available slots (respectively) throughout the week.\n\n\nThis exercise should take only a few minutes.\n\n\nViewing Slots\n\u00b6\n\n\nAs discussed in the lecture, the \ncondor_status\n command is used to view the current state of slots in an HTCondor pool.\n\n\nAt its most basic, the command is very straightforward:\n\n\nusername@learn $\n condor_status\n\n\n\n\n\nThis command, running on our (CHTC) pool, will produce a lot of output; there is one line per slot, and we typically have over 10,000 slots. \nTIP: You can widen your terminal window, which may help you to see all details of the output better.\n\n\nHere is some example output (what you see will be longer):\n\n\nslot1_31@e437.chtc.wisc.edu        LINUX      X86_64 Unclaimed Idle      0.000 8053  0+01:14:34\n\n\nslot1_32@e437.chtc.wisc.edu        LINUX      X86_64 Unclaimed Idle      0.000 8053  0+03:57:00\n\n\nslot1_33@e437.chtc.wisc.edu        LINUX      X86_64 Unclaimed Idle      0.000 8053  1+00:05:17\n\n\nslot1@e438.chtc.wisc.edu           LINUX      X86_64 Owner     Idle      0.300  250  7+03:22:21\n\n\nslot1_1@e438.chtc.wisc.edu         LINUX      X86_64 Claimed   Busy      0.930 1024  0+02:42:08\n\n\nslot1_2@e438.chtc.wisc.edu         LINUX      X86_64 Claimed   Busy      3.530 1024  0+02:40:24\n\n\n\n\n\n\nThis output consists of 8 columns:\n\n\n\n\n\n\n\n\nCol\n\n\nExample\n\n\nMeaning\n\n\n\n\n\n\n\n\n\n\nName\n\n\nslot1_1@e438.chtc.wisc.edu\n\n\nFull slot name (including the hostname)\n\n\n\n\n\n\nOpSys\n\n\nLINUX\n\n\nOperating system\n\n\n\n\n\n\nArch\n\n\nX86_64\n\n\nSlot architecture (e.g., Intel 64 bit)\n\n\n\n\n\n\nState\n\n\nClaimed\n\n\nState of the slot (\nUnclaimed\n is available, \nOwner\n is being used by the machine owner, \nClaimed\n is matched to a job)\n\n\n\n\n\n\nActivity\n\n\nBusy\n\n\nIs there activity on the slot?\n\n\n\n\n\n\nLoadAv\n\n\n0.930\n\n\nLoad average, a measure of CPU activity on the slot\n\n\n\n\n\n\nMem\n\n\n1024\n\n\nMemory available to the slot, in MB\n\n\n\n\n\n\nActvtyTime\n\n\n0+02:42:08\n\n\nAmount of time spent in current activity (days + hours:minutes:seconds)\n\n\n\n\n\n\n\n\nAt the end of the slot listing, there is a summary. Here is an example:\n\n\n                     Machines Owner Claimed Unclaimed Matched Preempting  Drain\n\n\n\n        X86_64/LINUX    10831     0   10194       631       0          0      6\n\n\n      X86_64/WINDOWS        2     2       0         0       0          0      0\n\n\n\n               Total    10833     2   10194       631       0          0      6\n\n\n\n\n\n\nThere is one row of summary for each machine (i.e. \"slot\") architecture/operating system combination with columns for the number of slots in each state. The final row gives a summary of slot states for the whole pool.\n\n\nQuestions:\n\u00b6\n\n\n\n\nWhen you run \ncondor_status\n, how many 64-bit Linux slots are available? (Hint: Unclaimed = available.)\n\n\nWhat percent of the total slots are currently claimed by a job? (Note: there is a rapid turnover of slots, which is what allows users with new submission to have jobs start quickly.)\n\n\nHow have these numbers changed (if at all) when you run the command again?\n\n\n\n\nViewing Whole Machines, Only\n\u00b6\n\n\nAlso try out the \n-compact\n for a slightly different view of whole machines (i.e. server hostnames), without the individual slots shown.\n\n\nusername@learn $\n condor_status -compact\n\n\n\n\n\nHow has the column information changed?\n\n\nViewing Jobs\n\u00b6\n\n\nThe \ncondor_q\n command lists jobs that are on this submit machine and that are running or waiting to run. The \n_q\n part of the name is meant to suggest the word \u201cqueue\u201d, or list of job sets \nwaiting\n to finish.\n\n\nViewing Your Own Jobs\n\u00b6\n\n\nThe default behavior of the command lists only your jobs:\n\n\nusername@learn $\n condor_q\n\n\n\n\n\nThe main part of the output (which will be empty, because you haven't submitted jobs yet) shows one set (\"batch\") of submitted jobs per line. If you had a single job in the queue, it would look something like the below:\n\n\n-- Schedd: learn.chtc.wisc.edu : <128.104.100.43:9618?... @ 07/12/19 09:59:31\n\n\nOWNER  BATCH_NAME            SUBMITTED   DONE   RUN    IDLE  TOTAL JOB_IDS\n\n\naapohl CMD: run_ffmpeg.sh   7/12 09:58      _      _      1      1 18801.0               \n\n\n\n\n\n\nThis output consists of 8 (or 9) columns:\n\n\n\n\n\n\n\n\nCol\n\n\nExample\n\n\nMeaning\n\n\n\n\n\n\n\n\n\n\nOWNER\n\n\naapohl\n\n\nThe user ID of the user who submitted the job\n\n\n\n\n\n\nBATCH_NAME\n\n\nrun_ffmpeg.sh\n\n\nThe executable or \"jobbatchname\" specified within the submit file(s)\n\n\n\n\n\n\nSUBMITTED\n\n\n7/12 09:58\n\n\nThe date and time when the job was submitted\n\n\n\n\n\n\nDONE\n\n\n_\n\n\nNumber of jobs in this batch that have completed\n\n\n\n\n\n\nRUN\n\n\n_\n\n\nNumber of jobs in this batch that are currently running\n\n\n\n\n\n\nIDLE\n\n\n1\n\n\nNumber of jobs in this batch that are idle, waiting for a match\n\n\n\n\n\n\nHOLD\n\n\n_\n\n\nColumn will show up if there are jobs on \"hold\" because something about the submission/setup needs to be corrected by the user\n\n\n\n\n\n\nTOTAL\n\n\n1\n\n\nTotal number of jobs in this batch\n\n\n\n\n\n\nJOB_IDS\n\n\n18801.0\n\n\nJob ID or range of Job IDs in this batch\n\n\n\n\n\n\n\n\nAt the end of the job listing, there is a summary. Here is a sample:\n\n\n1 jobs; 0 completed, 0 removed, 1 idle, 0 running, 0 held, 0 suspended\n\n\n\n\n\n\nIt shows total counts of jobs in the different possible states.\n\n\nQuestions:\n\n\n\n\nFor the sample above, when was the job submitted?\n\n\nFor the sample above, was the job running or not yet? How can you tell?\n\n\n\n\nViewing Everyone\u2019s Jobs\n\u00b6\n\n\nBy default, the \ncondor_q\n command shows \nyour\n jobs only. To see everyone\u2019s jobs that are queued on the machine, add the \n-all\n option:\n\n\nusername@learn $\n condor_q -all\n\n\n\n\n\n\n\nHow many jobs are queued in total (i.e., running or waiting to run)?\n\n\nHow many jobs from this submit machine are running right now?\n\n\n\n\nViewing Jobs without the Default \"batch\" Mode\n\u00b6\n\n\nThe \ncondor_q\n output, by default, groups \"batches\" of jobs together (if they were submitted with the same submit file or \"jobbatchname\"). To see more information for EVERY job on a separate line of output, use the \n-nobatch\n option to \ncondor_q\n:\n\n\nusername@learn $\n condor_q -all -nobatch\n\n\n\n\n\nHow has the column information changed?\n (Below is an example of the top of the output.)\n\n\n-- Schedd: learn.chtc.wisc.edu : <128.104.100.43:9618?... @ 07/12/19 11:58:44\n\n\n ID       OWNER            SUBMITTED     RUN_TIME ST PRI SIZE   CMD\n\n\n18203.0   s16_alirezakho  7/11 09:51   0+00:00:00 I  0      0.7 pascal\n\n\n18204.0   s16_alirezakho  7/11 09:51   0+00:00:00 I  0      0.7 pascal\n\n\n18801.0   aapohl          7/12 09:58   0+00:00:00 I  0      0.0 run_ffmpeg.sh\n\n\n18997.0   s16_martincum   7/12 10:59   0+00:00:32 I  0    733.0 runR.pl 1_0 run_perm.R 1 0 10\n\n\n19027.5   s16_martincum   7/12 11:06   0+00:09:20 I  0   2198.0 runR.pl 1_5 run_perm.R 1 5 1000\n\n\n\n\n\n\nThe \n-nobatch\n output shows a line for every job and consists of 8 columns:\n\n\n\n\n\n\n\n\nCol\n\n\nExample\n\n\nMeaning\n\n\n\n\n\n\n\n\n\n\nID\n\n\n18801.0\n\n\nJob ID, which is the \ncluster\n, a dot character (\n.\n), and the \nprocess\n\n\n\n\n\n\nOWNER\n\n\naapohl\n\n\nThe user ID of the user who submitted the job\n\n\n\n\n\n\nSUBMITTED\n\n\n7/12 09:58\n\n\nThe date and time when the job was submitted\n\n\n\n\n\n\nRUN_TIME\n\n\n0+00:00:00\n\n\nTotal time spent running so far (days + hours:minutes:seconds)\n\n\n\n\n\n\nST\n\n\nI\n\n\nStatus of job: \nI\n is Idle (waiting to run), \nR\n is Running, \nH\n is Held, etc.\n\n\n\n\n\n\nPRI\n\n\n0\n\n\nJob priority (see next lecture)\n\n\n\n\n\n\nSIZE\n\n\n0.0\n\n\nCurrent run-time memory usage, in MB\n\n\n\n\n\n\nCMD\n\n\nrun_ffmpeg.sh\n\n\nThe executable command (with arguments) to be run\n\n\n\n\n\n\n\n\nIn future exercises, you'll want to switch between \ncondor_q\n and \ncondor_q -nobatch\n to see different types of information about YOUR jobs.\n\n\nExtra Information\n\u00b6\n\n\nBoth \ncondor_status\n and \ncondor_q\n have many command-line options, some of which significantly change their output. You will explore a few of the most useful options today and tomorrow, but if you want to experiment now, go ahead! There are a few ways to learn more about the commands:\n\n\n\n\nUse the (brief) built-in help for the commands, e.g.: \ncondor_q -h\n\n\nRead the installed man(ual) pages for the commands, e.g.: \nman condor_q\n\n\nFind the command in \nthe online manual\n; \nnote:\n the text online is the same as the \nman\n text, only formatted for the web",
            "title": "Exercise 1.2"
        },
        {
            "location": "/materials/htc/part1-ex2-commands/#htc-exercise-12-experiment-with-htcondor-commands",
            "text": "The goal of this exercise is to learn about two foundational HTCondor commands,  condor_q  and  condor_status .\nThey will be useful for monitoring your jobs and available slots (respectively) throughout the week.  This exercise should take only a few minutes.",
            "title": "HTC Exercise 1.2: Experiment With HTCondor Commands"
        },
        {
            "location": "/materials/htc/part1-ex2-commands/#viewing-slots",
            "text": "As discussed in the lecture, the  condor_status  command is used to view the current state of slots in an HTCondor pool.  At its most basic, the command is very straightforward:  username@learn $  condor_status  This command, running on our (CHTC) pool, will produce a lot of output; there is one line per slot, and we typically have over 10,000 slots.  TIP: You can widen your terminal window, which may help you to see all details of the output better.  Here is some example output (what you see will be longer):  slot1_31@e437.chtc.wisc.edu        LINUX      X86_64 Unclaimed Idle      0.000 8053  0+01:14:34  slot1_32@e437.chtc.wisc.edu        LINUX      X86_64 Unclaimed Idle      0.000 8053  0+03:57:00  slot1_33@e437.chtc.wisc.edu        LINUX      X86_64 Unclaimed Idle      0.000 8053  1+00:05:17  slot1@e438.chtc.wisc.edu           LINUX      X86_64 Owner     Idle      0.300  250  7+03:22:21  slot1_1@e438.chtc.wisc.edu         LINUX      X86_64 Claimed   Busy      0.930 1024  0+02:42:08  slot1_2@e438.chtc.wisc.edu         LINUX      X86_64 Claimed   Busy      3.530 1024  0+02:40:24   This output consists of 8 columns:     Col  Example  Meaning      Name  slot1_1@e438.chtc.wisc.edu  Full slot name (including the hostname)    OpSys  LINUX  Operating system    Arch  X86_64  Slot architecture (e.g., Intel 64 bit)    State  Claimed  State of the slot ( Unclaimed  is available,  Owner  is being used by the machine owner,  Claimed  is matched to a job)    Activity  Busy  Is there activity on the slot?    LoadAv  0.930  Load average, a measure of CPU activity on the slot    Mem  1024  Memory available to the slot, in MB    ActvtyTime  0+02:42:08  Amount of time spent in current activity (days + hours:minutes:seconds)     At the end of the slot listing, there is a summary. Here is an example:                       Machines Owner Claimed Unclaimed Matched Preempting  Drain          X86_64/LINUX    10831     0   10194       631       0          0      6        X86_64/WINDOWS        2     2       0         0       0          0      0                 Total    10833     2   10194       631       0          0      6   There is one row of summary for each machine (i.e. \"slot\") architecture/operating system combination with columns for the number of slots in each state. The final row gives a summary of slot states for the whole pool.",
            "title": "Viewing Slots"
        },
        {
            "location": "/materials/htc/part1-ex2-commands/#questions",
            "text": "When you run  condor_status , how many 64-bit Linux slots are available? (Hint: Unclaimed = available.)  What percent of the total slots are currently claimed by a job? (Note: there is a rapid turnover of slots, which is what allows users with new submission to have jobs start quickly.)  How have these numbers changed (if at all) when you run the command again?",
            "title": "Questions:"
        },
        {
            "location": "/materials/htc/part1-ex2-commands/#viewing-whole-machines-only",
            "text": "Also try out the  -compact  for a slightly different view of whole machines (i.e. server hostnames), without the individual slots shown.  username@learn $  condor_status -compact  How has the column information changed?",
            "title": "Viewing Whole Machines, Only"
        },
        {
            "location": "/materials/htc/part1-ex2-commands/#viewing-jobs",
            "text": "The  condor_q  command lists jobs that are on this submit machine and that are running or waiting to run. The  _q  part of the name is meant to suggest the word \u201cqueue\u201d, or list of job sets  waiting  to finish.",
            "title": "Viewing Jobs"
        },
        {
            "location": "/materials/htc/part1-ex2-commands/#viewing-your-own-jobs",
            "text": "The default behavior of the command lists only your jobs:  username@learn $  condor_q  The main part of the output (which will be empty, because you haven't submitted jobs yet) shows one set (\"batch\") of submitted jobs per line. If you had a single job in the queue, it would look something like the below:  -- Schedd: learn.chtc.wisc.edu : <128.104.100.43:9618?... @ 07/12/19 09:59:31  OWNER  BATCH_NAME            SUBMITTED   DONE   RUN    IDLE  TOTAL JOB_IDS  aapohl CMD: run_ffmpeg.sh   7/12 09:58      _      _      1      1 18801.0                  This output consists of 8 (or 9) columns:     Col  Example  Meaning      OWNER  aapohl  The user ID of the user who submitted the job    BATCH_NAME  run_ffmpeg.sh  The executable or \"jobbatchname\" specified within the submit file(s)    SUBMITTED  7/12 09:58  The date and time when the job was submitted    DONE  _  Number of jobs in this batch that have completed    RUN  _  Number of jobs in this batch that are currently running    IDLE  1  Number of jobs in this batch that are idle, waiting for a match    HOLD  _  Column will show up if there are jobs on \"hold\" because something about the submission/setup needs to be corrected by the user    TOTAL  1  Total number of jobs in this batch    JOB_IDS  18801.0  Job ID or range of Job IDs in this batch     At the end of the job listing, there is a summary. Here is a sample:  1 jobs; 0 completed, 0 removed, 1 idle, 0 running, 0 held, 0 suspended   It shows total counts of jobs in the different possible states.  Questions:   For the sample above, when was the job submitted?  For the sample above, was the job running or not yet? How can you tell?",
            "title": "Viewing Your Own Jobs"
        },
        {
            "location": "/materials/htc/part1-ex2-commands/#viewing-everyones-jobs",
            "text": "By default, the  condor_q  command shows  your  jobs only. To see everyone\u2019s jobs that are queued on the machine, add the  -all  option:  username@learn $  condor_q -all   How many jobs are queued in total (i.e., running or waiting to run)?  How many jobs from this submit machine are running right now?",
            "title": "Viewing Everyone\u2019s Jobs"
        },
        {
            "location": "/materials/htc/part1-ex2-commands/#viewing-jobs-without-the-default-batch-mode",
            "text": "The  condor_q  output, by default, groups \"batches\" of jobs together (if they were submitted with the same submit file or \"jobbatchname\"). To see more information for EVERY job on a separate line of output, use the  -nobatch  option to  condor_q :  username@learn $  condor_q -all -nobatch  How has the column information changed?  (Below is an example of the top of the output.)  -- Schedd: learn.chtc.wisc.edu : <128.104.100.43:9618?... @ 07/12/19 11:58:44   ID       OWNER            SUBMITTED     RUN_TIME ST PRI SIZE   CMD  18203.0   s16_alirezakho  7/11 09:51   0+00:00:00 I  0      0.7 pascal  18204.0   s16_alirezakho  7/11 09:51   0+00:00:00 I  0      0.7 pascal  18801.0   aapohl          7/12 09:58   0+00:00:00 I  0      0.0 run_ffmpeg.sh  18997.0   s16_martincum   7/12 10:59   0+00:00:32 I  0    733.0 runR.pl 1_0 run_perm.R 1 0 10  19027.5   s16_martincum   7/12 11:06   0+00:09:20 I  0   2198.0 runR.pl 1_5 run_perm.R 1 5 1000   The  -nobatch  output shows a line for every job and consists of 8 columns:     Col  Example  Meaning      ID  18801.0  Job ID, which is the  cluster , a dot character ( . ), and the  process    OWNER  aapohl  The user ID of the user who submitted the job    SUBMITTED  7/12 09:58  The date and time when the job was submitted    RUN_TIME  0+00:00:00  Total time spent running so far (days + hours:minutes:seconds)    ST  I  Status of job:  I  is Idle (waiting to run),  R  is Running,  H  is Held, etc.    PRI  0  Job priority (see next lecture)    SIZE  0.0  Current run-time memory usage, in MB    CMD  run_ffmpeg.sh  The executable command (with arguments) to be run     In future exercises, you'll want to switch between  condor_q  and  condor_q -nobatch  to see different types of information about YOUR jobs.",
            "title": "Viewing Jobs without the Default \"batch\" Mode"
        },
        {
            "location": "/materials/htc/part1-ex2-commands/#extra-information",
            "text": "Both  condor_status  and  condor_q  have many command-line options, some of which significantly change their output. You will explore a few of the most useful options today and tomorrow, but if you want to experiment now, go ahead! There are a few ways to learn more about the commands:   Use the (brief) built-in help for the commands, e.g.:  condor_q -h  Read the installed man(ual) pages for the commands, e.g.:  man condor_q  Find the command in  the online manual ;  note:  the text online is the same as the  man  text, only formatted for the web",
            "title": "Extra Information"
        },
        {
            "location": "/materials/htc/part1-ex3-jobs/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nHTC Exercise 1.3: Run Jobs!\n\u00b6\n\n\nThe goal of this exercise is to submit jobs to HTCondor and have them run on the local pool (CHTC). This is a huge step in learning to use an HTC system!\n\n\nThis exercise will take longer than the first two, short ones. It is the essential part of this exercise time. If you are having any problems getting the jobs to run, please ask the instructors! It is very important that you know how to run jobs.\n\n\nRunning Your First Job\n\u00b6\n\n\nNearly all of the time, when you want to run an HTCondor job, you first write an HTCondor submit file for it. In this section, you will run the same \nhostname\n command as in Exercise 1.1, but where this command will run within a job on one of the 'execute' servers in CHTC's local HTCondor pool.\n\n\nHere is a straightforward submit file for the \nhostname\n command:\n\n\nexecutable = /bin/hostname\n\noutput = hostname.out\nerror = hostname.err\nlog = hostname.log\n\nrequest_cpus = 1\nrequest_memory = 1GB\nrequest_disk = 1MB\n\nqueue\n\n\n\n\n\nWrite those lines of text in a file named \nhostname.sub\n.\n\n\n\n\nNote\n\n\nThere is nothing magic about the name of an HTCondor submit file.\nIt can be any filename you want.\nIt's a good practice to always include the \n.sub\n extension, but it is not required.\nUltimately, a submit file is a text file\n\n\n\n\nThe lines of the submit file have the following meanings:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexecutable\n\n\nThe name of the program to run (relative to the directory from which you submit).\n\n\n\n\n\n\noutput\n\n\nThe filename where HTCondor will write the standard output from your job.\n\n\n\n\n\n\nerror\n\n\nThe filename where HTCondor will write the standard error from your job. This particular job is not likely to have any, but it is best to include this line for every job.\n\n\n\n\n\n\nlog\n\n\nThe filename where HTCondor will write information about your job run. While not required, it is a \nreally\n good idea to have a log file for every job.\n\n\n\n\n\n\nrequest_*\n\n\nTells HTCondor how many \ncpus\n and how much \nmemory\n and \ndisk\n we want, which is not much, because the 'hostname' executable is very small.\n\n\n\n\n\n\nqueue\n\n\nTells HTCondor to run your job with the settings above.\n\n\n\n\n\n\n\n\nNote that we are not using the \narguments\n or \ntransfer_input_files\n lines that were mentioned during lecture because the \nhostname\n program is all that needs to be transferred from the submit server, and we want to run it without any additional options.\n\n\nDouble-check your submit file, so that it matches the text above. Then, tell HTCondor to run your job:\n\n\nusername@learn $\n condor_submit hostname.sub\n\nSubmitting job(s).\n\n\n1 job(s) submitted to cluster NNNN.\n\n\n\n\n\n\nThe actual cluster number will be shown instead of \nNNNN\n. \nIf, instead of the text above, there are error messages, read them carefully and then try to correct your submit file or ask for help.\n\n\nNotice that \ncondor_submit\n returns back to the shell prompt right away. It does \nnot\n wait for your job to run. Instead, as soon as it has finished submitting your job into the queue, the submit command finishes.\n\n\nView your job in the queue\n\u00b6\n\n\nNow, use \ncondor_q\n and \ncondor_q -nobatch\n to watch for your job in the queue! \n\n\nYou may not even catch the job in the \nR\n running state, because the \nhostname\n command runs very quickly. When the job itself is finished, it will 'leave' the queue and no longer be listed in the \ncondor_q\n output.\n\n\nAfter the job finishes, check for the \nhostname\n output in \nhostname.out\n, which is where job information printed to the terminal screen will be printed for the job.\n\n\nusername@learn $\n cat hostname.out\n\ne171.chtc.wisc.edu\n\n\n\n\n\n\nThe \nhostname.err\n file should be empty, unless there were issues running the \nhostname\n executable after it was transferred to the slot. The \nhostname.log\n is more complex and will be the focus of a later exercise.\n\n\nRunning a Job With Arguments\n\u00b6\n\n\nVery often, when you run a command on the command line, it includes arguments (i.e. options) after the program name, as in the below examples:\n\n\nusername@learn $\n cat hostname.out\n\nusername@learn $\n sleep \n60\n\n\nusername@learn $\n dc -e \n'6 7 * p'\n\n\n\n\n\n\nIn an HTCondor submit file, the program (or 'executable') name goes in the \nexecutable\n statement and \nall remaining arguments\n go into an \narguments\n statement. For example, if the full command is:\n\n\nusername@learn $\n sleep \n60\n\n\n\n\n\n\nThen in the submit file, we would put the location of the \"sleep\" program (you can find it with \nwhich sleep\n) as the job \nexecutable\n, and \n60\n as the job \narguments\n:\n\n\nexecutable = /bin/sleep\narguments = 60\n\n\n\n\n\nFor the command-line command:\n\n\nusername@learn $\n dc -e \n'6 7 * p'\n\n\n\n\n\n\nWe would put the following into the submit file, putting the \narguments\n statement in quotes, since it contains single quotes:\n\n\nexecutable = /usr/bin/dc\narguments = \"-e '6 7 * p'\"\n\n\n\n\n\nLet\u2019s try a job submission with arguments. We will use the \nsleep\n command shown above, which simply does nothing for the specified number of seconds, then exits normally. It is convenient for simulating a job that takes a while to run.\n\n\nCreate a new submit file (you name it this time) and save the following text in it.\n\n\nexecutable = /bin/sleep\narguments = 60\n\noutput = sleep.out\nerror = sleep.err\nlog = sleep.log\n\nrequest_cpus = 1\nrequest_memory = 1GB\nrequest_disk = 1MB\n\nqueue\n\n\n\n\n\nExcept for changing a few filenames, this submit file is nearly identical to the last one. But, see the extra \narguments\n line?\n\n\nSubmit this new job. Again, watch for it to run using \ncondor_q\n and \ncondor_q -nobatch\n; \ncheck once every 15 seconds or so. \nOnce the job starts running, it will take about 1 minute to run (because of the \nsleep\n command, right?), \nso you should be able to see it running for a bit. \nWhen the job finishes, it will disappear from the queue, but there will be no output in the output or error files, because \nsleep\n does not produce any output.\n\n\nRunning a Script Job From the Submit Directory\n\u00b6\n\n\nSo far, we have been running programs (executables) that come with the standard Linux system. \nMore frequently, you will want to run a program that exists within your directory \nor perhaps a shell script of commands that you'd like to run within a job. In this example, you will write a shell script and a submit file that runs the shell script within a job:\n\n\n\n\n\n\nPut the following contents into a file named \ntest-script.sh\n:\n\n\n#!/bin/sh\n\n\necho\n \n'Date: '\n \n`\ndate\n`\n \n\necho\n \n'Host: '\n \n`\nhostname\n`\n \n\necho\n \n'System: '\n \n`\nuname -spo\n`\n \n\necho\n \n\"Program: \n$0\n\"\n \n\necho\n \n\"Args: \n$*\n\"\n\n\necho\n \n'ls: '\n \n`\nls\n`\n\n\n# END\n\n\n\n\n\n\n\n\n\n\nAdd executable permissions to the file (so that it can be run as a program):\n\n\nusername@learn $\n chmod +x test-script.sh\n\n\n\n\n\n\n\n\n\nTest your script from the command line:\n\n\nusername@learn $\n ./test-script.sh hello \n42\n \n\nDate: Mon Jul 17 10:02:20 CDT 2017 \n\n\nHost: learn.chtc.wisc.edu \n\n\nSystem: Linux x86_64 GNU/Linux \n\n\nProgram: ./test-script.sh\n\n\nArgs: hello 42\n\n\nls: hostname.sub montage hostname.err hostname.log hostname.out test-script.sh\n\n\n\n\n\n\nThis step is \nreally\n important! If you cannot run your executable from the command-line, HTCondor probably cannot run it on another machine, either. \nFurther, debugging problems like this one is surprisingly difficult. \nSo, if possible, test your \nexecutable\n and \narguments\n as a command at the command-line first.\n\n\n\n\n\n\nWrite the submit file (this should be getting easier by now):\n\n\nexecutable = test-script.sh\narguments = foo bar baz\n\noutput = script.out\nerror = script.err\nlog = script.log\n\nrequest_cpus = 1\nrequest_memory = 1GB\nrequest_disk = 1MB\n\nqueue\n\n\n\n\n\nIn this example, the \nexecutable\n that was named in the submit file did \nnot\n start with a \n/\n, \n    so the location of the file is relative to the submit directory itself. \n    In other words, in this format the executable must be in the same directory as the submit file.\n\n\n\n\nNote\n\n\nBlank lines between commands and spaces around the \n=\n do not matter to HTCondor.\nFor example, this submit file is equivalent to the one above:\n\n\nexecutable = test-script.sh\narguments =  foo bar baz\noutput =     script.out\nerror =      script.err\nlog =        script.log\n\nrequest_cpus=1\nrequest_memory=1GB\nrequest_disk=1MB\n\nqueue\n\n\n\n\n\nUse whitespace to make things clear to \nyou\n. \nWhat format do you prefer to read?\n\n\n\n\n\n\n\n\nSubmit the job, wait for it to finish, and check the output (and error, which should be empty).\n\n\nWhat do you notice about the lines returned for \"Program\" and \"ls\"? Remember that only files pertaining\nto \nthis\n job will be in the job working directory on the execute server. You're also seeing the effects\nof HTCondor's need to standardize some filenames when running your job, though they are named as you expect \nin the submission directory (per the submit file contents).\n\n\n\n\n\n\nExtra Challenge\n\u00b6\n\n\n\n\nNote\n\n\nThere are Extra Challenges throughout the school curriculum. You may be better off coming back to these after you've completed all other exercises for your current working session.\n\n\n\n\nBelow is a Python script that does something similar to the shell script above. Run this Python script using HTCondor.\n\n\n#!/usr/bin/env python\n\n\n\n\"\"\"Extra Challenge for OSG User School\n\n\nWritten by Tim Cartwright\n\n\nSubmitted to CHTC by #YOUR_NAME#\n\n\n\"\"\"\n\n\n\nimport\n \ngetpass\n\n\nimport\n \nos\n\n\nimport\n \nplatform\n\n\nimport\n \nsocket\n\n\nimport\n \nsys\n\n\nimport\n \ntime\n\n\n\narguments\n \n=\n \nNone\n\n\nif\n \nlen\n(\nsys\n.\nargv\n)\n \n>\n \n1\n:\n\n    \narguments\n \n=\n \n'\"'\n \n+\n \n' '\n.\njoin\n(\nsys\n.\nargv\n[\n1\n:])\n \n+\n \n'\"'\n\n\n\nprint\n \n>>\n \nsys\n.\nstderr\n,\n \n__doc__\n\n\nprint\n \n'Time    :'\n,\n \ntime\n.\nstrftime\n(\n'%Y-%m-\n%d\n (\n%a\n) %H:%M:%S %Z'\n)\n\n\nprint\n \n'Host    :'\n,\n \ngetpass\n.\ngetuser\n(),\n \n'@'\n,\n \nsocket\n.\ngethostname\n()\n\n\nuname\n \n=\n \nplatform\n.\nuname\n()\n\n\nprint\n \n\"System  :\"\n,\n \nuname\n[\n0\n],\n \nuname\n[\n2\n],\n \nuname\n[\n4\n]\n\n\nprint\n \n\"Version :\"\n,\n \nplatform\n.\npython_version\n()\n\n\nprint\n \n\"Program :\"\n,\n \nsys\n.\nexecutable\n\n\nprint\n \n'Script  :'\n,\n \nos\n.\npath\n.\nabspath\n(\n__file__\n)\n\n\nprint\n \n'Args    :'\n,\n \narguments",
            "title": "Exercise 1.3"
        },
        {
            "location": "/materials/htc/part1-ex3-jobs/#htc-exercise-13-run-jobs",
            "text": "The goal of this exercise is to submit jobs to HTCondor and have them run on the local pool (CHTC). This is a huge step in learning to use an HTC system!  This exercise will take longer than the first two, short ones. It is the essential part of this exercise time. If you are having any problems getting the jobs to run, please ask the instructors! It is very important that you know how to run jobs.",
            "title": "HTC Exercise 1.3: Run Jobs!"
        },
        {
            "location": "/materials/htc/part1-ex3-jobs/#running-your-first-job",
            "text": "Nearly all of the time, when you want to run an HTCondor job, you first write an HTCondor submit file for it. In this section, you will run the same  hostname  command as in Exercise 1.1, but where this command will run within a job on one of the 'execute' servers in CHTC's local HTCondor pool.  Here is a straightforward submit file for the  hostname  command:  executable = /bin/hostname\n\noutput = hostname.out\nerror = hostname.err\nlog = hostname.log\n\nrequest_cpus = 1\nrequest_memory = 1GB\nrequest_disk = 1MB\n\nqueue  Write those lines of text in a file named  hostname.sub .   Note  There is nothing magic about the name of an HTCondor submit file.\nIt can be any filename you want.\nIt's a good practice to always include the  .sub  extension, but it is not required.\nUltimately, a submit file is a text file   The lines of the submit file have the following meanings:           executable  The name of the program to run (relative to the directory from which you submit).    output  The filename where HTCondor will write the standard output from your job.    error  The filename where HTCondor will write the standard error from your job. This particular job is not likely to have any, but it is best to include this line for every job.    log  The filename where HTCondor will write information about your job run. While not required, it is a  really  good idea to have a log file for every job.    request_*  Tells HTCondor how many  cpus  and how much  memory  and  disk  we want, which is not much, because the 'hostname' executable is very small.    queue  Tells HTCondor to run your job with the settings above.     Note that we are not using the  arguments  or  transfer_input_files  lines that were mentioned during lecture because the  hostname  program is all that needs to be transferred from the submit server, and we want to run it without any additional options.  Double-check your submit file, so that it matches the text above. Then, tell HTCondor to run your job:  username@learn $  condor_submit hostname.sub Submitting job(s).  1 job(s) submitted to cluster NNNN.   The actual cluster number will be shown instead of  NNNN .  If, instead of the text above, there are error messages, read them carefully and then try to correct your submit file or ask for help.  Notice that  condor_submit  returns back to the shell prompt right away. It does  not  wait for your job to run. Instead, as soon as it has finished submitting your job into the queue, the submit command finishes.",
            "title": "Running Your First Job"
        },
        {
            "location": "/materials/htc/part1-ex3-jobs/#view-your-job-in-the-queue",
            "text": "Now, use  condor_q  and  condor_q -nobatch  to watch for your job in the queue!   You may not even catch the job in the  R  running state, because the  hostname  command runs very quickly. When the job itself is finished, it will 'leave' the queue and no longer be listed in the  condor_q  output.  After the job finishes, check for the  hostname  output in  hostname.out , which is where job information printed to the terminal screen will be printed for the job.  username@learn $  cat hostname.out e171.chtc.wisc.edu   The  hostname.err  file should be empty, unless there were issues running the  hostname  executable after it was transferred to the slot. The  hostname.log  is more complex and will be the focus of a later exercise.",
            "title": "View your job in the queue"
        },
        {
            "location": "/materials/htc/part1-ex3-jobs/#running-a-job-with-arguments",
            "text": "Very often, when you run a command on the command line, it includes arguments (i.e. options) after the program name, as in the below examples:  username@learn $  cat hostname.out username@learn $  sleep  60  username@learn $  dc -e  '6 7 * p'   In an HTCondor submit file, the program (or 'executable') name goes in the  executable  statement and  all remaining arguments  go into an  arguments  statement. For example, if the full command is:  username@learn $  sleep  60   Then in the submit file, we would put the location of the \"sleep\" program (you can find it with  which sleep ) as the job  executable , and  60  as the job  arguments :  executable = /bin/sleep\narguments = 60  For the command-line command:  username@learn $  dc -e  '6 7 * p'   We would put the following into the submit file, putting the  arguments  statement in quotes, since it contains single quotes:  executable = /usr/bin/dc\narguments = \"-e '6 7 * p'\"  Let\u2019s try a job submission with arguments. We will use the  sleep  command shown above, which simply does nothing for the specified number of seconds, then exits normally. It is convenient for simulating a job that takes a while to run.  Create a new submit file (you name it this time) and save the following text in it.  executable = /bin/sleep\narguments = 60\n\noutput = sleep.out\nerror = sleep.err\nlog = sleep.log\n\nrequest_cpus = 1\nrequest_memory = 1GB\nrequest_disk = 1MB\n\nqueue  Except for changing a few filenames, this submit file is nearly identical to the last one. But, see the extra  arguments  line?  Submit this new job. Again, watch for it to run using  condor_q  and  condor_q -nobatch ; \ncheck once every 15 seconds or so. \nOnce the job starts running, it will take about 1 minute to run (because of the  sleep  command, right?), \nso you should be able to see it running for a bit. \nWhen the job finishes, it will disappear from the queue, but there will be no output in the output or error files, because  sleep  does not produce any output.",
            "title": "Running a Job With Arguments"
        },
        {
            "location": "/materials/htc/part1-ex3-jobs/#running-a-script-job-from-the-submit-directory",
            "text": "So far, we have been running programs (executables) that come with the standard Linux system. \nMore frequently, you will want to run a program that exists within your directory \nor perhaps a shell script of commands that you'd like to run within a job. In this example, you will write a shell script and a submit file that runs the shell script within a job:    Put the following contents into a file named  test-script.sh :  #!/bin/sh  echo   'Date: '   ` date `   echo   'Host: '   ` hostname `   echo   'System: '   ` uname -spo `   echo   \"Program:  $0 \"   echo   \"Args:  $* \"  echo   'ls: '   ` ls `  # END     Add executable permissions to the file (so that it can be run as a program):  username@learn $  chmod +x test-script.sh    Test your script from the command line:  username@learn $  ./test-script.sh hello  42   Date: Mon Jul 17 10:02:20 CDT 2017   Host: learn.chtc.wisc.edu   System: Linux x86_64 GNU/Linux   Program: ./test-script.sh  Args: hello 42  ls: hostname.sub montage hostname.err hostname.log hostname.out test-script.sh   This step is  really  important! If you cannot run your executable from the command-line, HTCondor probably cannot run it on another machine, either. \nFurther, debugging problems like this one is surprisingly difficult. \nSo, if possible, test your  executable  and  arguments  as a command at the command-line first.    Write the submit file (this should be getting easier by now):  executable = test-script.sh\narguments = foo bar baz\n\noutput = script.out\nerror = script.err\nlog = script.log\n\nrequest_cpus = 1\nrequest_memory = 1GB\nrequest_disk = 1MB\n\nqueue  In this example, the  executable  that was named in the submit file did  not  start with a  / , \n    so the location of the file is relative to the submit directory itself. \n    In other words, in this format the executable must be in the same directory as the submit file.   Note  Blank lines between commands and spaces around the  =  do not matter to HTCondor.\nFor example, this submit file is equivalent to the one above:  executable = test-script.sh\narguments =  foo bar baz\noutput =     script.out\nerror =      script.err\nlog =        script.log\n\nrequest_cpus=1\nrequest_memory=1GB\nrequest_disk=1MB\n\nqueue  Use whitespace to make things clear to  you . \nWhat format do you prefer to read?     Submit the job, wait for it to finish, and check the output (and error, which should be empty).  What do you notice about the lines returned for \"Program\" and \"ls\"? Remember that only files pertaining\nto  this  job will be in the job working directory on the execute server. You're also seeing the effects\nof HTCondor's need to standardize some filenames when running your job, though they are named as you expect \nin the submission directory (per the submit file contents).",
            "title": "Running a Script Job From the Submit Directory"
        },
        {
            "location": "/materials/htc/part1-ex3-jobs/#extra-challenge",
            "text": "Note  There are Extra Challenges throughout the school curriculum. You may be better off coming back to these after you've completed all other exercises for your current working session.   Below is a Python script that does something similar to the shell script above. Run this Python script using HTCondor.  #!/usr/bin/env python  \"\"\"Extra Challenge for OSG User School  Written by Tim Cartwright  Submitted to CHTC by #YOUR_NAME#  \"\"\"  import   getpass  import   os  import   platform  import   socket  import   sys  import   time  arguments   =   None  if   len ( sys . argv )   >   1 : \n     arguments   =   '\"'   +   ' ' . join ( sys . argv [ 1 :])   +   '\"'  print   >>   sys . stderr ,   __doc__  print   'Time    :' ,   time . strftime ( '%Y-%m- %d  ( %a ) %H:%M:%S %Z' )  print   'Host    :' ,   getpass . getuser (),   '@' ,   socket . gethostname ()  uname   =   platform . uname ()  print   \"System  :\" ,   uname [ 0 ],   uname [ 2 ],   uname [ 4 ]  print   \"Version :\" ,   platform . python_version ()  print   \"Program :\" ,   sys . executable  print   'Script  :' ,   os . path . abspath ( __file__ )  print   'Args    :' ,   arguments",
            "title": "Extra Challenge"
        },
        {
            "location": "/materials/htc/part1-ex4-logs/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nHTC Exercise 1.4: Read and Interpret Log Files\n\u00b6\n\n\nThe goal of this exercise is to learn how to understand the contents of a job log file, which is where HTCondor describes the steps \ntaken to run your job.\nWhen things go wrong with your job, the log is the best place to look for first pointers (in addition to the .err file).\n\n\nThis exercise is short, but you'll want to at least read over it before moving on (and come back later, if you can't run through it now).\n\n\nReading a Log File\n\u00b6\n\n\nFor this exercise, we can examine a log file for any previous job that you have run. The example output below is based on the \nsleep 60\n job.\n\n\nA job log file is updated throughout the life of a job, usually at key events. Each event starts with a heading that indicates what happened and when. Here are \nall\n of the event headings from the \nsleep\n job log (detailed output in between headings has been omitted here):\n\n\n000 (5739.000.000) 2020-07-10 10:44:20 Job submitted from host: <128.104.100.43:9618?addrs=...>\n040 (5739.000.000) 2020-07-10 10:45:10 Started transferring input files\n040 (5739.000.000) 2020-07-10 10:45:10 Finished transferring input files\n001 (5739.000.000) 2020-07-10 10:45:11 Job executing on host: <128.104.55.42:9618?addrs=...>\n006 (5739.000.000) 2020-07-10 10:45:20 Image size of job updated: 72\n040 (5739.000.000) 2020-07-10 10:45:20 Started transferring output files\n040 (5739.000.000) 2020-07-10 10:45:20 Finished transferring output files\n006 (5739.000.000) 2020-07-10 10:46:11 Image size of job updated: 4072\n005 (5739.000.000) 2020-07-10 10:46:11 Job terminated.\n\n\n\n\n\nThere is a lot of extra information in those lines, but you can see:\n\n\n\n\nThe job ID: cluster 5739, process 0 (written \n000\n)\n\n\nThe date and local time of each event\n\n\nA brief description of the event: submission, execution, some information updates, and termination\n\n\n\n\nSome events provide no information in addition to the heading. For example:\n\n\n000 (5739.000.000) 2020-07-10 10:44:20 Job submitted from host: <128.104.100.43:9618?addrs=...>\n...\n\n\n\n\n\nand\n\n\n001 (5739.000.000) 2020-07-10 10:45:11 Job executing on host: <128.104.55.42:9618?addrs=...>\n...\n\n\n\n\n\n\n\nNote\n\n\nEach event ends with a line that contains only 3 dots: \n...\n\n\n\n\nBut the periodic information update event contains some additional information:\n\n\n006 (5739.000.000) 2020-07-10 10:45:20 Image size of job updated: 72\n    1  -  MemoryUsage of job (MB)\n    72  -  ResidentSetSize of job (KB)\n...\n\n\n\n\n\nThese updates record the amount of memory that the job is using on the execute machine. This can be helpful information, so that in future runs of the job, you can tell HTCondor how much memory you will need.\n\n\nThe job termination event includes a great deal of additional information:\n\n\n005 (5739.000.000) 2020-07-10 10:46:11 Job terminated.\n    (1) Normal termination (return value 0)\n        Usr 0 00:00:00, Sys 0 00:00:00  -  Run Remote Usage\n        Usr 0 00:00:00, Sys 0 00:00:00  -  Run Local Usage\n        Usr 0 00:00:00, Sys 0 00:00:00  -  Total Remote Usage\n        Usr 0 00:00:00, Sys 0 00:00:00  -  Total Local Usage\n    0  -  Run Bytes Sent By Job\n    27848  -  Run Bytes Received By Job\n    0  -  Total Bytes Sent By Job\n    27848  -  Total Bytes Received By Job\n    Partitionable Resources :    Usage  Request Allocated\n       Cpus                 :                 1         1\n       Disk (KB)            :       40       30   4203309\n       Memory (MB)          :        1        1         1\n...\n\n\n\n\n\nProbably the most interesting information is:\n\n\n\n\nThe \nreturn value\n (\n0\n here, means the executable completed and didn't indicate any internal errors; non-zero usually means failure)\n\n\nThe total number of bytes transferred each way, which could be useful if your network is slow\n\n\nThe \nPartitionable Resources\n table, especially disk and memory usage, which will inform larger submissions.\n\n\n\n\nThere are many other kinds of events, but the ones above will occur in almost every job log.\n\n\nUnderstanding When Job Log Events Are Written\n\u00b6\n\n\nWhen are events written to the job log file? Let\u2019s find out. Read through the entire procedure below before starting, because some parts of the process are time sensitive.\n\n\n\n\nChange the \nsleep\n job submit file, so that the job sleeps for 2 minutes (= 120 seconds)\n\n\nSubmit the updated sleep job\n\n\nAs soon as the \ncondor_submit\n command finishes, hit the return key a few times, to create some blank lines\n\n\n\n\nRight away, run a command to show the log file and \nkeep showing\n updates as they occur:\n\n\nusername@learn $\n tail -f sleep.log\n\n\n\n\n\n\n\n\n\nWatch the output carefully. When do events appear in the log file?\n\n\n\n\nAfter the termination event appears, press Control-C to end the \ntail\n command and return to the shell prompt.\n\n\n\n\nUnderstanding How HTCondor Writes Files\n\u00b6\n\n\nWhen HTCondor writes the output, error, and log files, does it erase the previous contents of the file or does it add new lines onto the end? Let\u2019s find out!\n\n\nFor this exercise, we can use the \nhostname\n job from earlier.\n\n\n\n\nEdit the \nhostname\n submit file so that it uses new and unique filenames for output, error, and log files.\n\nAlternatively, delete any existing output, error, and log files from previous runs of the \nhostname\n job.\n\n\nSubmit the job three separate times in a row (there are better ways to do this, which we will cover in the next lecture)\n\n\nWait for all three jobs to finish\n\n\nExamine the output file: How many hostnames are there? Did HTCondor erase the previous contents for each job, or add new lines?\n\n\nExamine the log file\u2026 carefully: What happened there? Pay close attention to the times and job IDs of the events.\n\n\n\n\nIf you have questions about how HTCondor handles these files, you could try finding relevant sections of the manual (this is hard and not as useful as one would hope), discuss it with neighbors or instructors, or ask questions at the end of this session.",
            "title": "Exercise 1.4"
        },
        {
            "location": "/materials/htc/part1-ex4-logs/#htc-exercise-14-read-and-interpret-log-files",
            "text": "The goal of this exercise is to learn how to understand the contents of a job log file, which is where HTCondor describes the steps \ntaken to run your job.\nWhen things go wrong with your job, the log is the best place to look for first pointers (in addition to the .err file).  This exercise is short, but you'll want to at least read over it before moving on (and come back later, if you can't run through it now).",
            "title": "HTC Exercise 1.4: Read and Interpret Log Files"
        },
        {
            "location": "/materials/htc/part1-ex4-logs/#reading-a-log-file",
            "text": "For this exercise, we can examine a log file for any previous job that you have run. The example output below is based on the  sleep 60  job.  A job log file is updated throughout the life of a job, usually at key events. Each event starts with a heading that indicates what happened and when. Here are  all  of the event headings from the  sleep  job log (detailed output in between headings has been omitted here):  000 (5739.000.000) 2020-07-10 10:44:20 Job submitted from host: <128.104.100.43:9618?addrs=...>\n040 (5739.000.000) 2020-07-10 10:45:10 Started transferring input files\n040 (5739.000.000) 2020-07-10 10:45:10 Finished transferring input files\n001 (5739.000.000) 2020-07-10 10:45:11 Job executing on host: <128.104.55.42:9618?addrs=...>\n006 (5739.000.000) 2020-07-10 10:45:20 Image size of job updated: 72\n040 (5739.000.000) 2020-07-10 10:45:20 Started transferring output files\n040 (5739.000.000) 2020-07-10 10:45:20 Finished transferring output files\n006 (5739.000.000) 2020-07-10 10:46:11 Image size of job updated: 4072\n005 (5739.000.000) 2020-07-10 10:46:11 Job terminated.  There is a lot of extra information in those lines, but you can see:   The job ID: cluster 5739, process 0 (written  000 )  The date and local time of each event  A brief description of the event: submission, execution, some information updates, and termination   Some events provide no information in addition to the heading. For example:  000 (5739.000.000) 2020-07-10 10:44:20 Job submitted from host: <128.104.100.43:9618?addrs=...>\n...  and  001 (5739.000.000) 2020-07-10 10:45:11 Job executing on host: <128.104.55.42:9618?addrs=...>\n...   Note  Each event ends with a line that contains only 3 dots:  ...   But the periodic information update event contains some additional information:  006 (5739.000.000) 2020-07-10 10:45:20 Image size of job updated: 72\n    1  -  MemoryUsage of job (MB)\n    72  -  ResidentSetSize of job (KB)\n...  These updates record the amount of memory that the job is using on the execute machine. This can be helpful information, so that in future runs of the job, you can tell HTCondor how much memory you will need.  The job termination event includes a great deal of additional information:  005 (5739.000.000) 2020-07-10 10:46:11 Job terminated.\n    (1) Normal termination (return value 0)\n        Usr 0 00:00:00, Sys 0 00:00:00  -  Run Remote Usage\n        Usr 0 00:00:00, Sys 0 00:00:00  -  Run Local Usage\n        Usr 0 00:00:00, Sys 0 00:00:00  -  Total Remote Usage\n        Usr 0 00:00:00, Sys 0 00:00:00  -  Total Local Usage\n    0  -  Run Bytes Sent By Job\n    27848  -  Run Bytes Received By Job\n    0  -  Total Bytes Sent By Job\n    27848  -  Total Bytes Received By Job\n    Partitionable Resources :    Usage  Request Allocated\n       Cpus                 :                 1         1\n       Disk (KB)            :       40       30   4203309\n       Memory (MB)          :        1        1         1\n...  Probably the most interesting information is:   The  return value  ( 0  here, means the executable completed and didn't indicate any internal errors; non-zero usually means failure)  The total number of bytes transferred each way, which could be useful if your network is slow  The  Partitionable Resources  table, especially disk and memory usage, which will inform larger submissions.   There are many other kinds of events, but the ones above will occur in almost every job log.",
            "title": "Reading a Log File"
        },
        {
            "location": "/materials/htc/part1-ex4-logs/#understanding-when-job-log-events-are-written",
            "text": "When are events written to the job log file? Let\u2019s find out. Read through the entire procedure below before starting, because some parts of the process are time sensitive.   Change the  sleep  job submit file, so that the job sleeps for 2 minutes (= 120 seconds)  Submit the updated sleep job  As soon as the  condor_submit  command finishes, hit the return key a few times, to create some blank lines   Right away, run a command to show the log file and  keep showing  updates as they occur:  username@learn $  tail -f sleep.log    Watch the output carefully. When do events appear in the log file?   After the termination event appears, press Control-C to end the  tail  command and return to the shell prompt.",
            "title": "Understanding When Job Log Events Are Written"
        },
        {
            "location": "/materials/htc/part1-ex4-logs/#understanding-how-htcondor-writes-files",
            "text": "When HTCondor writes the output, error, and log files, does it erase the previous contents of the file or does it add new lines onto the end? Let\u2019s find out!  For this exercise, we can use the  hostname  job from earlier.   Edit the  hostname  submit file so that it uses new and unique filenames for output, error, and log files. \nAlternatively, delete any existing output, error, and log files from previous runs of the  hostname  job.  Submit the job three separate times in a row (there are better ways to do this, which we will cover in the next lecture)  Wait for all three jobs to finish  Examine the output file: How many hostnames are there? Did HTCondor erase the previous contents for each job, or add new lines?  Examine the log file\u2026 carefully: What happened there? Pay close attention to the times and job IDs of the events.   If you have questions about how HTCondor handles these files, you could try finding relevant sections of the manual (this is hard and not as useful as one would hope), discuss it with neighbors or instructors, or ask questions at the end of this session.",
            "title": "Understanding How HTCondor Writes Files"
        },
        {
            "location": "/materials/htc/part1-ex5-request/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nHTC Exercise 1.5: Declare Resource Needs\n\u00b6\n\n\nThe goal of this exercise is to demonstrate how to test and tune the \nrequest_X\n statements in a submit file for when you don't know what resources your job needs.\n\n\nThere are three special resource request statements that you can use (optionally) in an HTCondor submit file:\n\n\n\n\nrequest_cpus\n for the number of CPUs your job will use (most softwares will take an argument to control this number, and it's usually otherwise \"1\")\n\n\nrequest_memory\n for the maximum amount of run-time memory your job may use\n\n\nrequest_disk\n for the maximum amount of disk space your job may use (including the executable and all other data that may show up during the job)\n\n\n\n\nHTCondor defaults to certain reasonable values for these request settings, so you do not need to use them to get \nsmall\n jobs to run. \nHowever, it is in \nYOUR\n best interest to always estimate resource requests before submitting any job, and to definitely tune your requests before submitting multiple jobs. In many HTCondor pools:\n\n\n\n\nIf your job goes over the request values, it may be removed from the execute machine and held (status 'H' in the \ncondor_q\n output, awaiting action on your part) without saving any partial job output files. So it is a disadvantage to not declare your resource needs or if you underestimate them. \n\n\nConversely, if you overestimate them by too much, your jobs will match to fewer slots, with a longer average wait time. Additionally, by hogging up resources that you don't need, other users may be deprived of the resources they require. In the long run, it works better for all users of the pool if you declare what you really need.\n\n\n\n\nBut how do you know what to request? In particular, we are concerned with memory and disk here; requesting multiple CPUs and using them is covered a bit in later school materials, but true HTC splits work up into jobs that each use as few CPU cores as possible (one CPU core is always best to have the most jobs running and completing soonest).\n\n\nDetermining Resource Needs Before Running Any Jobs\n\u00b6\n\n\n\n\nNote\n\n\nIf you are running short on time, you can skip to \"Determining Resource Needs By Running Test Jobs\", below, but try to come back and read over this part at some point.\n\n\n\n\nIt can be very difficult to predict the memory needs of your running program without running tests. Typically, the memory size of a job changes over time, making the task even trickier. \nIf you have knowledge ahead of time about your job\u2019s maximum memory needs, use that, or a maybe a number that's just a bit higher, to be safe. Worst case scenario, you can request a fairly large amount of memory (as high as what's on your laptop or other server, if you know your program can run without crashing) for a first test job, OR you can run the program locally and 'watch' it:\n\n\nExamining a Running Program on a Local Computer\n\u00b6\n\n\nWhen working on a shared submit server, you should not run computationally-intensive work because it can use resources needed by HTCondor to manage the queue for all uses. \nHowever, you may have access to other computers (your laptop, for example, or another server) where you can observe the memory usage of a program. The downside is that you'll have to watch a program run for essentially the entire time, to make sure you catch the maximum memory usage.\n\n\nFor Memory:\n\u00b6\n\n\nOn Mac and Windows, for example, the \"Activity Monitor\" and \"Task Manager\" applications may be useful. On a Mac or Linux system, you can use the \nps\n command or the \ntop\n command in the Terminal to watch a running program and see (roughly) how much memory it is using. Full coverage of these tools is beyond the scope of this exercise, but here are two quick examples:\n\n\nUsing \nps\n:\n\n\nusername@learn $\n ps ux\n\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n\n\ncat      24342  0.0  0.0  90224  1864 ?        S    13:39   0:00 sshd: cat@pts/0  \n\n\ncat      24343  0.0  0.0  66096  1580 pts/0    Ss   13:39   0:00 -bash\n\n\ncat      25864  0.0  0.0  65624   996 pts/0    R+   13:52   0:00 ps ux\n\n\ncat      30052  0.0  0.0  90720  2456 ?        S    Jun22   0:00 sshd: cat@pts/2  \n\n\ncat      30053  0.0  0.0  66096  1624 pts/2    Ss+  Jun22   0:00 -bash\n\n\n\n\n\n\nThe Resident Set Size (\nRSS\n) column, highlighted above, gives a rough indication of the memory usage (in KB) of each running process. If your program runs long enough, you can run this command several times and note the greatest value.\n\n\nUsing \ntop\n:\n\n\nusername@learn $\n top -u <USERNAME>\n\ntop - 13:55:31 up 11 days, 20:59,  5 users,  load average: 0.12, 0.12, 0.09\n\n\nTasks: 198 total,   1 running, 197 sleeping,   0 stopped,   0 zombie\n\n\nCpu(s):  1.2%us,  0.1%sy,  0.0%ni, 98.5%id,  0.2%wa,  0.0%hi,  0.1%si,  0.0%st\n\n\nMem:   4001440k total,  3558028k used,   443412k free,   258568k buffers\n\n\nSwap:  4194296k total,      148k used,  4194148k free,  2960760k cached\n\n\n\n  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND\n\n\n24342 cat       15   0 90224 1864 1096 S  0.0  0.0   0:00.26 sshd\n\n\n24343 cat       15   0 66096 1580 1232 S  0.0  0.0   0:00.07 bash\n\n\n25927 cat       15   0 12760 1196  836 R  0.0  0.0   0:00.01 top\n\n\n30052 cat       16   0 90720 2456 1112 S  0.0  0.1   0:00.69 sshd\n\n\n30053 cat       18   0 66096 1624 1236 S  0.0  0.0   0:00.37 bash\n\n\n\n\n\n\nThe \ntop\n command (shown here with an option to limit the output to a single user ID) also shows information about running processes, but updates periodically by itself. Type the letter \nq\n to quit the interactive display. Again, the highlighted \nRES\n column shows an approximation of memory usage.\n\n\nFor Disk:\n\u00b6\n\n\nDetermining disk needs may be a bit easier, because you can check on the size of files that a program is using while it runs. However, it is important to count all files that HTCondor counts to get an accurate size. HTCondor counts \neverything\n in your job sandbox toward your job\u2019s disk usage:\n\n\n\n\nThe executable itself\n\n\nAll \"input\" files (anything else that gets transferred TO the job, even if you don't think of it as \"input\")\n\n\nAll files created during the job (broadly defined as \"output\"), including the captured standard output and error files that you list in the submit file.\n\n\nAll temporary files created in the sandbox, even if they get deleted by the executable before it's done.\n\n\n\n\nIf you can run your program within a single directory on a local computer (not on the submit server), you should be able to view files and their sizes with the \nls\n and \ndu\n commands.\n\n\nDetermining Resource Needs By Running Test Jobs (BEST)\n\u00b6\n\n\nDespite the techniques mentioned above, by far the easiest approach to measuring your job\u2019s resource needs is to run one or a small number of sample jobs and have HTCondor itself tell you about the resources used during the runs.\n\n\nFor example, here is a strange Python script that does not do anything useful, but consumes some real resources while running:\n\n\n#!/usr/bin/env python\n\n\nimport\n \ntime\n\n\nimport\n \nos\n\n\nsize\n \n=\n \n1000000\n\n\nnumbers\n \n=\n \n[]\n\n\nfor\n \ni\n \nin\n \nxrange\n(\nsize\n):\n \nnumbers\n.\nappend\n(\nstr\n(\ni\n))\n\n\ntempfile\n \n=\n \nopen\n(\n'numbers.txt'\n,\n \n'w'\n)\n\n\ntempfile\n.\nwrite\n(\n' '\n.\njoin\n(\nnumbers\n))\n\n\ntempfile\n.\nclose\n()\n\n\ntime\n.\nsleep\n(\n60\n)\n\n\n\n\n\n\nWithout trying to figure out what this code does or how many resources it uses, create a submit file for it, \nand run it once with HTCondor, starting with somewhat high memory requests (\"1GB\" for memory and disk is a good starting point, unless you think the job will use far more).\nWhen it is done, examine the log file. In particular, we care about these lines:\n\n\n    Partitionable Resources :    Usage  Request Allocated\n       Cpus                 :                 1         1\n       Disk (KB)            :     6739  1048576   8022934\n       Memory (MB)          :        3     1024      1024\n\n\n\n\n\nSo, now we know that HTCondor saw that the job used 6,739 KB of disk (= about 6.5 MB) and 3 MB of memory!\n\n\nThis is a great technique for determining the real resource needs of your job. If you think resource needs vary from run to run, submit a few sample jobs and look at all the results. And it never hurts to round up your resource requests a little, just in case your job occasionally uses more resources.\n\n\nSetting Resource Requirements\n\u00b6\n\n\nOnce you know your job\u2019s resource requirements, it is easy to declare them in your submit file. For example, taking our results above as an example, we might slightly increase our requests above what was used, just to be safe:\n\n\nrequest_memory = 4MB  \n# rounded up from 3 MB\n\nrequest_disk = 7MB  \n# rounded up from 6.5 MB\n\n\n\n\n\n\nPay close attention to units:\n\n\n\n\nWithout explicit units, \nrequest_memory\n is in MB (megabytes)\n\n\nWithout explicit units, \nrequest_disk\n is in KB (kilobytes)\n\n\nAllowable units are \nKB\n (kilobytes), \nMB\n (megabytes), \nGB\n (gigabytes), and \nTB\n (terabytes)\n\n\n\n\nHTCondor translates these requirements into attributes that become part of the job's \nrequirements\n expression. However, do not put your CPU, memory, and disk requirements directly into the \nrequirements\n expression; use the \nrequest_XXX\n statements instead.\n\n\nIf you still have time in this working session, Add these requirements to your submit file for the Python script, rerun the job, and confirm in the log file that your requests were used.\n\n\nAfter changing the requirements in your submit file, did your job run successfully? If not, why?\n(Hint: HTCondor polls a job's resource use on a timer. How long are these jobs running for?)",
            "title": "Exercise 1.5"
        },
        {
            "location": "/materials/htc/part1-ex5-request/#htc-exercise-15-declare-resource-needs",
            "text": "The goal of this exercise is to demonstrate how to test and tune the  request_X  statements in a submit file for when you don't know what resources your job needs.  There are three special resource request statements that you can use (optionally) in an HTCondor submit file:   request_cpus  for the number of CPUs your job will use (most softwares will take an argument to control this number, and it's usually otherwise \"1\")  request_memory  for the maximum amount of run-time memory your job may use  request_disk  for the maximum amount of disk space your job may use (including the executable and all other data that may show up during the job)   HTCondor defaults to certain reasonable values for these request settings, so you do not need to use them to get  small  jobs to run. \nHowever, it is in  YOUR  best interest to always estimate resource requests before submitting any job, and to definitely tune your requests before submitting multiple jobs. In many HTCondor pools:   If your job goes over the request values, it may be removed from the execute machine and held (status 'H' in the  condor_q  output, awaiting action on your part) without saving any partial job output files. So it is a disadvantage to not declare your resource needs or if you underestimate them.   Conversely, if you overestimate them by too much, your jobs will match to fewer slots, with a longer average wait time. Additionally, by hogging up resources that you don't need, other users may be deprived of the resources they require. In the long run, it works better for all users of the pool if you declare what you really need.   But how do you know what to request? In particular, we are concerned with memory and disk here; requesting multiple CPUs and using them is covered a bit in later school materials, but true HTC splits work up into jobs that each use as few CPU cores as possible (one CPU core is always best to have the most jobs running and completing soonest).",
            "title": "HTC Exercise 1.5: Declare Resource Needs"
        },
        {
            "location": "/materials/htc/part1-ex5-request/#determining-resource-needs-before-running-any-jobs",
            "text": "Note  If you are running short on time, you can skip to \"Determining Resource Needs By Running Test Jobs\", below, but try to come back and read over this part at some point.   It can be very difficult to predict the memory needs of your running program without running tests. Typically, the memory size of a job changes over time, making the task even trickier. \nIf you have knowledge ahead of time about your job\u2019s maximum memory needs, use that, or a maybe a number that's just a bit higher, to be safe. Worst case scenario, you can request a fairly large amount of memory (as high as what's on your laptop or other server, if you know your program can run without crashing) for a first test job, OR you can run the program locally and 'watch' it:",
            "title": "Determining Resource Needs Before Running Any Jobs"
        },
        {
            "location": "/materials/htc/part1-ex5-request/#examining-a-running-program-on-a-local-computer",
            "text": "When working on a shared submit server, you should not run computationally-intensive work because it can use resources needed by HTCondor to manage the queue for all uses. \nHowever, you may have access to other computers (your laptop, for example, or another server) where you can observe the memory usage of a program. The downside is that you'll have to watch a program run for essentially the entire time, to make sure you catch the maximum memory usage.",
            "title": "Examining a Running Program on a Local Computer"
        },
        {
            "location": "/materials/htc/part1-ex5-request/#for-memory",
            "text": "On Mac and Windows, for example, the \"Activity Monitor\" and \"Task Manager\" applications may be useful. On a Mac or Linux system, you can use the  ps  command or the  top  command in the Terminal to watch a running program and see (roughly) how much memory it is using. Full coverage of these tools is beyond the scope of this exercise, but here are two quick examples:  Using  ps :  username@learn $  ps ux USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND  cat      24342  0.0  0.0  90224  1864 ?        S    13:39   0:00 sshd: cat@pts/0    cat      24343  0.0  0.0  66096  1580 pts/0    Ss   13:39   0:00 -bash  cat      25864  0.0  0.0  65624   996 pts/0    R+   13:52   0:00 ps ux  cat      30052  0.0  0.0  90720  2456 ?        S    Jun22   0:00 sshd: cat@pts/2    cat      30053  0.0  0.0  66096  1624 pts/2    Ss+  Jun22   0:00 -bash   The Resident Set Size ( RSS ) column, highlighted above, gives a rough indication of the memory usage (in KB) of each running process. If your program runs long enough, you can run this command several times and note the greatest value.  Using  top :  username@learn $  top -u <USERNAME> top - 13:55:31 up 11 days, 20:59,  5 users,  load average: 0.12, 0.12, 0.09  Tasks: 198 total,   1 running, 197 sleeping,   0 stopped,   0 zombie  Cpu(s):  1.2%us,  0.1%sy,  0.0%ni, 98.5%id,  0.2%wa,  0.0%hi,  0.1%si,  0.0%st  Mem:   4001440k total,  3558028k used,   443412k free,   258568k buffers  Swap:  4194296k total,      148k used,  4194148k free,  2960760k cached    PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND  24342 cat       15   0 90224 1864 1096 S  0.0  0.0   0:00.26 sshd  24343 cat       15   0 66096 1580 1232 S  0.0  0.0   0:00.07 bash  25927 cat       15   0 12760 1196  836 R  0.0  0.0   0:00.01 top  30052 cat       16   0 90720 2456 1112 S  0.0  0.1   0:00.69 sshd  30053 cat       18   0 66096 1624 1236 S  0.0  0.0   0:00.37 bash   The  top  command (shown here with an option to limit the output to a single user ID) also shows information about running processes, but updates periodically by itself. Type the letter  q  to quit the interactive display. Again, the highlighted  RES  column shows an approximation of memory usage.",
            "title": "For Memory:"
        },
        {
            "location": "/materials/htc/part1-ex5-request/#for-disk",
            "text": "Determining disk needs may be a bit easier, because you can check on the size of files that a program is using while it runs. However, it is important to count all files that HTCondor counts to get an accurate size. HTCondor counts  everything  in your job sandbox toward your job\u2019s disk usage:   The executable itself  All \"input\" files (anything else that gets transferred TO the job, even if you don't think of it as \"input\")  All files created during the job (broadly defined as \"output\"), including the captured standard output and error files that you list in the submit file.  All temporary files created in the sandbox, even if they get deleted by the executable before it's done.   If you can run your program within a single directory on a local computer (not on the submit server), you should be able to view files and their sizes with the  ls  and  du  commands.",
            "title": "For Disk:"
        },
        {
            "location": "/materials/htc/part1-ex5-request/#determining-resource-needs-by-running-test-jobs-best",
            "text": "Despite the techniques mentioned above, by far the easiest approach to measuring your job\u2019s resource needs is to run one or a small number of sample jobs and have HTCondor itself tell you about the resources used during the runs.  For example, here is a strange Python script that does not do anything useful, but consumes some real resources while running:  #!/usr/bin/env python  import   time  import   os  size   =   1000000  numbers   =   []  for   i   in   xrange ( size ):   numbers . append ( str ( i ))  tempfile   =   open ( 'numbers.txt' ,   'w' )  tempfile . write ( ' ' . join ( numbers ))  tempfile . close ()  time . sleep ( 60 )   Without trying to figure out what this code does or how many resources it uses, create a submit file for it, \nand run it once with HTCondor, starting with somewhat high memory requests (\"1GB\" for memory and disk is a good starting point, unless you think the job will use far more).\nWhen it is done, examine the log file. In particular, we care about these lines:      Partitionable Resources :    Usage  Request Allocated\n       Cpus                 :                 1         1\n       Disk (KB)            :     6739  1048576   8022934\n       Memory (MB)          :        3     1024      1024  So, now we know that HTCondor saw that the job used 6,739 KB of disk (= about 6.5 MB) and 3 MB of memory!  This is a great technique for determining the real resource needs of your job. If you think resource needs vary from run to run, submit a few sample jobs and look at all the results. And it never hurts to round up your resource requests a little, just in case your job occasionally uses more resources.",
            "title": "Determining Resource Needs By Running Test Jobs (BEST)"
        },
        {
            "location": "/materials/htc/part1-ex5-request/#setting-resource-requirements",
            "text": "Once you know your job\u2019s resource requirements, it is easy to declare them in your submit file. For example, taking our results above as an example, we might slightly increase our requests above what was used, just to be safe:  request_memory = 4MB   # rounded up from 3 MB \nrequest_disk = 7MB   # rounded up from 6.5 MB   Pay close attention to units:   Without explicit units,  request_memory  is in MB (megabytes)  Without explicit units,  request_disk  is in KB (kilobytes)  Allowable units are  KB  (kilobytes),  MB  (megabytes),  GB  (gigabytes), and  TB  (terabytes)   HTCondor translates these requirements into attributes that become part of the job's  requirements  expression. However, do not put your CPU, memory, and disk requirements directly into the  requirements  expression; use the  request_XXX  statements instead.  If you still have time in this working session, Add these requirements to your submit file for the Python script, rerun the job, and confirm in the log file that your requests were used.  After changing the requirements in your submit file, did your job run successfully? If not, why?\n(Hint: HTCondor polls a job's resource use on a timer. How long are these jobs running for?)",
            "title": "Setting Resource Requirements"
        },
        {
            "location": "/materials/htc/part1-ex6-remove/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nHTC Exercise 1.6: Remove Jobs From the Queue\n\u00b6\n\n\nThe goal of this exercise is to show you how to remove jobs from the queue. This is helpful if you make a mistake, do not want to wait for a job to complete, or otherwise need to fix things. For example, if some test jobs go on hold for using too much memory or disk, you may want to just remove them, edit the submit files, and then submit again.\n\n\nSkip this exercise and come back to it if you are short on time, or until you need to remove jobs for other exercises\n\n\n\n\nNote\n\n\nPlease remember to remove any jobs from the queue that you have given up on. Otherwise, the queue will start to get very long with jobs that will waste resources (and decrease your priority), or that may never run (if they're on hold, or have other issues keeping them from matching).\n\n\n\n\nThis exercise is very short, but if you are out of time, you can come back to it later.\n\n\nRemoving a Job or Cluster From the Queue\n\u00b6\n\n\nTo practice removing jobs from the queue, you need a job in the queue!\n\n\n\n\nSubmit a job from an earlier exercise\n\n\nDetermine the job ID (\ncluster.process\n) from the \ncondor_submit\n output or from \ncondor_q\n\n\n\n\nRemove the job:\n\n\nusername@learn $\n condor_rm <JOB.ID>\n\n\n\n\n\nUse the full job ID this time, e.g. \n5759.0\n.\n\n\n\n\n\n\nDid the job leave the queue immediately? If not, about how long did it take?\n\n\n\n\n\n\nSo far, we have created job clusters that contain only one job process (the \n.0\n part of the job ID). That will change soon, so it is good to know how to remove a specific job ID. However, it is possible to remove all jobs that are part of a cluster at once. Simply omit the job process (the \n.0\n part of the job ID) in the \ncondor_rm\n command:\n\n\nusername@learn $\n condor_rm <CLUSTER>\n\n\n\n\n\nFinally, you can include many job clusters and full job IDs in a single \ncondor_rm\n command. For example:\n\n\nusername@learn $\n condor_rm \n5768\n \n5769\n \n5770\n.0 \n5771\n.2\n\n\n\n\n\nRemoving All of Your Jobs\n\u00b6\n\n\nIf you really want to remove all of your jobs at once, you can do that with:\n\n\nusername@learn $\n condor_rm <USERNAME>\n\n\n\n\n\nIf you want to test it: (optional, though you'll likely need this in the future)\n\n\n\n\nQuickly submit several jobs from past exercises\n\n\nView the jobs in the queue with \ncondor_q\n\n\nRemove them all with the above command\n\n\nUse \ncondor_q\n to track progress\n\n\n\n\nIn case you are wondering, you can remove only your own jobs.\nHTCondor administrators can remove anyone\u2019s jobs, so be nice to them.",
            "title": "Exercise 1.6"
        },
        {
            "location": "/materials/htc/part1-ex6-remove/#htc-exercise-16-remove-jobs-from-the-queue",
            "text": "The goal of this exercise is to show you how to remove jobs from the queue. This is helpful if you make a mistake, do not want to wait for a job to complete, or otherwise need to fix things. For example, if some test jobs go on hold for using too much memory or disk, you may want to just remove them, edit the submit files, and then submit again.  Skip this exercise and come back to it if you are short on time, or until you need to remove jobs for other exercises   Note  Please remember to remove any jobs from the queue that you have given up on. Otherwise, the queue will start to get very long with jobs that will waste resources (and decrease your priority), or that may never run (if they're on hold, or have other issues keeping them from matching).   This exercise is very short, but if you are out of time, you can come back to it later.",
            "title": "HTC Exercise 1.6: Remove Jobs From the Queue"
        },
        {
            "location": "/materials/htc/part1-ex6-remove/#removing-a-job-or-cluster-from-the-queue",
            "text": "To practice removing jobs from the queue, you need a job in the queue!   Submit a job from an earlier exercise  Determine the job ID ( cluster.process ) from the  condor_submit  output or from  condor_q   Remove the job:  username@learn $  condor_rm <JOB.ID>  Use the full job ID this time, e.g.  5759.0 .    Did the job leave the queue immediately? If not, about how long did it take?    So far, we have created job clusters that contain only one job process (the  .0  part of the job ID). That will change soon, so it is good to know how to remove a specific job ID. However, it is possible to remove all jobs that are part of a cluster at once. Simply omit the job process (the  .0  part of the job ID) in the  condor_rm  command:  username@learn $  condor_rm <CLUSTER>  Finally, you can include many job clusters and full job IDs in a single  condor_rm  command. For example:  username@learn $  condor_rm  5768   5769   5770 .0  5771 .2",
            "title": "Removing a Job or Cluster From the Queue"
        },
        {
            "location": "/materials/htc/part1-ex6-remove/#removing-all-of-your-jobs",
            "text": "If you really want to remove all of your jobs at once, you can do that with:  username@learn $  condor_rm <USERNAME>  If you want to test it: (optional, though you'll likely need this in the future)   Quickly submit several jobs from past exercises  View the jobs in the queue with  condor_q  Remove them all with the above command  Use  condor_q  to track progress   In case you are wondering, you can remove only your own jobs.\nHTCondor administrators can remove anyone\u2019s jobs, so be nice to them.",
            "title": "Removing All of Your Jobs"
        },
        {
            "location": "/materials/htc/part1-ex7-compile/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nHTC Bonus Exercise 1.7: Compile and Run Some C Code\n\u00b6\n\n\nThe goal of this exercise is to show that compiled code works just fine in HTCondor. It is mainly of interest to people who have their own C code to run (or C++, or really any compiled code, although Java would be handled a bit differently).\n\n\nPreparing a C Executable\n\u00b6\n\n\nWhen preparing a C program for HTCondor, it is best to compile and link the executable statically, so that it does not depend on external libraries and their particular versions. Why is this important? When your compiled C program is sent to another machine for execution, that machine may not have the same libraries that you have on your submit machine (or wherever you compile the program). If the libraries are not available or are the wrong versions, your program may fail or, perhaps worse, silently produce the wrong results.\n\n\nHere is a simple C program to try using (thanks, Alain Roy):\n\n\n#include\n \n<stdio.h>\n\n\n\nint\n \nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n \nsleep_time\n;\n\n    \nint\n \ninput\n;\n\n    \nint\n \nfailure\n;\n\n\n    \nif\n \n(\nargc\n \n!=\n \n3\n)\n \n{\n\n        \nprintf\n(\n\"Usage: simple <sleep-time> <integer>\n\\n\n\"\n);\n\n        \nfailure\n \n=\n \n1\n;\n\n    \n}\n \nelse\n \n{\n\n        \nsleep_time\n \n=\n \natoi\n(\nargv\n[\n1\n]);\n\n        \ninput\n      \n=\n \natoi\n(\nargv\n[\n2\n]);\n\n\n        \nprintf\n(\n\"Thinking really hard for %d seconds...\n\\n\n\"\n,\n \nsleep_time\n);\n\n        \nsleep\n(\nsleep_time\n);\n\n        \nprintf\n(\n\"We calculated: %d\n\\n\n\"\n,\n \ninput\n \n*\n \n2\n);\n\n        \nfailure\n \n=\n \n0\n;\n\n    \n}\n\n    \nreturn\n \nfailure\n;\n\n\n}\n\n\n\n\n\n\nSave that code to a file, for example, \nsimple.c\n.\n\n\nCompile the program with static linking:\n\n\nusername@learn $\n gcc -static -o simple simple.c\n\n\n\n\n\nAs always, test that you can run your command from the command line first. First, without arguments to make sure it fails correctly:\n\n\nusername@learn $\n ./simple\n\n\n\n\n\nand then with valid arguments:\n\n\nusername@learn $\n ./simple \n5\n \n21\n\n\n\n\n\n\nRunning a Compiled C Program\n\u00b6\n\n\nRunning the compiled program is no different than running any other program. Here is a submit file for the C program (call it simple.sub):\n\n\nexecutable = simple\narguments = \"60 64\"\n\noutput = c-program.out\nerror = c-program.err\nlog = c-program.log\n\nshould_transfer_files = YES\nwhen_to_transfer_output = ON_EXIT\n\nrequest_cpus = 1\nrequest_memory = 1GB\nrequest_disk = 1MB\n\nqueue\n\n\n\n\n\nThen submit the job as usual!\n\n\nIn summary, it is easy to work with statically linked compiled code.\nIt \nis\n possible to handle dynamically linked compiled code, but it is trickier.\nWe will only mention this topic briefly during the lecture on Software.",
            "title": "Bonus Exercise 1.7"
        },
        {
            "location": "/materials/htc/part1-ex7-compile/#htc-bonus-exercise-17-compile-and-run-some-c-code",
            "text": "The goal of this exercise is to show that compiled code works just fine in HTCondor. It is mainly of interest to people who have their own C code to run (or C++, or really any compiled code, although Java would be handled a bit differently).",
            "title": "HTC Bonus Exercise 1.7: Compile and Run Some C Code"
        },
        {
            "location": "/materials/htc/part1-ex7-compile/#preparing-a-c-executable",
            "text": "When preparing a C program for HTCondor, it is best to compile and link the executable statically, so that it does not depend on external libraries and their particular versions. Why is this important? When your compiled C program is sent to another machine for execution, that machine may not have the same libraries that you have on your submit machine (or wherever you compile the program). If the libraries are not available or are the wrong versions, your program may fail or, perhaps worse, silently produce the wrong results.  Here is a simple C program to try using (thanks, Alain Roy):  #include   <stdio.h>  int   main ( int   argc ,   char   ** argv )  { \n     int   sleep_time ; \n     int   input ; \n     int   failure ; \n\n     if   ( argc   !=   3 )   { \n         printf ( \"Usage: simple <sleep-time> <integer> \\n \" ); \n         failure   =   1 ; \n     }   else   { \n         sleep_time   =   atoi ( argv [ 1 ]); \n         input        =   atoi ( argv [ 2 ]); \n\n         printf ( \"Thinking really hard for %d seconds... \\n \" ,   sleep_time ); \n         sleep ( sleep_time ); \n         printf ( \"We calculated: %d \\n \" ,   input   *   2 ); \n         failure   =   0 ; \n     } \n     return   failure ;  }   Save that code to a file, for example,  simple.c .  Compile the program with static linking:  username@learn $  gcc -static -o simple simple.c  As always, test that you can run your command from the command line first. First, without arguments to make sure it fails correctly:  username@learn $  ./simple  and then with valid arguments:  username@learn $  ./simple  5   21",
            "title": "Preparing a C Executable"
        },
        {
            "location": "/materials/htc/part1-ex7-compile/#running-a-compiled-c-program",
            "text": "Running the compiled program is no different than running any other program. Here is a submit file for the C program (call it simple.sub):  executable = simple\narguments = \"60 64\"\n\noutput = c-program.out\nerror = c-program.err\nlog = c-program.log\n\nshould_transfer_files = YES\nwhen_to_transfer_output = ON_EXIT\n\nrequest_cpus = 1\nrequest_memory = 1GB\nrequest_disk = 1MB\n\nqueue  Then submit the job as usual!  In summary, it is easy to work with statically linked compiled code.\nIt  is  possible to handle dynamically linked compiled code, but it is trickier.\nWe will only mention this topic briefly during the lecture on Software.",
            "title": "Running a Compiled C Program"
        },
        {
            "location": "/materials/htc/part2-ex1-files/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nHTC Exercise 2.1: Work With Input and Output Files\n\u00b6\n\n\nThe goal of this exercise is make input files available to your job on the execute machine, and return output files back. This small change significantly adds to the kinds of jobs that you can run.\n\n\nViewing a Job Sandbox\n\u00b6\n\n\nBefore you learn to transfer files to and from your job, it is good to understand a bit more about the environment in which your job runs.\nWhen the HTCondor \nstarter\n process prepares to run your job, it creates a new directory for your job and all of its files.\nWe call this directory the \njob sandbox\n, because it is your job\u2019s private space to play.\nLet\u2019s see what is in the job sandbox for a minimal job with no special input or output files.\n\n\n\n\n\n\nSave the script below in a file named \nsandbox.sh\n:\n\n\n#!/bin/sh\n\n\necho\n \n'Date: '\n \n`\ndate\n`\n\n\necho\n \n'Host: '\n \n`\nhostname\n`\n \n\necho\n \n'Sandbox: '\n \n`\npwd\n`\n \nls -alF\n\n# END\n\n\n\n\n\n\n\n\n\n\nCreate a submit file for this script and submit it.\n\n\n\n\nWhen the job finishes, look at the contents of the output file.\n\n\n\n\nIn the output file, note the \nSandbox:\n line: That is the full path to your job sandbox for the run. It was created just for your job, and it was removed as soon as your job finished.\n\n\nNext, look at the output that appears after the \nSandbox:\n line; it is the output from the \nls\n command in the script. It shows all of the files in your job sandbox, as they existed at the end of the execution of \nsandbox.sh\n. The files are:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.chirp.config\n\n\nConfiguration for an advanced feature\n\n\n\n\n\n\n.job.ad\n\n\nThe job ClassAd\n\n\n\n\n\n\n.machine.ad\n\n\nThe machine ClassAd\n\n\n\n\n\n\n_condor_stderr\n\n\nSaved standard error from the job\n\n\n\n\n\n\n_condor_stdout\n\n\nSaved standard output from the job\n\n\n\n\n\n\ncondor_exec.exe\n\n\nThe executable, renamed from \nsandbox.sh\n\n\n\n\n\n\ntmp/\n, \nvar/tmp/\n\n\nDirectories in which to put temporary files\n\n\n\n\n\n\n\n\nSo, HTCondor wrote copies of the job and machine ads (for use by the job, if desired), transferred your executable (\nsandbox.sh\n), renamed it (\ncondor_exec.exe\n), ran it, and saved its standard output and standard error into files. Notice that your submit file, which was in the same directory on the submit machine as your executable, was \nnot\n transferred, nor were any other files that happened to be in directory with the submit file.\n\n\nNow that we know something about the sandbox, we can transfer more files to and from it.\n\n\nRunning a Job With Input Files\n\u00b6\n\n\nNext, you will run a job that requires an input file. Remember, the initial job sandbox will contain only the renamed job executable, unless you tell HTCondor explicitly about every other file that needs to be transferred. Fortunately, this is easy.\n\n\nHere is a Python script that takes the name of an input file (containing one word per line) from the command line, counts the number of times each (lowercased) word occurs in the text, and prints out the final list of words and their counts.\n\n\n#!/usr/bin/env python\n\n\n\nimport\n \nos\n\n\nimport\n \nsys\n\n\n\nif\n \nlen\n(\nsys\n.\nargv\n)\n \n!=\n \n2\n:\n\n    \nprint\n \n'Usage: \n%s\n DATA'\n \n%\n \n(\nos\n.\npath\n.\nbasename\n(\nsys\n.\nargv\n[\n0\n]))\n\n    \nsys\n.\nexit\n(\n1\n)\n\n\ninput_filename\n \n=\n \nsys\n.\nargv\n[\n1\n]\n\n\n\nwords\n \n=\n \n{}\n\n\n\nmy_file\n \n=\n \nopen\n(\ninput_filename\n,\n \n'r'\n)\n\n\nfor\n \nline\n \nin\n \nmy_file\n:\n\n    \nword\n \n=\n \nline\n.\nstrip\n()\n.\nlower\n()\n\n    \nif\n \nword\n \nin\n \nwords\n:\n\n        \nwords\n[\nword\n]\n \n+=\n \n1\n\n    \nelse\n:\n\n        \nwords\n[\nword\n]\n \n=\n \n1\n\n\nmy_file\n.\nclose\n()\n\n\n\nfor\n \nword\n \nin\n \nsorted\n(\nwords\n.\nkeys\n()):\n\n    \nprint\n \n'\n%8d\n \n%s\n'\n \n%\n \n(\nwords\n[\nword\n],\n \nword\n)\n\n\n\n\n\n\n\n\nSave the Python script in a file named \nfreq.py\n.\n\n\n\n\nDownload the input file for the script (263K lines, ~1.4 MB) and save it in your submit directory:\n\n\nusername@learn $\n wget http://proxy.chtc.wisc.edu/SQUID/osgschool20/intro-2.1-words.txt\n\n\n\n\n\n\n\n\n\nCreate a submit file for the \nfreq.py\n executable.\n\n\n\n\n\n\nAdd a line to tell HTCondor to transfer the input file:\n\n\ntransfer_input_files = intro-2.1-words.txt\n\n\n\n\n\nAs with all submit file commands, it does not matter where this line goes, as long as it comes before the word \nqueue\n.\n\n\n\n\n\n\nDo not forget to add a line to name the input file as the argument to the Python script.\n\n\n\n\nSubmit the job, wait for it to finish, and check the output!\n\n\n\n\nIf things do not work the first time, keep trying! At this point in the exercises, we are telling you less and less explicitly how to do steps that you have done before. If you get stuck, ask for help in the #intro-to-htc Slack channel.\n\n\n\n\nNote\n\n\nIf you want to transfer more than one input file, list all of them on a single \ntransfer_input_files\n command,\nseparated by commas.\nFor example, if there are three input files:\n\n\ntransfer_input_files = a.txt, b.txt, c.txt\n\n\n\n\n\n\n\nTransferring Output Files\n\u00b6\n\n\nSo far, we have relied on programs that send their output to the standard output and error streams, which HTCondor captures, saves, and returns back to the submit directory. But what if your program writes one or more files for its output? How do you tell HTCondor to bring them back?\n\n\nLet\u2019s start by exploring what happens to files that a job creates in the sandbox.\nWe will use a very simple method for creating a new file: we will copy an input file to another name.\n\n\n\n\nFind or create a small input file (it is fine to use any small file from a previous exercise).\n\n\nCreate a submit file that transfers the input file and copies it to another name (as if doing \n/bin/cp input.txt output.txt\n on the command line)\n\n\nMake the output filename different than any filenames that are in your submit directory\n\n\nWhat is the \nexecutable\n line?\n\n\nWhat is the \narguments\n line?\n\n\nHow do you tell HTCondor to transfer the input file?\n\n\nAs always, use \noutput\n, \nerror\n, and \nlog\n filenames that are different from previous exercises\n\n\n\n\n\n\nSubmit the job and wait for it to finish.\n\n\n\n\nWhat happened? Can you tell what HTCondor did with the output file that was created (did it end up back on the submit server?), after it was created in the job sandbox? Look carefully at the list of files in your submit directory now.\n\n\nTransferring Specific Output Files\n\u00b6\n\n\nAs you saw in the last exercise, by default HTCondor transfers files that are created in the job sandbox back to the submit directory when the job finishes. In fact, HTCondor will also transfer back \nchanged\n input files, too. But, this only works for files that are in the top-level sandbox directory, and \nnot\n for ones contained in subdirectories.\n\n\nWhat if you want to bring back only \nsome\n output files, or output files contained in subdirectories?\n\n\nHere is a shell script that creates several files, including a copy of an input file in a new subdirectory:\n\n\n#!/bin/sh\n\n\nif\n \n[\n \n$#\n -ne \n1\n \n]\n;\n \nthen\n \necho\n \n\"Usage: \n$0\n INPUT\"\n;\n \nexit\n \n1\n;\n \nfi\n\ndate > output-timestamp.txt\ncal > output-calendar.txt\nmkdir subdirectory\ncp \n$1\n subdirectory/backup-\n$1\n\n\n\n\n\n\nFirst, let\u2019s confirm that HTCondor does not bring back the output file in the subdirectory:\n\n\n\n\nSave the shell script in a file named \noutput.sh\n.\n\n\nWrite a submit file that transfers an input file and runs \noutput.sh\n on it (passing the filename as an argument).\n\n\nSubmit the job, wait for it to finish, and examine the contents of your submit directory.\n\n\n\n\nSuppose you decide that you want only the timestamp output file and all files in the subdirectory, but not the calendar output file. You can tell HTCondor to transfer these specific files:\n\n\ntransfer_output_files = output-timestamp.txt, subdirectory/\n\n\n\n\n\n\n\nNote\n\n\nSee the trailing slash (\n/\n) on the subdirectory?\nThat tells HTCondor to transfer back \nthe files\n contained in the subdirectory, but not the directory itself;\nthe files will be written directly into the submit directory.\nIf you want HTCondor to transfer back an entire directory, leave off the trailing slash.\n\n\n\n\n\n\nRemove all output files from the previous run, including \noutput-timestamp.txt\n and \noutput-calendar.txt\n.\n\n\nCopy the previous submit file that ran \noutput.sh\n and add the \ntransfer_output_files\n line from above.\n\n\nSubmit the job, wait for it to finish, and examine the contents of your submit directory.\n\n\n\n\nDid it work as you expected?\n\n\nThinking About Progress So Far\n\u00b6\n\n\nAt this point, you can do just about everything that you need in order to run jobs on a local HTC pool. You can identify the executable, arguments, and input files, and you can get output back from the job. This is a big achievement!\n\n\nIn some ways, everything after this exercise shows you how to submit multiple jobs at once and makes it easier to run certain kinds of jobs and deal with certain kinds of situations.\n\n\nReferences\n\u00b6\n\n\nThere are many more details about HTCondor\u2019s file transfer mechanism not covered here. For more information, read the \n\"Submitting Jobs Without a Shared Filesystem\"\n of the HTCondor Manual.",
            "title": "Exercise 2.1"
        },
        {
            "location": "/materials/htc/part2-ex1-files/#htc-exercise-21-work-with-input-and-output-files",
            "text": "The goal of this exercise is make input files available to your job on the execute machine, and return output files back. This small change significantly adds to the kinds of jobs that you can run.",
            "title": "HTC Exercise 2.1: Work With Input and Output Files"
        },
        {
            "location": "/materials/htc/part2-ex1-files/#viewing-a-job-sandbox",
            "text": "Before you learn to transfer files to and from your job, it is good to understand a bit more about the environment in which your job runs.\nWhen the HTCondor  starter  process prepares to run your job, it creates a new directory for your job and all of its files.\nWe call this directory the  job sandbox , because it is your job\u2019s private space to play.\nLet\u2019s see what is in the job sandbox for a minimal job with no special input or output files.    Save the script below in a file named  sandbox.sh :  #!/bin/sh  echo   'Date: '   ` date `  echo   'Host: '   ` hostname `   echo   'Sandbox: '   ` pwd `  \nls -alF # END     Create a submit file for this script and submit it.   When the job finishes, look at the contents of the output file.   In the output file, note the  Sandbox:  line: That is the full path to your job sandbox for the run. It was created just for your job, and it was removed as soon as your job finished.  Next, look at the output that appears after the  Sandbox:  line; it is the output from the  ls  command in the script. It shows all of the files in your job sandbox, as they existed at the end of the execution of  sandbox.sh . The files are:           .chirp.config  Configuration for an advanced feature    .job.ad  The job ClassAd    .machine.ad  The machine ClassAd    _condor_stderr  Saved standard error from the job    _condor_stdout  Saved standard output from the job    condor_exec.exe  The executable, renamed from  sandbox.sh    tmp/ ,  var/tmp/  Directories in which to put temporary files     So, HTCondor wrote copies of the job and machine ads (for use by the job, if desired), transferred your executable ( sandbox.sh ), renamed it ( condor_exec.exe ), ran it, and saved its standard output and standard error into files. Notice that your submit file, which was in the same directory on the submit machine as your executable, was  not  transferred, nor were any other files that happened to be in directory with the submit file.  Now that we know something about the sandbox, we can transfer more files to and from it.",
            "title": "Viewing a Job Sandbox"
        },
        {
            "location": "/materials/htc/part2-ex1-files/#running-a-job-with-input-files",
            "text": "Next, you will run a job that requires an input file. Remember, the initial job sandbox will contain only the renamed job executable, unless you tell HTCondor explicitly about every other file that needs to be transferred. Fortunately, this is easy.  Here is a Python script that takes the name of an input file (containing one word per line) from the command line, counts the number of times each (lowercased) word occurs in the text, and prints out the final list of words and their counts.  #!/usr/bin/env python  import   os  import   sys  if   len ( sys . argv )   !=   2 : \n     print   'Usage:  %s  DATA'   %   ( os . path . basename ( sys . argv [ 0 ])) \n     sys . exit ( 1 )  input_filename   =   sys . argv [ 1 ]  words   =   {}  my_file   =   open ( input_filename ,   'r' )  for   line   in   my_file : \n     word   =   line . strip () . lower () \n     if   word   in   words : \n         words [ word ]   +=   1 \n     else : \n         words [ word ]   =   1  my_file . close ()  for   word   in   sorted ( words . keys ()): \n     print   ' %8d   %s '   %   ( words [ word ],   word )    Save the Python script in a file named  freq.py .   Download the input file for the script (263K lines, ~1.4 MB) and save it in your submit directory:  username@learn $  wget http://proxy.chtc.wisc.edu/SQUID/osgschool20/intro-2.1-words.txt    Create a submit file for the  freq.py  executable.    Add a line to tell HTCondor to transfer the input file:  transfer_input_files = intro-2.1-words.txt  As with all submit file commands, it does not matter where this line goes, as long as it comes before the word  queue .    Do not forget to add a line to name the input file as the argument to the Python script.   Submit the job, wait for it to finish, and check the output!   If things do not work the first time, keep trying! At this point in the exercises, we are telling you less and less explicitly how to do steps that you have done before. If you get stuck, ask for help in the #intro-to-htc Slack channel.   Note  If you want to transfer more than one input file, list all of them on a single  transfer_input_files  command,\nseparated by commas.\nFor example, if there are three input files:  transfer_input_files = a.txt, b.txt, c.txt",
            "title": "Running a Job With Input Files"
        },
        {
            "location": "/materials/htc/part2-ex1-files/#transferring-output-files",
            "text": "So far, we have relied on programs that send their output to the standard output and error streams, which HTCondor captures, saves, and returns back to the submit directory. But what if your program writes one or more files for its output? How do you tell HTCondor to bring them back?  Let\u2019s start by exploring what happens to files that a job creates in the sandbox.\nWe will use a very simple method for creating a new file: we will copy an input file to another name.   Find or create a small input file (it is fine to use any small file from a previous exercise).  Create a submit file that transfers the input file and copies it to another name (as if doing  /bin/cp input.txt output.txt  on the command line)  Make the output filename different than any filenames that are in your submit directory  What is the  executable  line?  What is the  arguments  line?  How do you tell HTCondor to transfer the input file?  As always, use  output ,  error , and  log  filenames that are different from previous exercises    Submit the job and wait for it to finish.   What happened? Can you tell what HTCondor did with the output file that was created (did it end up back on the submit server?), after it was created in the job sandbox? Look carefully at the list of files in your submit directory now.",
            "title": "Transferring Output Files"
        },
        {
            "location": "/materials/htc/part2-ex1-files/#transferring-specific-output-files",
            "text": "As you saw in the last exercise, by default HTCondor transfers files that are created in the job sandbox back to the submit directory when the job finishes. In fact, HTCondor will also transfer back  changed  input files, too. But, this only works for files that are in the top-level sandbox directory, and  not  for ones contained in subdirectories.  What if you want to bring back only  some  output files, or output files contained in subdirectories?  Here is a shell script that creates several files, including a copy of an input file in a new subdirectory:  #!/bin/sh  if   [   $#  -ne  1   ] ;   then   echo   \"Usage:  $0  INPUT\" ;   exit   1 ;   fi \ndate > output-timestamp.txt\ncal > output-calendar.txt\nmkdir subdirectory\ncp  $1  subdirectory/backup- $1   First, let\u2019s confirm that HTCondor does not bring back the output file in the subdirectory:   Save the shell script in a file named  output.sh .  Write a submit file that transfers an input file and runs  output.sh  on it (passing the filename as an argument).  Submit the job, wait for it to finish, and examine the contents of your submit directory.   Suppose you decide that you want only the timestamp output file and all files in the subdirectory, but not the calendar output file. You can tell HTCondor to transfer these specific files:  transfer_output_files = output-timestamp.txt, subdirectory/   Note  See the trailing slash ( / ) on the subdirectory?\nThat tells HTCondor to transfer back  the files  contained in the subdirectory, but not the directory itself;\nthe files will be written directly into the submit directory.\nIf you want HTCondor to transfer back an entire directory, leave off the trailing slash.    Remove all output files from the previous run, including  output-timestamp.txt  and  output-calendar.txt .  Copy the previous submit file that ran  output.sh  and add the  transfer_output_files  line from above.  Submit the job, wait for it to finish, and examine the contents of your submit directory.   Did it work as you expected?",
            "title": "Transferring Specific Output Files"
        },
        {
            "location": "/materials/htc/part2-ex1-files/#thinking-about-progress-so-far",
            "text": "At this point, you can do just about everything that you need in order to run jobs on a local HTC pool. You can identify the executable, arguments, and input files, and you can get output back from the job. This is a big achievement!  In some ways, everything after this exercise shows you how to submit multiple jobs at once and makes it easier to run certain kinds of jobs and deal with certain kinds of situations.",
            "title": "Thinking About Progress So Far"
        },
        {
            "location": "/materials/htc/part2-ex1-files/#references",
            "text": "There are many more details about HTCondor\u2019s file transfer mechanism not covered here. For more information, read the  \"Submitting Jobs Without a Shared Filesystem\"  of the HTCondor Manual.",
            "title": "References"
        },
        {
            "location": "/materials/htc/part2-ex2-queue-n/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nHTC Exercise 2.2: Use queue \nN\n, $(Cluster), and $(Process)\n\u00b6\n\n\nThe goal of the next several exercises is\nto learn to submit many jobs from a single \nqueue\n statement,\nand to control things like filenames and arguments on a per-job basis when doing so.\n\n\nSuppose you have a program that you want to run many times with different arguments each time. With what you know so far, you have a couple of choices:\n\n\n\n\nWrite one submit file; submit one job, change the argument in the submit file, submit another job, change the submit file, \u2026\n\n\nWrite many submit files that are nearly identical except for the program argument\n\n\n\n\nNeither of these options seems very satisfying. Fortunately, we can do better with HTCondor.\n\n\nRunning Many Jobs With One queue Statement\n\u00b6\n\n\nHere is a C program that uses a stochastic (random) method to estimate the value of \u03c0\u00a0\u2014 feel free to try to figure out the method from the code, but it is not critical for this exercise. The single argument to the program is the number of samples to take. More samples should result in better estimates!\n\n\n#include\n \n<stdio.h>\n\n\n#include\n \n<stdlib.h>\n\n\n#include\n \n<sys/time.h>\n\n\n\nint\n \nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n  \nstruct\n \ntimeval\n \nmy_timeval\n;\n\n  \nint\n \niterations\n \n=\n \n0\n;\n\n  \nint\n \ninside_circle\n \n=\n \n0\n;\n\n  \nint\n \ni\n;\n\n  \ndouble\n \nx\n,\n \ny\n,\n \npi_estimate\n;\n\n\n  \ngettimeofday\n(\n&\nmy_timeval\n,\n \nNULL\n);\n\n  \nsrand48\n(\nmy_timeval\n.\ntv_sec\n \n^\n \nmy_timeval\n.\ntv_usec\n);\n\n\n  \nif\n \n(\nargc\n \n==\n \n2\n)\n \n{\n\n    \niterations\n \n=\n \natoi\n(\nargv\n[\n1\n]);\n\n  \n}\n \nelse\n \n{\n\n    \nprintf\n(\n\"usage: circlepi ITERATIONS\n\\n\n\"\n);\n\n    \nexit\n(\n1\n);\n\n  \n}\n\n\n  \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n<\n \niterations\n;\n \ni\n++\n)\n \n{\n\n    \nx\n \n=\n \n(\ndrand48\n()\n \n-\n \n0.5\n)\n \n*\n \n2.0\n;\n\n    \ny\n \n=\n \n(\ndrand48\n()\n \n-\n \n0.5\n)\n \n*\n \n2.0\n;\n\n    \nif\n \n(((\nx\n \n*\n \nx\n)\n \n+\n \n(\ny\n \n*\n \ny\n))\n \n<=\n \n1.0\n)\n \n{\n\n      \ninside_circle\n++\n;\n\n    \n}\n\n  \n}\n\n  \npi_estimate\n \n=\n \n4.0\n \n*\n \n((\ndouble\n)\n \ninside_circle\n \n/\n \n(\ndouble\n)\n \niterations\n);\n\n  \nprintf\n(\n\"%d iterations, %d inside; pi = %f\n\\n\n\"\n,\n \niterations\n,\n \ninside_circle\n,\n \npi_estimate\n);\n\n  \nreturn\n \n0\n;\n\n\n}\n\n\n\n\n\n\n\n\nIn a new directory for this exercise, save the code to a file named \ncirclepi.c\n\n\n\n\nCompile the code (we will cover this in more detail during the Software lecture):\n\n\nusername@learn $\n gcc -static -o circlepi circlepi.c\n\n\n\n\n\n\n\n\n\nTest the program with just 1000 samples:\n\n\nusername@learn $\n ./circlepi \n1000\n\n\n\n\n\n\n\n\n\n\nNow suppose that you want to run the program many times, to produce many estimates.\nTo do so, we can tell HTCondor how many jobs to \"queue up\" via the \nqueue\n statement\nwe've been putting at the end of each of our submit files.\nLet\u2019s see how it works:\n\n\n\n\nWrite a normal submit file for this program\n\n\nPass 1 million (\n1000000\n) as the command line argument to \ncirclepi\n\n\nAt the end of the file, write \nqueue 3\n instead of just \nqueue\n (\"queue 3 jobs\" vs. \"queue a job\").\n\n\n\n\n\n\n\n\nSubmit the file. Note the slightly different message from \ncondor_submit\n:\n\n\n3 job(s) submitted to cluster *NNNN*.\n\n\n\n\n\n\n\n\n\n\nBefore the jobs execute, look at the job queue to see the multiple jobs\n\n\n\n\n\n\nHere is some sample \ncondor_q -nobatch\n output:\n\n\n ID       OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD\n\n\n10228.0   cat             7/25 11:57   0+00:00:00 I  0    0.7 circlepi 1000000000\n\n\n10228.1   cat             7/25 11:57   0+00:00:00 I  0    0.7 circlepi 1000000000\n\n\n10228.2   cat             7/25 11:57   0+00:00:00 I  0    0.7 circlepi 1000000000\n\n\n\n\n\n\nIn this sample, all three jobs are part of \ncluster\n \n10228\n, \nbut the first job was assigned \nprocess\n \n0\n, \nthe second job was assigned process \n1\n, \nand the third one was assigned process \n2\n.\n(Programmers like to start counting from 0.)\n\n\nNow we can understand what the first column in the output, the \njob ID\n, represents.\nIt is a job\u2019s cluster number, a dot (\n.\n), and the job\u2019s process number.\nSo in the example above, the job ID of the second job is \n10228.1\n.\n\n\nPop Quiz:\n Do you remember how to ask HTCondor to list all of the jobs from one cluster? How about one specific job ID?\n\n\nUsing queue \nN\n With Output\n\u00b6\n\n\nWhen all three jobs in your single cluster are finished, examine the resulting files.\n\n\n\n\nWhat is in the output file?\n\n\nWhat is in the error file (hopefully nothing)?\n\n\nWhat is in the log file? Look carefully at the job IDs in each event.\n\n\nIs this what you expected? Is it what you wanted?\n\n\n\n\nUsing $(Process) to Distinguish Jobs\n\u00b6\n\n\nAs you saw with the experiment above, each job ended up overwriting the same output and error filenames in the submission directory.\nAfter all, we didn't tell it to behave any differently when it ran three jobs.\nWe need a way to separate output (and error) files \nper job that is queued\n, not just for the whole cluster of jobs. Fortunately, HTCondor has a way to separate the files easily.\n\n\nWhen processing a submit file, HTCondor will replace any instance of \n$(Process)\n with the process number of the job, for each job that is queued. \nFor example, you can use the \n$(Process)\n variable to define a separate output file name for each job:\n\n\noutput = my-output-file-$(Process).out\nqueue 10\n\n\n\n\n\nThese variables are sometimes called \"submit macros\".\n\n\nEven though the \noutput\n filename is defined only once, HTCondor will create separate output filenames for each job:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFirst job\n\n\nmy-output-file-0.out\n\n\n\n\n\n\nSecond job\n\n\nmy-output-file-1.out\n\n\n\n\n\n\nThird job\n\n\nmy-output-file-2.out\n\n\n\n\n\n\n...\n\n\n...\n\n\n\n\n\n\nLast (tenth) job\n\n\nmy-output-file-9.out\n\n\n\n\n\n\n\n\nLet\u2019s see how this works for our program that estimates \u03c0.\n\n\n\n\nIn your submit file, change the definitions of \noutput\n and \nerror\n to use \n$(Process)\n in the filename, similar to the example above.\n\n\nDelete any output, error, and log files from previous runs.\n\n\nSubmit the updated file.\n\n\n\n\nWhen all three jobs are finished, examine the resulting files again.\n\n\n\n\nHow many files are there of each type? What are their names?\n\n\nIs this what you expected? Is it what you wanted from the \u03c0 estimation process?\n\n\n\n\nUsing $(Cluster) to Separate Files Across Runs\n\u00b6\n\n\nWith \n$(Process)\n, you can get separate output (and error) filenames for each job within a run. However, the next time you submit the same file, all of the output and error files are overwritten by new ones created by the new jobs. Maybe this is the behavior that you want. But sometimes, you may want to separate files by run, as well.\n\n\nIn addition to \n$(Process)\n, there is also a \n$(Cluster)\n variable that you can use in your submit files. It works just like \n$(Process)\n, except it is replaced with the cluster number of the entire submission. Because the cluster number is the same for all jobs within a single submission, it does not separate files by job within a submission. But when used \nwith\n \n$(Process)\n, it can be used to separate files by run. For example, consider this \noutput\n statement:\n\n\noutput = my-output-file-$(Cluster)-$(Process).out\n\n\n\n\n\nFor one particular run, it might result in output filenames like \nmy-output-file-2444-0.out\n, \nmyoutput-file-2444-1.out\n, \nmyoutput-file-2444-2.out\n, etc.\n\n\nHowever, the next run would have different filenames, replacing \n2444\n with the new Cluster number of that run.\n\n\nUsing $(Process) and $(Cluster) in Other Statements\n\u00b6\n\n\nThe \n$(Cluster)\n and \n$(Process)\n variables can be used in any submit file statement, although they are useful in some kinds of submit file statements and not really for others. For example, consider using $(Cluster) or $(Process) in each of the below:\n\n\n\n\nlog\n\n\ntransfer_input_files\n\n\ntransfer_output_files\n\n\narguments\n\n\n\n\nUnfortunately, HTCondor does not easily let you perform math on the \n$(Process)\n number when using it. So, for example, if you use \n$(Process)\n as a numeric argument to a command, it will always result in jobs getting the arguments 0, 1, 2, and so on. If you have control over your program and the way in which it uses command-line arguments, then you are fine. Otherwise, you might need a solution like those in the next exercises.\n\n\n(Optional) Defining JobBatchName for Tracking\n\u00b6\n\n\nDuring the lecture, it was mentioned that you can define arbitrary attributes in your submit file, and that one purpose of such attributes is to track or report on different jobs separately. In this optional exercise, you will see how this technique can be used.\n\n\nOnce again, we will use \nsleep\n jobs, so that your jobs remain in the queue long enough to experiment on.\n\n\n\n\nCreate a submit file that runs \nsleep 120\n (or some reasonable duration).\n\n\n\n\nInstead of a single \nqueue\n statement, write this:\n\n\njobbatchname = 1\nqueue 5\n\n\n\n\n\n\n\n\n\nSubmit the file.\n\n\n\n\n\n\nNow, quickly edit the submit file to instead say:\n\n\njobbatchname = 2\n\n\n\n\n\n\n\n\n\nSubmit the file again.\n\n\n\n\n\n\nCheck on the submissions using a normal \ncondor_q\n and \ncondor_q -nobatch\n. Of course, your special attribute does not appear in the \ncondor_q -nobatch\n output, but it is present in the \ncondor_q\n output and in each job\u2019s ClassAd. You can see the effect of the attribute by limiting your \ncondor_q\n output to one type of job or another. First, run this command:\n\n\nusername@learn $\n condor_q -constraint \n'JobBatchName == \"1\"'\n\n\n\n\n\n\nDo you get the output that you expected? Using the example command above, how would you list your other five jobs?\n(More on constraints in other exercises later today.)",
            "title": "Exercise 2.2"
        },
        {
            "location": "/materials/htc/part2-ex2-queue-n/#htc-exercise-22-use-queue-n-cluster-and-process",
            "text": "The goal of the next several exercises is\nto learn to submit many jobs from a single  queue  statement,\nand to control things like filenames and arguments on a per-job basis when doing so.  Suppose you have a program that you want to run many times with different arguments each time. With what you know so far, you have a couple of choices:   Write one submit file; submit one job, change the argument in the submit file, submit another job, change the submit file, \u2026  Write many submit files that are nearly identical except for the program argument   Neither of these options seems very satisfying. Fortunately, we can do better with HTCondor.",
            "title": "HTC Exercise 2.2: Use queue N, $(Cluster), and $(Process)"
        },
        {
            "location": "/materials/htc/part2-ex2-queue-n/#running-many-jobs-with-one-queue-statement",
            "text": "Here is a C program that uses a stochastic (random) method to estimate the value of \u03c0\u00a0\u2014 feel free to try to figure out the method from the code, but it is not critical for this exercise. The single argument to the program is the number of samples to take. More samples should result in better estimates!  #include   <stdio.h>  #include   <stdlib.h>  #include   <sys/time.h>  int   main ( int   argc ,   char   * argv [])  { \n   struct   timeval   my_timeval ; \n   int   iterations   =   0 ; \n   int   inside_circle   =   0 ; \n   int   i ; \n   double   x ,   y ,   pi_estimate ; \n\n   gettimeofday ( & my_timeval ,   NULL ); \n   srand48 ( my_timeval . tv_sec   ^   my_timeval . tv_usec ); \n\n   if   ( argc   ==   2 )   { \n     iterations   =   atoi ( argv [ 1 ]); \n   }   else   { \n     printf ( \"usage: circlepi ITERATIONS \\n \" ); \n     exit ( 1 ); \n   } \n\n   for   ( i   =   0 ;   i   <   iterations ;   i ++ )   { \n     x   =   ( drand48 ()   -   0.5 )   *   2.0 ; \n     y   =   ( drand48 ()   -   0.5 )   *   2.0 ; \n     if   ((( x   *   x )   +   ( y   *   y ))   <=   1.0 )   { \n       inside_circle ++ ; \n     } \n   } \n   pi_estimate   =   4.0   *   (( double )   inside_circle   /   ( double )   iterations ); \n   printf ( \"%d iterations, %d inside; pi = %f \\n \" ,   iterations ,   inside_circle ,   pi_estimate ); \n   return   0 ;  }    In a new directory for this exercise, save the code to a file named  circlepi.c   Compile the code (we will cover this in more detail during the Software lecture):  username@learn $  gcc -static -o circlepi circlepi.c    Test the program with just 1000 samples:  username@learn $  ./circlepi  1000     Now suppose that you want to run the program many times, to produce many estimates.\nTo do so, we can tell HTCondor how many jobs to \"queue up\" via the  queue  statement\nwe've been putting at the end of each of our submit files.\nLet\u2019s see how it works:   Write a normal submit file for this program  Pass 1 million ( 1000000 ) as the command line argument to  circlepi  At the end of the file, write  queue 3  instead of just  queue  (\"queue 3 jobs\" vs. \"queue a job\").     Submit the file. Note the slightly different message from  condor_submit :  3 job(s) submitted to cluster *NNNN*.     Before the jobs execute, look at the job queue to see the multiple jobs    Here is some sample  condor_q -nobatch  output:   ID       OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD  10228.0   cat             7/25 11:57   0+00:00:00 I  0    0.7 circlepi 1000000000  10228.1   cat             7/25 11:57   0+00:00:00 I  0    0.7 circlepi 1000000000  10228.2   cat             7/25 11:57   0+00:00:00 I  0    0.7 circlepi 1000000000   In this sample, all three jobs are part of  cluster   10228 , \nbut the first job was assigned  process   0 , \nthe second job was assigned process  1 , \nand the third one was assigned process  2 .\n(Programmers like to start counting from 0.)  Now we can understand what the first column in the output, the  job ID , represents.\nIt is a job\u2019s cluster number, a dot ( . ), and the job\u2019s process number.\nSo in the example above, the job ID of the second job is  10228.1 .  Pop Quiz:  Do you remember how to ask HTCondor to list all of the jobs from one cluster? How about one specific job ID?",
            "title": "Running Many Jobs With One queue Statement"
        },
        {
            "location": "/materials/htc/part2-ex2-queue-n/#using-queue-n-with-output",
            "text": "When all three jobs in your single cluster are finished, examine the resulting files.   What is in the output file?  What is in the error file (hopefully nothing)?  What is in the log file? Look carefully at the job IDs in each event.  Is this what you expected? Is it what you wanted?",
            "title": "Using queue N With Output"
        },
        {
            "location": "/materials/htc/part2-ex2-queue-n/#using-process-to-distinguish-jobs",
            "text": "As you saw with the experiment above, each job ended up overwriting the same output and error filenames in the submission directory.\nAfter all, we didn't tell it to behave any differently when it ran three jobs.\nWe need a way to separate output (and error) files  per job that is queued , not just for the whole cluster of jobs. Fortunately, HTCondor has a way to separate the files easily.  When processing a submit file, HTCondor will replace any instance of  $(Process)  with the process number of the job, for each job that is queued. \nFor example, you can use the  $(Process)  variable to define a separate output file name for each job:  output = my-output-file-$(Process).out\nqueue 10  These variables are sometimes called \"submit macros\".  Even though the  output  filename is defined only once, HTCondor will create separate output filenames for each job:           First job  my-output-file-0.out    Second job  my-output-file-1.out    Third job  my-output-file-2.out    ...  ...    Last (tenth) job  my-output-file-9.out     Let\u2019s see how this works for our program that estimates \u03c0.   In your submit file, change the definitions of  output  and  error  to use  $(Process)  in the filename, similar to the example above.  Delete any output, error, and log files from previous runs.  Submit the updated file.   When all three jobs are finished, examine the resulting files again.   How many files are there of each type? What are their names?  Is this what you expected? Is it what you wanted from the \u03c0 estimation process?",
            "title": "Using $(Process) to Distinguish Jobs"
        },
        {
            "location": "/materials/htc/part2-ex2-queue-n/#using-cluster-to-separate-files-across-runs",
            "text": "With  $(Process) , you can get separate output (and error) filenames for each job within a run. However, the next time you submit the same file, all of the output and error files are overwritten by new ones created by the new jobs. Maybe this is the behavior that you want. But sometimes, you may want to separate files by run, as well.  In addition to  $(Process) , there is also a  $(Cluster)  variable that you can use in your submit files. It works just like  $(Process) , except it is replaced with the cluster number of the entire submission. Because the cluster number is the same for all jobs within a single submission, it does not separate files by job within a submission. But when used  with   $(Process) , it can be used to separate files by run. For example, consider this  output  statement:  output = my-output-file-$(Cluster)-$(Process).out  For one particular run, it might result in output filenames like  my-output-file-2444-0.out ,  myoutput-file-2444-1.out ,  myoutput-file-2444-2.out , etc.  However, the next run would have different filenames, replacing  2444  with the new Cluster number of that run.",
            "title": "Using $(Cluster) to Separate Files Across Runs"
        },
        {
            "location": "/materials/htc/part2-ex2-queue-n/#using-process-and-cluster-in-other-statements",
            "text": "The  $(Cluster)  and  $(Process)  variables can be used in any submit file statement, although they are useful in some kinds of submit file statements and not really for others. For example, consider using $(Cluster) or $(Process) in each of the below:   log  transfer_input_files  transfer_output_files  arguments   Unfortunately, HTCondor does not easily let you perform math on the  $(Process)  number when using it. So, for example, if you use  $(Process)  as a numeric argument to a command, it will always result in jobs getting the arguments 0, 1, 2, and so on. If you have control over your program and the way in which it uses command-line arguments, then you are fine. Otherwise, you might need a solution like those in the next exercises.",
            "title": "Using $(Process) and $(Cluster) in Other Statements"
        },
        {
            "location": "/materials/htc/part2-ex2-queue-n/#optional-defining-jobbatchname-for-tracking",
            "text": "During the lecture, it was mentioned that you can define arbitrary attributes in your submit file, and that one purpose of such attributes is to track or report on different jobs separately. In this optional exercise, you will see how this technique can be used.  Once again, we will use  sleep  jobs, so that your jobs remain in the queue long enough to experiment on.   Create a submit file that runs  sleep 120  (or some reasonable duration).   Instead of a single  queue  statement, write this:  jobbatchname = 1\nqueue 5    Submit the file.    Now, quickly edit the submit file to instead say:  jobbatchname = 2    Submit the file again.    Check on the submissions using a normal  condor_q  and  condor_q -nobatch . Of course, your special attribute does not appear in the  condor_q -nobatch  output, but it is present in the  condor_q  output and in each job\u2019s ClassAd. You can see the effect of the attribute by limiting your  condor_q  output to one type of job or another. First, run this command:  username@learn $  condor_q -constraint  'JobBatchName == \"1\"'   Do you get the output that you expected? Using the example command above, how would you list your other five jobs?\n(More on constraints in other exercises later today.)",
            "title": "(Optional) Defining JobBatchName for Tracking"
        },
        {
            "location": "/materials/htc/part2-ex3-queue-from/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nHTC Exercise 2.3: Submit with \u201cqueue from\u201d\n\u00b6\n\n\nIn this exercise and the next one, you will explore more ways to use a single\nsubmit file to submit many jobs. The goal of this exercise is to submit many\njobs from a single submit file by using the \nqueue ... from\n syntax to read\nvariable values from a file.\n\n\nIn all cases of submitting many jobs from a single submit file, the key questions are:\n\n\n\n\nWhat makes each job unique? In other words, there is one job per _____?\n\n\nSo, how should you tell HTCondor to distinguish each job?\n\n\n\n\nFor \nqueue *N*\n, jobs are distinguished simply by the built-in \"process\" variable. But with the remaining \nqueue\n forms, you help HTCondor distinguish jobs by other, more meaningful \ncustom\n variables.\n\n\nCounting Words in Files\n\u00b6\n\n\nImagine you have a collection of books, and you want to analyze how word usage varies from book to book or author to author. As mentioned in the lecture, HTCondor provides many ways to submit jobs for this task. You could create a separate submit file for each book, and submit all of the files manually, but you'd have a lot of file lines to modify each time (in particular, all five of the last lines before \nqueue\n below):\n\n\nexecutable              = freq.py\nrequest_memory          = 1GB\nrequest_disk            = 20MB\nshould_transfer_files   = YES\nwhen_to_transfer_output = ON_EXIT\n\ntransfer_input_files = AAiW.txt\narguments            = AAiW.txt\noutput               = AAiW.out\nerror                = AAiW.err\nlog                  = AAiW.log\nqueue\n\n\n\n\n\nThis would be overly verbose and tedious. Let's do better.\n\n\nQueue Jobs From a List of Values\n\u00b6\n\n\nSuppose we want to modify our word-frequency analysis from a previous exercise so that it outputs only the most common \nN\n words of a document. However, we want to experiment with different values of \nN\n. \n\n\nFor this analysis, we will have a new version of the word-frequency counting\nscript.  First, we need a new version of the word counting program so that it\naccepts an extra number as a command line argument and outputs only that many\nof the most common words. Here is the new code (it's still not important that\nyou understand this code):\n\n\n#!/usr/bin/env python\n\n\n\nimport\n \nos\n\n\nimport\n \nsys\n\n\nimport\n \noperator\n\n\n\nif\n \nlen\n(\nsys\n.\nargv\n)\n \n!=\n \n3\n:\n\n    \nprint\n \n'Usage: \n%s\n DATA NUM_WORDS'\n \n%\n \n(\nos\n.\npath\n.\nbasename\n(\nsys\n.\nargv\n[\n0\n]))\n\n    \nsys\n.\nexit\n(\n1\n)\n\n\ninput_filename\n \n=\n \nsys\n.\nargv\n[\n1\n]\n\n\nnum_words\n \n=\n \nint\n(\nsys\n.\nargv\n[\n2\n])\n\n\n\nwords\n \n=\n \n{}\n\n\n\nmy_file\n \n=\n \nopen\n(\ninput_filename\n,\n \n'r'\n)\n\n\nfor\n \nline\n \nin\n \nmy_file\n:\n\n    \nline_words\n \n=\n \nline\n.\nsplit\n()\n\n    \nfor\n \nword\n \nin\n \nline_words\n:\n\n        \nif\n \nword\n \nin\n \nwords\n:\n\n            \nwords\n[\nword\n]\n \n+=\n \n1\n\n        \nelse\n:\n\n            \nwords\n[\nword\n]\n \n=\n \n1\n\n\nmy_file\n.\nclose\n()\n\n\n\nsorted_words\n \n=\n \nsorted\n(\nwords\n.\nitems\n(),\n \nkey\n=\noperator\n.\nitemgetter\n(\n1\n))\n\n\nfor\n \nword\n \nin\n \nsorted_words\n[\n-\nnum_words\n:]:\n\n    \nprint\n \n'\n%s\n \n%8d\n'\n \n%\n \n(\nword\n[\n0\n],\n \nword\n[\n1\n])\n\n\n\n\n\n\nTo submit this program with a collection of two variable values for each run, one for the number of top words and one for the filename:\n\n\n\n\nSave the script as \nwordcount-top-n.py\n.\n\n\n\n\nDownload and unpack some books from Project Gutenberg:\n\n\nusername@learn $\n wget http://proxy.chtc.wisc.edu/SQUID/osgschool20/books.zip\n\nusername@learn $\n unzip books.zip\n\n\n\n\n\n\n\n\n\nCreate a new submit file (or base it off a previous one!) named \nwordcount-top.sub\n, including memory and disk requests of 20\u00a0MB.\n\n\n\n\nAll of the jobs will use the same \nexecutable\n and \nlog\n statements.\n\n\n\n\nUpdate other statements to work with two variables, \nbook\n and \nn\n:\n\n\noutput = $(book)_top_$(n).out \nerror = $(book)_top_$(n).err \ntransfer_input_files = $(book) \narguments = \"$(book) $(n)\" \nqueue book,n from books_n.txt\n\n\n\n\n\nNote especially the changes to the \nqueue\n statement; it now tells HTCondor to read a separate text file of \npairs\n of values, which will be assigned to \nbook\n and \nn\n respectively.\n\n\n\n\n\n\nCreate the separate text file of job variable values and save it as \nbooks_n.txt\n:\n\n\nAAiW.txt, 10 \nAAiW.txt, 25 \nAAiW.txt, 50 \nPandP.txt, 10 \nPandP.txt, 25 \nPandP.txt, 50\nTAoSH.txt, 10\nTAoSH.txt, 25\nTAoSH.txt, 50\n\n\n\n\n\nNote that we used 3 different values for \nn\n for each book.\n\n\n\n\n\n\nSubmit the file\n\n\n\n\nDo a quick sanity check: How many jobs were submitted? How many log, output, and error files were created?\n\n\n\n\nExtra Challenge 1\n\u00b6\n\n\nYou may have noticed that the output of these jobs has a messy naming convention. Because our macros resolve to the filenames, including their extension (e.g., \nAAiW.txt\n), the output filenames contain with multiple extensions (e.g., \nAAiW.txt.err\n). Although the extra extension is acceptable, it makes the filenames harder to read and possibly organize. \nChange your submit file and variable file for this exercise so that the output filenames do not include the \n.txt\n extension.",
            "title": "Exercise 2.3"
        },
        {
            "location": "/materials/htc/part2-ex3-queue-from/#htc-exercise-23-submit-with-queue-from",
            "text": "In this exercise and the next one, you will explore more ways to use a single\nsubmit file to submit many jobs. The goal of this exercise is to submit many\njobs from a single submit file by using the  queue ... from  syntax to read\nvariable values from a file.  In all cases of submitting many jobs from a single submit file, the key questions are:   What makes each job unique? In other words, there is one job per _____?  So, how should you tell HTCondor to distinguish each job?   For  queue *N* , jobs are distinguished simply by the built-in \"process\" variable. But with the remaining  queue  forms, you help HTCondor distinguish jobs by other, more meaningful  custom  variables.",
            "title": "HTC Exercise 2.3: Submit with \u201cqueue from\u201d"
        },
        {
            "location": "/materials/htc/part2-ex3-queue-from/#counting-words-in-files",
            "text": "Imagine you have a collection of books, and you want to analyze how word usage varies from book to book or author to author. As mentioned in the lecture, HTCondor provides many ways to submit jobs for this task. You could create a separate submit file for each book, and submit all of the files manually, but you'd have a lot of file lines to modify each time (in particular, all five of the last lines before  queue  below):  executable              = freq.py\nrequest_memory          = 1GB\nrequest_disk            = 20MB\nshould_transfer_files   = YES\nwhen_to_transfer_output = ON_EXIT\n\ntransfer_input_files = AAiW.txt\narguments            = AAiW.txt\noutput               = AAiW.out\nerror                = AAiW.err\nlog                  = AAiW.log\nqueue  This would be overly verbose and tedious. Let's do better.",
            "title": "Counting Words in Files"
        },
        {
            "location": "/materials/htc/part2-ex3-queue-from/#queue-jobs-from-a-list-of-values",
            "text": "Suppose we want to modify our word-frequency analysis from a previous exercise so that it outputs only the most common  N  words of a document. However, we want to experiment with different values of  N .   For this analysis, we will have a new version of the word-frequency counting\nscript.  First, we need a new version of the word counting program so that it\naccepts an extra number as a command line argument and outputs only that many\nof the most common words. Here is the new code (it's still not important that\nyou understand this code):  #!/usr/bin/env python  import   os  import   sys  import   operator  if   len ( sys . argv )   !=   3 : \n     print   'Usage:  %s  DATA NUM_WORDS'   %   ( os . path . basename ( sys . argv [ 0 ])) \n     sys . exit ( 1 )  input_filename   =   sys . argv [ 1 ]  num_words   =   int ( sys . argv [ 2 ])  words   =   {}  my_file   =   open ( input_filename ,   'r' )  for   line   in   my_file : \n     line_words   =   line . split () \n     for   word   in   line_words : \n         if   word   in   words : \n             words [ word ]   +=   1 \n         else : \n             words [ word ]   =   1  my_file . close ()  sorted_words   =   sorted ( words . items (),   key = operator . itemgetter ( 1 ))  for   word   in   sorted_words [ - num_words :]: \n     print   ' %s   %8d '   %   ( word [ 0 ],   word [ 1 ])   To submit this program with a collection of two variable values for each run, one for the number of top words and one for the filename:   Save the script as  wordcount-top-n.py .   Download and unpack some books from Project Gutenberg:  username@learn $  wget http://proxy.chtc.wisc.edu/SQUID/osgschool20/books.zip username@learn $  unzip books.zip    Create a new submit file (or base it off a previous one!) named  wordcount-top.sub , including memory and disk requests of 20\u00a0MB.   All of the jobs will use the same  executable  and  log  statements.   Update other statements to work with two variables,  book  and  n :  output = $(book)_top_$(n).out \nerror = $(book)_top_$(n).err \ntransfer_input_files = $(book) \narguments = \"$(book) $(n)\" \nqueue book,n from books_n.txt  Note especially the changes to the  queue  statement; it now tells HTCondor to read a separate text file of  pairs  of values, which will be assigned to  book  and  n  respectively.    Create the separate text file of job variable values and save it as  books_n.txt :  AAiW.txt, 10 \nAAiW.txt, 25 \nAAiW.txt, 50 \nPandP.txt, 10 \nPandP.txt, 25 \nPandP.txt, 50\nTAoSH.txt, 10\nTAoSH.txt, 25\nTAoSH.txt, 50  Note that we used 3 different values for  n  for each book.    Submit the file   Do a quick sanity check: How many jobs were submitted? How many log, output, and error files were created?",
            "title": "Queue Jobs From a List of Values"
        },
        {
            "location": "/materials/htc/part2-ex3-queue-from/#extra-challenge-1",
            "text": "You may have noticed that the output of these jobs has a messy naming convention. Because our macros resolve to the filenames, including their extension (e.g.,  AAiW.txt ), the output filenames contain with multiple extensions (e.g.,  AAiW.txt.err ). Although the extra extension is acceptable, it makes the filenames harder to read and possibly organize.  Change your submit file and variable file for this exercise so that the output filenames do not include the  .txt  extension.",
            "title": "Extra Challenge 1"
        },
        {
            "location": "/materials/htc/part2-ex4-queue-matching/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nBonus HTC Exercise 2.4: Submit With \u201cqueue matching\u201d\n\u00b6\n\n\nThe goal of this exercise is to submit many jobs from a single submit file by using the \nqueue ... matching\n syntax to submit jobs with variable values derived from files in the current directory which match a specified pattern.\n\n\nCounting Words in Files\n\u00b6\n\n\nReturning to our book word-counting example, let's pretend that instead of\nthree books, we have an entire library. While we could list all of the text\nfiles in a \nbooks.txt\n file and use \nqueue book from books.txt\n, it could be a\ntedious process, especially for tens of thousands of files. Luckily HTCondor\nprovides a mechanism for submitting jobs based on pattern-matched files.\n\n\nQueue Jobs By Matching Filenames\n\u00b6\n\n\nThis is an example of a common scenario: We want to run one job per file, where the filenames match a certain consistent pattern. The \nqueue ... matching\n statement is made for this scenario.\n\n\nLet\u2019s see this in action. First, here is a new version of the script (note, we removed the 'top n words' restriction):\n\n\n#!/usr/bin/env python\n\n\n\nimport\n \nos\n\n\nimport\n \nsys\n\n\nimport\n \noperator\n\n\n\nif\n \nlen\n(\nsys\n.\nargv\n)\n \n!=\n \n2\n:\n\n    \nprint\n \n'Usage: \n%s\n DATA'\n \n%\n \n(\nos\n.\npath\n.\nbasename\n(\nsys\n.\nargv\n[\n0\n]))\n\n    \nsys\n.\nexit\n(\n1\n)\n\n\ninput_filename\n \n=\n \nsys\n.\nargv\n[\n1\n]\n\n\n\nwords\n \n=\n \n{}\n\n\n\nmy_file\n \n=\n \nopen\n(\ninput_filename\n,\n \n'r'\n)\n\n\nfor\n \nline\n \nin\n \nmy_file\n:\n\n    \nline_words\n \n=\n \nline\n.\nsplit\n()\n\n    \nfor\n \nword\n \nin\n \nline_words\n:\n\n        \nif\n \nword\n \nin\n \nwords\n:\n\n            \nwords\n[\nword\n]\n \n+=\n \n1\n\n        \nelse\n:\n\n            \nwords\n[\nword\n]\n \n=\n \n1\n\n\nmy_file\n.\nclose\n()\n\n\n\nsorted_words\n \n=\n \nsorted\n(\nwords\n.\nitems\n(),\n \nkey\n=\noperator\n.\nitemgetter\n(\n1\n))\n\n\nfor\n \nword\n \nin\n \nsorted_words\n:\n\n    \nprint\n \n'\n%s\n \n%8d\n'\n \n%\n \n(\nword\n[\n0\n],\n \nword\n[\n1\n])\n\n\n\n\n\n\nTo use the script:\n\n\n\n\nSave it as \nwordcount.py\n.\n\n\nVerify the script by running it on one book manually.\n\n\nCreate a new submit file to submit one job (pick a book file and model your submit file off of the one above)\n\n\n\n\nModify the following submit file statements to work for all books:\n\n\ntransfer_input_files = $(book) \narguments = $(book) \noutput = $(book).out \nerror = $(book).err \nqueue book matching *.txt\n\n\n\n\n\n\n\nNote\n\n\nAs always, the order of statements in a submit file does not matter, except that the \nqueue\n statement should be last. Also note that any submit file variable name (here, \nbook\n, but true for \nprocess\n and all others) may be used in any mixture of upper- and lowercase letters.\n\n\n\n\n\n\n\n\nSubmit the jobs.\n\n\n\n\n\n\nHTCondor uses the \nqueue ... matching\n statement to look for files in the submit directory that match the given pattern, then queues one job per match. For each job, the given variable (e.g., \nbook\n here) is assigned the name of the matching file, so that it can be used in \noutput\n, \nerror\n, and other statements.\n\n\nThe result is the same as if we had written out a much longer submit file:\n\n\n...\n\ntransfer_input_files = AAiW.txt\narguments = \"AAiW.txt\"\noutput = AAiW.txt.out\nerror = AAiW.txt.err\nqueue\n\ntransfer_input_files = PandP.txt\narguments = \"PandP.txt\"\noutput = PandP.txt.out\nerror = PandP.txt.err\nqueue\n\ntransfer_input_files = TAoSH.txt\narguments = \"TAoSH.txt\"\noutput = TAoSH.txt.out\nerror = TAoSH.txt.err\nqueue\n\n...\n\n\n\n\n\nHow many jobs were created? Is this what you expected? If you ran this in the\nsame directory as Exercise 2.3, you may have noticed that a job was submitted\nfor the \nbooks_n.txt\n file that holds the variable values in the \nqueue from\n\nstatement. Beware the dangers of matching more files than intended! One\nsolution may be to put all of the books into an \nbooks\n directory and \nqueue\nmatching books/*.txt\n. Can you think of other solutions? If you have time, try one!\n\n\nExtra Challenge 1\n\u00b6\n\n\nIn the example above, you used a single log file for all three jobs. HTCondor handles this situation with no problem; each job writes its events into the log file without getting in the way of other events and other jobs. But as you may have seen, it may be difficult for a person to understand the events for any particular job in the combined log file.\n\n\nCreate a new submit file that works just like the one above, except that each job writes its own log file.\n\n\nExtra Challenge 2\n\u00b6\n\n\nBetween this exercise and the previous one, you have explored two of the three primary \nqueue\n statements. How would you use the \nqueue in ... list\n statement to accomplish the same thing(s) as one or both of the exercises?",
            "title": "Bonus Exercise 2.4"
        },
        {
            "location": "/materials/htc/part2-ex4-queue-matching/#bonus-htc-exercise-24-submit-with-queue-matching",
            "text": "The goal of this exercise is to submit many jobs from a single submit file by using the  queue ... matching  syntax to submit jobs with variable values derived from files in the current directory which match a specified pattern.",
            "title": "Bonus HTC Exercise 2.4: Submit With \u201cqueue matching\u201d"
        },
        {
            "location": "/materials/htc/part2-ex4-queue-matching/#counting-words-in-files",
            "text": "Returning to our book word-counting example, let's pretend that instead of\nthree books, we have an entire library. While we could list all of the text\nfiles in a  books.txt  file and use  queue book from books.txt , it could be a\ntedious process, especially for tens of thousands of files. Luckily HTCondor\nprovides a mechanism for submitting jobs based on pattern-matched files.",
            "title": "Counting Words in Files"
        },
        {
            "location": "/materials/htc/part2-ex4-queue-matching/#queue-jobs-by-matching-filenames",
            "text": "This is an example of a common scenario: We want to run one job per file, where the filenames match a certain consistent pattern. The  queue ... matching  statement is made for this scenario.  Let\u2019s see this in action. First, here is a new version of the script (note, we removed the 'top n words' restriction):  #!/usr/bin/env python  import   os  import   sys  import   operator  if   len ( sys . argv )   !=   2 : \n     print   'Usage:  %s  DATA'   %   ( os . path . basename ( sys . argv [ 0 ])) \n     sys . exit ( 1 )  input_filename   =   sys . argv [ 1 ]  words   =   {}  my_file   =   open ( input_filename ,   'r' )  for   line   in   my_file : \n     line_words   =   line . split () \n     for   word   in   line_words : \n         if   word   in   words : \n             words [ word ]   +=   1 \n         else : \n             words [ word ]   =   1  my_file . close ()  sorted_words   =   sorted ( words . items (),   key = operator . itemgetter ( 1 ))  for   word   in   sorted_words : \n     print   ' %s   %8d '   %   ( word [ 0 ],   word [ 1 ])   To use the script:   Save it as  wordcount.py .  Verify the script by running it on one book manually.  Create a new submit file to submit one job (pick a book file and model your submit file off of the one above)   Modify the following submit file statements to work for all books:  transfer_input_files = $(book) \narguments = $(book) \noutput = $(book).out \nerror = $(book).err \nqueue book matching *.txt   Note  As always, the order of statements in a submit file does not matter, except that the  queue  statement should be last. Also note that any submit file variable name (here,  book , but true for  process  and all others) may be used in any mixture of upper- and lowercase letters.     Submit the jobs.    HTCondor uses the  queue ... matching  statement to look for files in the submit directory that match the given pattern, then queues one job per match. For each job, the given variable (e.g.,  book  here) is assigned the name of the matching file, so that it can be used in  output ,  error , and other statements.  The result is the same as if we had written out a much longer submit file:  ...\n\ntransfer_input_files = AAiW.txt\narguments = \"AAiW.txt\"\noutput = AAiW.txt.out\nerror = AAiW.txt.err\nqueue\n\ntransfer_input_files = PandP.txt\narguments = \"PandP.txt\"\noutput = PandP.txt.out\nerror = PandP.txt.err\nqueue\n\ntransfer_input_files = TAoSH.txt\narguments = \"TAoSH.txt\"\noutput = TAoSH.txt.out\nerror = TAoSH.txt.err\nqueue\n\n...  How many jobs were created? Is this what you expected? If you ran this in the\nsame directory as Exercise 2.3, you may have noticed that a job was submitted\nfor the  books_n.txt  file that holds the variable values in the  queue from \nstatement. Beware the dangers of matching more files than intended! One\nsolution may be to put all of the books into an  books  directory and  queue\nmatching books/*.txt . Can you think of other solutions? If you have time, try one!",
            "title": "Queue Jobs By Matching Filenames"
        },
        {
            "location": "/materials/htc/part2-ex4-queue-matching/#extra-challenge-1",
            "text": "In the example above, you used a single log file for all three jobs. HTCondor handles this situation with no problem; each job writes its events into the log file without getting in the way of other events and other jobs. But as you may have seen, it may be difficult for a person to understand the events for any particular job in the combined log file.  Create a new submit file that works just like the one above, except that each job writes its own log file.",
            "title": "Extra Challenge 1"
        },
        {
            "location": "/materials/htc/part2-ex4-queue-matching/#extra-challenge-2",
            "text": "Between this exercise and the previous one, you have explored two of the three primary  queue  statements. How would you use the  queue in ... list  statement to accomplish the same thing(s) as one or both of the exercises?",
            "title": "Extra Challenge 2"
        },
        {
            "location": "/materials/htc/part3-ex1-queue/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nBonus HTC Exercise 3.1: Explore condor_q\n\u00b6\n\n\nThe goal of this exercise is try out some of the most common options to the \ncondor_q\n command, so that you can view jobs effectively.\n\n\nThe main part of this exercise should take just a few minutes, but if you have more time later, come back and work on the extension ideas at the end to become a \ncondor_q\n expert!\n\n\nSelecting Jobs\n\u00b6\n\n\nThe \ncondor_q\n program has many options for selecting which jobs are listed. You have already seen that the default mode is to show only your jobs in \"batch\" mode:\n\n\nusername@learn $\n condor_q\n\n\n\n\n\nYou've seen that you can view all jobs (all users) in the submit node's queue by using the \n-all\n argument:\n\n\nusername@learn $\n condor_q -all\n\n\n\n\n\nAnd you've seen that you can view more details about queued jobs, with each separate job on a single line using the \n-nobatch\n option:\n\n\nusername@learn $\n condor_q -nobatch\n\nusername@learn $\n condor_q -all -nobatch\n\n\n\n\n\nDid you know you can also name one or more user IDs on the command line, in which case jobs for all of the named users are listed at once?\n\n\nusername@learn $\n condor_q <USERNAME1> <USERNAME2> <USERNAME3>\n\n\n\n\n\nTo list just the jobs associated with a single cluster number:\n\n\nusername@learn $\n condor_q <CLUSTER>\n\n\n\n\n\nFor example, if you want to see the jobs in cluster 5678 (i.e., \n5678.0\n, \n5678.1\n, etc.), you use \ncondor_q 5678\n.\n\n\nTo list a specific job (i.e., cluster.process, as in 5678.0):\n\n\nusername@learn $\n condor_q <JOB.ID>\n\n\n\n\n\nFor example, to see job ID 5678.1, you use \ncondor_q 5678.1\n.\n\n\n\n\nNote\n\n\nYou can name more than one cluster, job ID, or combination thereof on the command line, in which case jobs for\n\nall\n of the named clusters and/or job IDs are listed.\n\n\n\n\nLet\u2019s get some practice using \ncondor_q\n selections!\n\n\n\n\nUsing a previous exercise, submit several \nsleep\n jobs.\n\n\nList all jobs in the queue \u2014 are there others besides your own?\n\n\nPractice using all forms of \ncondor_q\n that you have learned:\n\n\nList just your jobs, with and without batching.\n\n\nList a specific cluster.\n\n\nList a specific job ID.\n\n\nTry listing several users at once.\n\n\nTry listing several clusters and job IDs at once.\n\n\n\n\n\n\nWhen there are a variety of jobs in the queue, try combining a username and a different user's cluster or job ID in the same command \u2014 what happens?\n\n\n\n\nViewing a Job ClassAd\n\u00b6\n\n\nYou may have wondered why it is useful to be able to list a single job ID using \ncondor_q\n. By itself, it may not be that useful. But, in combination with another option, it is very useful!\n\n\nIf you add the \n-long\n option to \ncondor_q\n (or its short form, \n-l\n), it will show the complete ClassAd for each selected job, instead of the one-line summary that you have seen so far. Because job ClassAds may have 80\u201390 attributes (or more), it probably makes the most sense to show the ClassAd for a single job at a time. And you know how to show just one job! Here is what the command looks like:\n\n\nusername@learn $\n condor_q -long <JOB.ID>\n\n\n\n\n\nThe output from this command is long and complex. Most of the attributes that HTCondor adds to a job are arcane and uninteresting for us now. But here are some examples of common, interesting attributes taken directly from \ncondor_q\n output (except with some line breaks added to the \nRequirements\n attribute):\n\n\nMyType = \"Job\"\nErr = \"sleep.err\"\nUserLog = \"/home/cat/intro-2.1-queue/sleep.log\"\nRequirements = ( IsOSGSchoolSlot =?= true ) &&\n        ( TARGET.Arch == \"X86_64\" ) &&\n        ( TARGET.OpSys == \"LINUX\" ) &&\n        ( TARGET.Disk >= RequestDisk ) &&\n        ( TARGET.Memory >= RequestMemory ) &&\n        ( TARGET.HasFileTransfer )\nClusterId = 2420\nWhenToTransferOutput = \"ON_EXIT\"\nOwner = \"cat\"\nCondorVersion = \"$CondorVersion: 8.5.5 May 03 2016 BuildID: 366162 $\"\nOut = \"sleep.out\"\nCmd = \"/bin/sleep\"\nArguments = \"120\"\n\n\n\n\n\n\n\nNote\n\n\nAttributes are listed in no particular order and may change from time to time.\nDo not assume anything about the order of attributes in \ncondor_q\n output.\n\n\n\n\nSee what you can find in a job ClassAd from your own job.\n\n\n\n\nUsing a previous exercise, submit a \nsleep\n job that sleeps for at least 3 minutes (180 seconds).\n\n\n\n\nBefore the job executes, capture its ClassAd and save to a file:\n\n\ncondor_q -l <JOB.ID> > classad-1.txt\n\n\n\n\n\n\n\n\n\n\nAfter the job starts execution but before it finishes, capture its ClassAd again and save to a file\n\n\ncondor_q -l <JOB.ID> > classad-2.txt\n\n\n\n\n\n\n\n\n\n\nNow examine each saved ClassAd file. Here are a few things to look for:\n\n\n\n\nCan you find attributes that came from your submit file? (E.g., Cmd, Arguments, Out, Err, UserLog, and so forth)\n\n\nCan you find attributes that could have come from your submit file, but that HTCondor added for you? (E.g., Requirements)\n\n\nHow many of the following attributes can you guess the meaning of?\n\n\nDiskUsage\n\n\nImageSize\n\n\nBytesSent\n\n\nJobStatus\n\n\n\n\n\n\n\n\nWhy Is My Job Not Running?\n\u00b6\n\n\nSometimes, you submit a job and it just sits in the queue in Idle state, never running. It can be difficult to figure out why a job never matches and runs. Fortunately, HTCondor can give you some help.\n\n\nTo ask HTCondor why your job is not running, add the \n-better-analyze\n option to \ncondor_q\n for the specific job. For example, for job ID 2423.0, the command is:\n\n\nusername@learn $\n condor_q -better-analyze \n2423\n.0\n\n\n\n\n\nOf course, replace the job ID with your own.\n\n\nLet\u2019s submit a job that will never run and see what happens. Here is the submit file to use:\n\n\nexecutable = /bin/hostname\noutput = norun.out\nerror = norun.err\nlog = norun.log\nshould_transfer_files = YES\nwhen_to_transfer_output = ON_EXIT\nrequest_disk = 10MB\nrequest_memory = 8TB\nqueue\n\n\n\n\n\n(Do you see what I did?)\n\n\n\n\nSave and submit this file.\n\n\nRun \ncondor_q -better-analyze\n on the job ID.\n\n\n\n\nThere is a lot of output, but a few items are worth highlighting. Here is a sample from my own job (with some lines omitted):\n\n\n-- Schedd: learn.chtc.wisc.edu : <128.104.100.148:9618?...\n...\n\nJob 98096.000 defines the following attributes:\n\n    RequestDisk = 10240\n    RequestMemory = 8388608\n\nThe Requirements expression for job 98096.000 reduces to these conditions:\n\n\n         Slots\nStep    Matched  Condition\n-----  --------  ---------\n[1]       11227  Target.OpSysMajorVer == 7\n[9]       13098  TARGET.Disk >= RequestDisk\n[11]          0  TARGET.Memory >= RequestMemory\n\nNo successful match recorded.\nLast failed match: Fri Jul 12 15:36:30 2019\n\nReason for last match failure: no match found\n\n98096.000:  Run analysis summary ignoring user priority.  Of 710 machines,\n    710 are rejected by your job's requirements\n      0 reject your job because of their own requirements\n      0 match and are already running your jobs\n      0 match but are serving other users\n      0 are able to run your job\n...\n\n\n\n\n\nAt the end of the summary, \ncondor_q\n provides a breakdown of how \nmachines\n and their own requirements match against my own job's requirements. 710 total machines were considered above, and \nall\n of them were rejected based on \nmy job's requirements\n. In other words, I am asking for something that is not available. But what?\n\n\nFurther up in the output, there is an analysis of the job's requirements, along with how many slots within the pool match each of those requirements. The example above reports that 13098 slots match our small disk request request, but \nnone\n of the slots matched the \nTARGET.Memory >= RequestMemory\n condition. The output also reports the value used for the \nRequestMemory\n attribute: my job asked for \n8 terabytes\n of memory (8,388,608 MB) -- of course no machines matched that part of the expression! That's a lot of memory on today's machines.\n\n\nThe output from \ncondor_q -analyze\n (and \ncondor_q -better-analyze\n) may be helpful or it may not be, depending on your exact case. The example above was constructed so that it would be obvious what the problem was. But in many cases, this is a good place to start looking if you are having problems matching.\n\n\nBonus: Automatic Formatting Output\n\u00b6\n\n\nDo this exercise only if you have time, though it's pretty awesome!\n\n\nThere is a way to select the specific job attributes you want \ncondor_q\n to tell you about with the \n-autoformat\n or \n-af\n option. In this case, HTCondor decides for you how to format the data you ask for from job ClassAd(s). \n(To tell HTCondor how to specially format this information, yourself, you could use the \n-format\n option, which we're not covering.)\n\n\nTo use autoformatting, use the \n-af\n option followed by the attribute name, for each attribute that you want to output:\n\n\nusername@learn $\n condor_q -all -af Owner ClusterId Cmd\n\nmoate 2418 /share/test.sh\n\n\ncat 2421 /bin/sleep\n\n\ncat 2422 /bin/sleep\n\n\n\n\n\n\nBonus Question\n: If you wanted to print out the \nRequirements\n expression of a job, how would you do that with \n-af\n? Is the output what you expected? (HINT: for ClassAd attributes like \"Requirements\" that are long expressions, instead of plain values, you can use \n-af:r\n to view the expressions, instead of what it's current evaluation.)\n\n\nReferences\n\u00b6\n\n\nAs suggested above, if you want to learn more about \ncondor_q\n, you can do some reading:\n\n\n\n\nRead the \ncondor_q\n man page or HTCondor Manual section (same text) to learn about more options\n\n\nRead about ClassAd attributes in Appendix A of the HTCondor Manual",
            "title": "Bonus Exercise 3.1"
        },
        {
            "location": "/materials/htc/part3-ex1-queue/#bonus-htc-exercise-31-explore-condor_q",
            "text": "The goal of this exercise is try out some of the most common options to the  condor_q  command, so that you can view jobs effectively.  The main part of this exercise should take just a few minutes, but if you have more time later, come back and work on the extension ideas at the end to become a  condor_q  expert!",
            "title": "Bonus HTC Exercise 3.1: Explore condor_q"
        },
        {
            "location": "/materials/htc/part3-ex1-queue/#selecting-jobs",
            "text": "The  condor_q  program has many options for selecting which jobs are listed. You have already seen that the default mode is to show only your jobs in \"batch\" mode:  username@learn $  condor_q  You've seen that you can view all jobs (all users) in the submit node's queue by using the  -all  argument:  username@learn $  condor_q -all  And you've seen that you can view more details about queued jobs, with each separate job on a single line using the  -nobatch  option:  username@learn $  condor_q -nobatch username@learn $  condor_q -all -nobatch  Did you know you can also name one or more user IDs on the command line, in which case jobs for all of the named users are listed at once?  username@learn $  condor_q <USERNAME1> <USERNAME2> <USERNAME3>  To list just the jobs associated with a single cluster number:  username@learn $  condor_q <CLUSTER>  For example, if you want to see the jobs in cluster 5678 (i.e.,  5678.0 ,  5678.1 , etc.), you use  condor_q 5678 .  To list a specific job (i.e., cluster.process, as in 5678.0):  username@learn $  condor_q <JOB.ID>  For example, to see job ID 5678.1, you use  condor_q 5678.1 .   Note  You can name more than one cluster, job ID, or combination thereof on the command line, in which case jobs for all  of the named clusters and/or job IDs are listed.   Let\u2019s get some practice using  condor_q  selections!   Using a previous exercise, submit several  sleep  jobs.  List all jobs in the queue \u2014 are there others besides your own?  Practice using all forms of  condor_q  that you have learned:  List just your jobs, with and without batching.  List a specific cluster.  List a specific job ID.  Try listing several users at once.  Try listing several clusters and job IDs at once.    When there are a variety of jobs in the queue, try combining a username and a different user's cluster or job ID in the same command \u2014 what happens?",
            "title": "Selecting Jobs"
        },
        {
            "location": "/materials/htc/part3-ex1-queue/#viewing-a-job-classad",
            "text": "You may have wondered why it is useful to be able to list a single job ID using  condor_q . By itself, it may not be that useful. But, in combination with another option, it is very useful!  If you add the  -long  option to  condor_q  (or its short form,  -l ), it will show the complete ClassAd for each selected job, instead of the one-line summary that you have seen so far. Because job ClassAds may have 80\u201390 attributes (or more), it probably makes the most sense to show the ClassAd for a single job at a time. And you know how to show just one job! Here is what the command looks like:  username@learn $  condor_q -long <JOB.ID>  The output from this command is long and complex. Most of the attributes that HTCondor adds to a job are arcane and uninteresting for us now. But here are some examples of common, interesting attributes taken directly from  condor_q  output (except with some line breaks added to the  Requirements  attribute):  MyType = \"Job\"\nErr = \"sleep.err\"\nUserLog = \"/home/cat/intro-2.1-queue/sleep.log\"\nRequirements = ( IsOSGSchoolSlot =?= true ) &&\n        ( TARGET.Arch == \"X86_64\" ) &&\n        ( TARGET.OpSys == \"LINUX\" ) &&\n        ( TARGET.Disk >= RequestDisk ) &&\n        ( TARGET.Memory >= RequestMemory ) &&\n        ( TARGET.HasFileTransfer )\nClusterId = 2420\nWhenToTransferOutput = \"ON_EXIT\"\nOwner = \"cat\"\nCondorVersion = \"$CondorVersion: 8.5.5 May 03 2016 BuildID: 366162 $\"\nOut = \"sleep.out\"\nCmd = \"/bin/sleep\"\nArguments = \"120\"   Note  Attributes are listed in no particular order and may change from time to time.\nDo not assume anything about the order of attributes in  condor_q  output.   See what you can find in a job ClassAd from your own job.   Using a previous exercise, submit a  sleep  job that sleeps for at least 3 minutes (180 seconds).   Before the job executes, capture its ClassAd and save to a file:  condor_q -l <JOB.ID> > classad-1.txt     After the job starts execution but before it finishes, capture its ClassAd again and save to a file  condor_q -l <JOB.ID> > classad-2.txt     Now examine each saved ClassAd file. Here are a few things to look for:   Can you find attributes that came from your submit file? (E.g., Cmd, Arguments, Out, Err, UserLog, and so forth)  Can you find attributes that could have come from your submit file, but that HTCondor added for you? (E.g., Requirements)  How many of the following attributes can you guess the meaning of?  DiskUsage  ImageSize  BytesSent  JobStatus",
            "title": "Viewing a Job ClassAd"
        },
        {
            "location": "/materials/htc/part3-ex1-queue/#why-is-my-job-not-running",
            "text": "Sometimes, you submit a job and it just sits in the queue in Idle state, never running. It can be difficult to figure out why a job never matches and runs. Fortunately, HTCondor can give you some help.  To ask HTCondor why your job is not running, add the  -better-analyze  option to  condor_q  for the specific job. For example, for job ID 2423.0, the command is:  username@learn $  condor_q -better-analyze  2423 .0  Of course, replace the job ID with your own.  Let\u2019s submit a job that will never run and see what happens. Here is the submit file to use:  executable = /bin/hostname\noutput = norun.out\nerror = norun.err\nlog = norun.log\nshould_transfer_files = YES\nwhen_to_transfer_output = ON_EXIT\nrequest_disk = 10MB\nrequest_memory = 8TB\nqueue  (Do you see what I did?)   Save and submit this file.  Run  condor_q -better-analyze  on the job ID.   There is a lot of output, but a few items are worth highlighting. Here is a sample from my own job (with some lines omitted):  -- Schedd: learn.chtc.wisc.edu : <128.104.100.148:9618?...\n...\n\nJob 98096.000 defines the following attributes:\n\n    RequestDisk = 10240\n    RequestMemory = 8388608\n\nThe Requirements expression for job 98096.000 reduces to these conditions:\n\n\n         Slots\nStep    Matched  Condition\n-----  --------  ---------\n[1]       11227  Target.OpSysMajorVer == 7\n[9]       13098  TARGET.Disk >= RequestDisk\n[11]          0  TARGET.Memory >= RequestMemory\n\nNo successful match recorded.\nLast failed match: Fri Jul 12 15:36:30 2019\n\nReason for last match failure: no match found\n\n98096.000:  Run analysis summary ignoring user priority.  Of 710 machines,\n    710 are rejected by your job's requirements\n      0 reject your job because of their own requirements\n      0 match and are already running your jobs\n      0 match but are serving other users\n      0 are able to run your job\n...  At the end of the summary,  condor_q  provides a breakdown of how  machines  and their own requirements match against my own job's requirements. 710 total machines were considered above, and  all  of them were rejected based on  my job's requirements . In other words, I am asking for something that is not available. But what?  Further up in the output, there is an analysis of the job's requirements, along with how many slots within the pool match each of those requirements. The example above reports that 13098 slots match our small disk request request, but  none  of the slots matched the  TARGET.Memory >= RequestMemory  condition. The output also reports the value used for the  RequestMemory  attribute: my job asked for  8 terabytes  of memory (8,388,608 MB) -- of course no machines matched that part of the expression! That's a lot of memory on today's machines.  The output from  condor_q -analyze  (and  condor_q -better-analyze ) may be helpful or it may not be, depending on your exact case. The example above was constructed so that it would be obvious what the problem was. But in many cases, this is a good place to start looking if you are having problems matching.",
            "title": "Why Is My Job Not Running?"
        },
        {
            "location": "/materials/htc/part3-ex1-queue/#bonus-automatic-formatting-output",
            "text": "Do this exercise only if you have time, though it's pretty awesome!  There is a way to select the specific job attributes you want  condor_q  to tell you about with the  -autoformat  or  -af  option. In this case, HTCondor decides for you how to format the data you ask for from job ClassAd(s). \n(To tell HTCondor how to specially format this information, yourself, you could use the  -format  option, which we're not covering.)  To use autoformatting, use the  -af  option followed by the attribute name, for each attribute that you want to output:  username@learn $  condor_q -all -af Owner ClusterId Cmd moate 2418 /share/test.sh  cat 2421 /bin/sleep  cat 2422 /bin/sleep   Bonus Question : If you wanted to print out the  Requirements  expression of a job, how would you do that with  -af ? Is the output what you expected? (HINT: for ClassAd attributes like \"Requirements\" that are long expressions, instead of plain values, you can use  -af:r  to view the expressions, instead of what it's current evaluation.)",
            "title": "Bonus: Automatic Formatting Output"
        },
        {
            "location": "/materials/htc/part3-ex1-queue/#references",
            "text": "As suggested above, if you want to learn more about  condor_q , you can do some reading:   Read the  condor_q  man page or HTCondor Manual section (same text) to learn about more options  Read about ClassAd attributes in Appendix A of the HTCondor Manual",
            "title": "References"
        },
        {
            "location": "/materials/htc/part3-ex2-status/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nBonus HTC Exercise 3.2: Explore condor_status\n\u00b6\n\n\nThe goal of this exercise is try out some of the most common options to the \ncondor_status\n command, so that you can view slots effectively.\n\n\nThe main part of this exercise should take just a few minutes, but if you have more time later, come back and work on the extension ideas at the end to become a \ncondor_status\n expert!\n\n\nSelecting Slots\n\u00b6\n\n\nThe \ncondor_status\n program has many options for selecting which slots are listed. You've already learned the basic \ncondor_status\n and the \ncondor_status -compact\n variation (which you may wish to retry now, before proceeding).\n\n\nAnother convenient option is to list only those slots that are available now:\n\n\nusername@learn $\n condor_status -avail\n\n\n\n\n\nOf course, the individual execute machines only report their slots to the collector at certain time intervals, so this list will not reflect the up-to-the-second reality of all slots. But this limitation is true of all \ncondor_status\n output, not just with the \n-avail\n option.\n\n\nSimilar to \ncondor_q\n, you can limit the slots that are listed in two easy ways. To list just the slots on a specific machine:\n\n\nusername@learn $\n condor_status <hostname>\n\n\n\n\n\nFor example, if you want to see the slots on \ne2337.chtc.wisc.edu\n (in the CHTC pool):\n\n\nusername@learn $\n condor_status e2337.chtc.wisc.edu\n\n\n\n\n\nTo list a specific slot on a machine:\n\n\nusername@learn $\n condor_status <slot>@<hostname>\n\n\n\n\n\nFor example, to see the \u201cfirst\u201d slot on the machine above:\n\n\nusername@learn $\n condor_status slot1@e2337.chtc.wisc.edu\n\n\n\n\n\n\n\nNote\n\n\nYou can name more than one hostname, slot, or combination thereof on the command line, in which case slots for\n\nall\n of the named hostnames and/or slots are listed.\n\n\n\n\nLet\u2019s get some practice using \ncondor_status\n selections!\n\n\n\n\nList all slots in the pool \u2014 how many are there total?\n\n\nPractice using all forms of \ncondor_status\n that you have learned:\n\n\nList the available slots.\n\n\nList the slots on a specific machine (e.g., \ne2337.chtc.wisc.edu\n).\n\n\nList a specific slot from that machine.\n\n\nTry listing the slots from a few (but not all) machines at once.\n\n\nTry using a mix of hostnames and slot IDs at once.\n\n\n\n\n\n\n\n\nViewing a Slot ClassAd\n\u00b6\n\n\nJust as with \ncondor_q\n, you can use \ncondor_status\n to view the complete ClassAd for a given slot (often confusingly called the \u201cmachine\u201d ad):\n\n\nusername@learn $\n condor_status -long <slot>@<hostname>\n\n\n\n\n\nBecause slot ClassAds may have 150\u2013200 attributes (or more), it probably makes the most sense to show the ClassAd for a single slot at a time, as shown above.\n\n\nHere are some examples of common, interesting attributes taken directly from \ncondor_status\n output:\n\n\nOpSys = \"LINUX\"\nDetectedCpus = 24\nOpSysAndVer = \"SL6\"\nMyType = \"Machine\"\nLoadAvg = 0.99\nTotalDisk = 798098404\nOSIssue = \"Scientific Linux release 6.6 (Carbon)\"\nTotalMemory = 24016\nMachine = \"e242.chtc.wisc.edu\"\nCondorVersion = \"$CondorVersion: 8.5.5 May 03 2016 BuildID: 366162 $\"\nMemory = 1024\n\n\n\n\n\nAs you may be able to tell, there is a mix of attributes about the machine as a whole (hence the name \u201cmachine ad\u201d) and about the slot in particular.\n\n\nGo ahead and examine a machine ClassAd now. I suggest looking at one of the slots on, say, \ne2337.chtc.wisc.edu\n because of its relatively simple configuration.\n\n\nViewing Slots by ClassAd Expression\n\u00b6\n\n\nOften, it is helpful to view slots that meet some particular criteria. For example, if you know that your job needs a lot of memory to run, you may want to see how many high-memory slots there are and whether they are busy. You can filter the list of slots like this using the \n-constraint\n option and a ClassAd expression.\n\n\nFor example, suppose we want to list all slots that are running Scientific Linux 7 (operating system) and have at least 16 GB memory available. Note that memory is reported in units of Megabytes. The command is:\n\n\nusername@learn $\n condor_status -constraint \n'OpSysAndVer == \"CentOS7\" && Memory >= 16000'\n\n\n\n\n\n\n\n\nNote\n\n\nBe very careful with using quote characters appropriately in these commands.\nIn the example above, the single quotes (\n'\n) are for the shell, so that the entire expression is passed to\n\ncondor_status\n untouched, and the double quotes (\n\"\n) surround a string value within the expression itself.\n\n\n\n\nCurrently on CHTC, there are only a few slots that meet these criteria (our high-memory servers, mainly used for metagenomics assemblies).\n\n\nIf you are interested in learning more about writing ClassAd expressions, look at section 4.1 and especially 4.1.4 of the HTCondor Manual. This is definitely advanced material, so if you do not want to read it, that is fine. But if you do, take some time to practice writing expressions for the \ncondor_status -constraint\n command.\n\n\n\n\nNote\n\n\nThe \ncondor_q\n command accepts the \n-constraint\n option as well!\nAs you might expect, the option allows you to limit the jobs that are listed based on a ClassAd expression.\n\n\n\n\nBonus: Formatting Output\n\u00b6\n\n\nThe \ncondor_status\n command accepts the same \n-autoformat\n (\n-af\n) options that \ncondor_q\n accepts, and the options have the same meanings in both commands. Of course, the attributes available in machine ads may differ from the ones that are available in job ads. Use the HTCondor Manual or look at individual slot ClassAds to get a better idea of what attributes are available.\n\n\nFor example, I was curious about the host name and operating system of the slots with more than 32GB of memory:\n\n\nusername@learn $\n condor_status -af Machine -af OpSysAndVer -constraint \n'Memory >= 32000'\n\n\n\n\n\n\nIf you like, spend a few minutes now or later experimenting with \ncondor_status\n formatting.\n\n\nReferences\n\u00b6\n\n\nAs suggested above, if you want to learn more about \ncondor_q\n, you can do some reading:\n\n\n\n\nRead the \ncondor_status\n man page or HTCondor Manual section (same text) to learn about more options\n\n\nRead about \nClassAd attributes\n in the appendix of the HTCondor Manual\n\n\nRead about \nClassAd expressions\n in section 4.1.4 of the HTCondor Manual",
            "title": "Bonus Exercise 3.2"
        },
        {
            "location": "/materials/htc/part3-ex2-status/#bonus-htc-exercise-32-explore-condor_status",
            "text": "The goal of this exercise is try out some of the most common options to the  condor_status  command, so that you can view slots effectively.  The main part of this exercise should take just a few minutes, but if you have more time later, come back and work on the extension ideas at the end to become a  condor_status  expert!",
            "title": "Bonus HTC Exercise 3.2: Explore condor_status"
        },
        {
            "location": "/materials/htc/part3-ex2-status/#selecting-slots",
            "text": "The  condor_status  program has many options for selecting which slots are listed. You've already learned the basic  condor_status  and the  condor_status -compact  variation (which you may wish to retry now, before proceeding).  Another convenient option is to list only those slots that are available now:  username@learn $  condor_status -avail  Of course, the individual execute machines only report their slots to the collector at certain time intervals, so this list will not reflect the up-to-the-second reality of all slots. But this limitation is true of all  condor_status  output, not just with the  -avail  option.  Similar to  condor_q , you can limit the slots that are listed in two easy ways. To list just the slots on a specific machine:  username@learn $  condor_status <hostname>  For example, if you want to see the slots on  e2337.chtc.wisc.edu  (in the CHTC pool):  username@learn $  condor_status e2337.chtc.wisc.edu  To list a specific slot on a machine:  username@learn $  condor_status <slot>@<hostname>  For example, to see the \u201cfirst\u201d slot on the machine above:  username@learn $  condor_status slot1@e2337.chtc.wisc.edu   Note  You can name more than one hostname, slot, or combination thereof on the command line, in which case slots for all  of the named hostnames and/or slots are listed.   Let\u2019s get some practice using  condor_status  selections!   List all slots in the pool \u2014 how many are there total?  Practice using all forms of  condor_status  that you have learned:  List the available slots.  List the slots on a specific machine (e.g.,  e2337.chtc.wisc.edu ).  List a specific slot from that machine.  Try listing the slots from a few (but not all) machines at once.  Try using a mix of hostnames and slot IDs at once.",
            "title": "Selecting Slots"
        },
        {
            "location": "/materials/htc/part3-ex2-status/#viewing-a-slot-classad",
            "text": "Just as with  condor_q , you can use  condor_status  to view the complete ClassAd for a given slot (often confusingly called the \u201cmachine\u201d ad):  username@learn $  condor_status -long <slot>@<hostname>  Because slot ClassAds may have 150\u2013200 attributes (or more), it probably makes the most sense to show the ClassAd for a single slot at a time, as shown above.  Here are some examples of common, interesting attributes taken directly from  condor_status  output:  OpSys = \"LINUX\"\nDetectedCpus = 24\nOpSysAndVer = \"SL6\"\nMyType = \"Machine\"\nLoadAvg = 0.99\nTotalDisk = 798098404\nOSIssue = \"Scientific Linux release 6.6 (Carbon)\"\nTotalMemory = 24016\nMachine = \"e242.chtc.wisc.edu\"\nCondorVersion = \"$CondorVersion: 8.5.5 May 03 2016 BuildID: 366162 $\"\nMemory = 1024  As you may be able to tell, there is a mix of attributes about the machine as a whole (hence the name \u201cmachine ad\u201d) and about the slot in particular.  Go ahead and examine a machine ClassAd now. I suggest looking at one of the slots on, say,  e2337.chtc.wisc.edu  because of its relatively simple configuration.",
            "title": "Viewing a Slot ClassAd"
        },
        {
            "location": "/materials/htc/part3-ex2-status/#viewing-slots-by-classad-expression",
            "text": "Often, it is helpful to view slots that meet some particular criteria. For example, if you know that your job needs a lot of memory to run, you may want to see how many high-memory slots there are and whether they are busy. You can filter the list of slots like this using the  -constraint  option and a ClassAd expression.  For example, suppose we want to list all slots that are running Scientific Linux 7 (operating system) and have at least 16 GB memory available. Note that memory is reported in units of Megabytes. The command is:  username@learn $  condor_status -constraint  'OpSysAndVer == \"CentOS7\" && Memory >= 16000'    Note  Be very careful with using quote characters appropriately in these commands.\nIn the example above, the single quotes ( ' ) are for the shell, so that the entire expression is passed to condor_status  untouched, and the double quotes ( \" ) surround a string value within the expression itself.   Currently on CHTC, there are only a few slots that meet these criteria (our high-memory servers, mainly used for metagenomics assemblies).  If you are interested in learning more about writing ClassAd expressions, look at section 4.1 and especially 4.1.4 of the HTCondor Manual. This is definitely advanced material, so if you do not want to read it, that is fine. But if you do, take some time to practice writing expressions for the  condor_status -constraint  command.   Note  The  condor_q  command accepts the  -constraint  option as well!\nAs you might expect, the option allows you to limit the jobs that are listed based on a ClassAd expression.",
            "title": "Viewing Slots by ClassAd Expression"
        },
        {
            "location": "/materials/htc/part3-ex2-status/#bonus-formatting-output",
            "text": "The  condor_status  command accepts the same  -autoformat  ( -af ) options that  condor_q  accepts, and the options have the same meanings in both commands. Of course, the attributes available in machine ads may differ from the ones that are available in job ads. Use the HTCondor Manual or look at individual slot ClassAds to get a better idea of what attributes are available.  For example, I was curious about the host name and operating system of the slots with more than 32GB of memory:  username@learn $  condor_status -af Machine -af OpSysAndVer -constraint  'Memory >= 32000'   If you like, spend a few minutes now or later experimenting with  condor_status  formatting.",
            "title": "Bonus: Formatting Output"
        },
        {
            "location": "/materials/htc/part3-ex2-status/#references",
            "text": "As suggested above, if you want to learn more about  condor_q , you can do some reading:   Read the  condor_status  man page or HTCondor Manual section (same text) to learn about more options  Read about  ClassAd attributes  in the appendix of the HTCondor Manual  Read about  ClassAd expressions  in section 4.1.4 of the HTCondor Manual",
            "title": "References"
        },
        {
            "location": "/materials/htc/part3-ex3-job-retry/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nBonus HTC Exercise 3.3: Retries\n\u00b6\n\n\nThe goal of this exercise is to demonstrate running a job that intermittently fails and thus could benefit from having HTCondor automatically retry it.\n\n\nThis first part of the exercise should take only a few minutes, and is designed to setup the next exercises.\n\n\nBad Job\n\u00b6\n\n\nLet\u2019s assume that a colleague has shared with you a program, and it fails once in a while. In the real world, we would probably just fix the program, but what if you cannot change the software? Unfortunately, this situation happens more often than we would like.\n\n\nBelow is a Python script that fails once in a while.\nWe will not fix it, but instead use it to simulate a program that can fail and that we \ncannot\n fix.\n\n\n#!/usr/bin/env python3\n\n\n\n# murphy.py simulates a real program with real problems\n\n\nimport\n \nrandom\n\n\nimport\n \nsys\n\n\nimport\n \ntime\n\n\n\n# For one out of every three attempts, simulate a runtime error\n\n\nif\n \nrandom\n.\nrandint\n(\n0\n,\n \n2\n)\n \n==\n \n0\n:\n\n    \n# Intentionally don't print any output\n\n    \nsys\n.\nexit\n(\n15\n)\n\n\nelse\n:\n\n    \ntime\n.\nsleep\n(\n3\n)\n\n    \nprint\n(\n\"All work done correctly\"\n)\n\n\n\n# By convention, zero exit code means success\n\n\nsys\n.\nexit\n(\n0\n)\n\n\n\n\n\n\nLet\u2019s see what happens when a program like this one is run in HTCondor.\n\n\n\n\nIn a new directory for this exercise, save the script above as \nmurphy.py\n.\n\n\nWrite a submit file for the script; \nqueue 20\n instances of the job and be sure to ask for 20\u00a0MB of memory and disk.\n\n\nSubmit the file, note the ClusterId, and wait for the jobs to finish.\n\n\n\n\nWhat output do you expect? What output did you get? If you are curious about the exit code from the job, it is saved in completed jobs in \ncondor_history\n in the \nExitCode\n attribute. The following command will show the \nExitCode\n for a given cluster of jobs:\n\n\nusername@learn $\n condor_history <CLUSTER> -af ProcId ExitCode\n\n\n\n\n\n(Be sure to replace \n<cluster>\n with your actual cluster ID. The command may take a minute or so to complete.)\n\n\nHow many of the jobs succeeded? How many failed?\n\n\nRetrying Failed Jobs\n\u00b6\n\n\nNow let\u2019s see if we can solve the problem of jobs that fail once in a while. In this particular case, if HTCondor runs a failed job again, it has a good chance of succeeding. Not all failing jobs are like this, but in this case it is a reasonable assumption.\n\n\nFrom the lecture materials, implement the \nmax_retries\n feature to retry any job with a non-zero exit code up to 5 times, then resubmit the jobs. Did your change work?\n\n\nAfter the jobs have finished, examine the log file(s) to see what happened in detail. Did any jobs need to be restarted? Another way to see how many restarts there were is to look at the \nNumJobStarts\n attribute of a completed job with the \ncondor_history\n command, in the same way you looked at the \nExitCode\n attribute earlier. Does the number of retries seem correct? For those jobs which did need to be retried, what is their \nExitCode\n; and what about the \nExitCode\n from earlier execution attempts?\n\n\nA (Too) Long Running Job\n\u00b6\n\n\nSometimes, an ill-behaved job will get stuck in a loop and run forever, instead of exiting with a failure code, and it may just need to be re-run (or run on a different execute server) to complete without getting stuck. We can modify our Python program to simulate this kind of bad job with the following file:\n\n\n#!/usr/bin/env python3\n\n\n\n# murphy.py simulate a real program with real problems\n\n\nimport\n \nrandom\n\n\nimport\n \nsys\n\n\nimport\n \ntime\n\n\n\n# For one out of every three attempts, simulate an \"infinite\" loop\n\n\nif\n \nrandom\n.\nrandint\n(\n0\n,\n \n2\n)\n \n==\n \n0\n:\n\n    \n# Intentionally don't print any output\n\n    \ntime\n.\nsleep\n(\n3600\n)\n\n    \nsys\n.\nexit\n(\n15\n)\n\n\nelse\n:\n\n    \ntime\n.\nsleep\n(\n3\n)\n\n    \nprint\n(\n\"All work done correctly\"\n)\n\n\n\n# By convention, zero exit code means success\n\n\nsys\n.\nexit\n(\n0\n)\n\n\n\n\n\n\nLet\u2019s see what happens when a program like this one is run in HTCondor.\n\n\n\n\nSave the script to a new file named \nmurphy2.py\n.\n\n\nCopy your previous submit file to a new name and change the \nexecutable\n to \nmurphy2.py\n.\n\n\nIf you like, submit the new file\u00a0\u2014 but after a while be sure to remove the whole cluster to clear out the \u201chung\u201d jobs.\n\n\n\n\nNow try to change the submit file to automatically remove any jobs that \nrun\n for more than one minute. You can make this change with just a single line in your submit file\n\n\nperiodic_remove = (JobStatus == 2) && ( (CurrentTime - EnteredCurrentStatus) > 60 )\n\n\n\n\n\n\n\n\n\nSubmit the new file. Do the long running jobs get removed? What does \ncondor_history\n show for the cluster after all jobs are done? Which job status (i.e. idle, held, running) do you think \nJobStatus == 2\n corresponds to?\n\n\n\n\n\n\nBonus Exercise\n\u00b6\n\n\nIf you have time, edit your submit file so that instead of removing long running jobs,\nHTCondor will automatically put the long-running job on hold,\nand then automatically release it.",
            "title": "Bonus Exercise 3.3"
        },
        {
            "location": "/materials/htc/part3-ex3-job-retry/#bonus-htc-exercise-33-retries",
            "text": "The goal of this exercise is to demonstrate running a job that intermittently fails and thus could benefit from having HTCondor automatically retry it.  This first part of the exercise should take only a few minutes, and is designed to setup the next exercises.",
            "title": "Bonus HTC Exercise 3.3: Retries"
        },
        {
            "location": "/materials/htc/part3-ex3-job-retry/#bad-job",
            "text": "Let\u2019s assume that a colleague has shared with you a program, and it fails once in a while. In the real world, we would probably just fix the program, but what if you cannot change the software? Unfortunately, this situation happens more often than we would like.  Below is a Python script that fails once in a while.\nWe will not fix it, but instead use it to simulate a program that can fail and that we  cannot  fix.  #!/usr/bin/env python3  # murphy.py simulates a real program with real problems  import   random  import   sys  import   time  # For one out of every three attempts, simulate a runtime error  if   random . randint ( 0 ,   2 )   ==   0 : \n     # Intentionally don't print any output \n     sys . exit ( 15 )  else : \n     time . sleep ( 3 ) \n     print ( \"All work done correctly\" )  # By convention, zero exit code means success  sys . exit ( 0 )   Let\u2019s see what happens when a program like this one is run in HTCondor.   In a new directory for this exercise, save the script above as  murphy.py .  Write a submit file for the script;  queue 20  instances of the job and be sure to ask for 20\u00a0MB of memory and disk.  Submit the file, note the ClusterId, and wait for the jobs to finish.   What output do you expect? What output did you get? If you are curious about the exit code from the job, it is saved in completed jobs in  condor_history  in the  ExitCode  attribute. The following command will show the  ExitCode  for a given cluster of jobs:  username@learn $  condor_history <CLUSTER> -af ProcId ExitCode  (Be sure to replace  <cluster>  with your actual cluster ID. The command may take a minute or so to complete.)  How many of the jobs succeeded? How many failed?",
            "title": "Bad Job"
        },
        {
            "location": "/materials/htc/part3-ex3-job-retry/#retrying-failed-jobs",
            "text": "Now let\u2019s see if we can solve the problem of jobs that fail once in a while. In this particular case, if HTCondor runs a failed job again, it has a good chance of succeeding. Not all failing jobs are like this, but in this case it is a reasonable assumption.  From the lecture materials, implement the  max_retries  feature to retry any job with a non-zero exit code up to 5 times, then resubmit the jobs. Did your change work?  After the jobs have finished, examine the log file(s) to see what happened in detail. Did any jobs need to be restarted? Another way to see how many restarts there were is to look at the  NumJobStarts  attribute of a completed job with the  condor_history  command, in the same way you looked at the  ExitCode  attribute earlier. Does the number of retries seem correct? For those jobs which did need to be retried, what is their  ExitCode ; and what about the  ExitCode  from earlier execution attempts?",
            "title": "Retrying Failed Jobs"
        },
        {
            "location": "/materials/htc/part3-ex3-job-retry/#a-too-long-running-job",
            "text": "Sometimes, an ill-behaved job will get stuck in a loop and run forever, instead of exiting with a failure code, and it may just need to be re-run (or run on a different execute server) to complete without getting stuck. We can modify our Python program to simulate this kind of bad job with the following file:  #!/usr/bin/env python3  # murphy.py simulate a real program with real problems  import   random  import   sys  import   time  # For one out of every three attempts, simulate an \"infinite\" loop  if   random . randint ( 0 ,   2 )   ==   0 : \n     # Intentionally don't print any output \n     time . sleep ( 3600 ) \n     sys . exit ( 15 )  else : \n     time . sleep ( 3 ) \n     print ( \"All work done correctly\" )  # By convention, zero exit code means success  sys . exit ( 0 )   Let\u2019s see what happens when a program like this one is run in HTCondor.   Save the script to a new file named  murphy2.py .  Copy your previous submit file to a new name and change the  executable  to  murphy2.py .  If you like, submit the new file\u00a0\u2014 but after a while be sure to remove the whole cluster to clear out the \u201chung\u201d jobs.   Now try to change the submit file to automatically remove any jobs that  run  for more than one minute. You can make this change with just a single line in your submit file  periodic_remove = (JobStatus == 2) && ( (CurrentTime - EnteredCurrentStatus) > 60 )    Submit the new file. Do the long running jobs get removed? What does  condor_history  show for the cluster after all jobs are done? Which job status (i.e. idle, held, running) do you think  JobStatus == 2  corresponds to?",
            "title": "A (Too) Long Running Job"
        },
        {
            "location": "/materials/htc/part3-ex3-job-retry/#bonus-exercise",
            "text": "If you have time, edit your submit file so that instead of removing long running jobs,\nHTCondor will automatically put the long-running job on hold,\nand then automatically release it.",
            "title": "Bonus Exercise"
        },
        {
            "location": "/materials/osg/temp/",
            "text": "OSG-VSP Exercises Coming Soon!\n\u00b6\n\n\nThis is just a placeholder document for OSG Virtual School Pilot 2020 exercises,\nwhich will be posted soon.",
            "title": "Placeholder"
        },
        {
            "location": "/materials/osg/temp/#osg-vsp-exercises-coming-soon",
            "text": "This is just a placeholder document for OSG Virtual School Pilot 2020 exercises,\nwhich will be posted soon.",
            "title": "OSG-VSP Exercises Coming Soon!"
        },
        {
            "location": "/materials/sw/part1-ex1-download/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nSoftware Exercise 1.1: Using a Pre-compiled Binary\n\u00b6\n\n\nIn this exercise, we will run a job using a downloaded, pre-compiled binary. This exercise should take 10-15 minutes.\n\n\nBackground\n\u00b6\n\n\nThis is the simplest scenario for using a particular software program on the Open Science Grid - downloading a pre-compiled binary and using it to run jobs. \n\n\nOur Software Example\n\u00b6\n\n\nThe software we will be using for this example is a common tool for aligning genome and protein sequences against a\nreference database, the BLAST program.\n\n\n\n\n\n\nSearch the internet for the BLAST software.  Searches might include \"blast executable or \"download blast software\".  Hopefully these searches will lead you to a BLAST website page that looks like this:\n\n\n\n\n\n\n\n\nClick on the title that says \n\"Download BLAST\"\n and then look for the link that has the \nlatest installation and source code\n.  You should end up on a page with a list of each version of BLAST that is available for different operating systems.\n\n\n\n\n\n\nWe could download the source and compile it ourselves, but instead, we're going to use one of the pre-built binaries.  Before proceeding, look at the list of downloads and try to determine which one you want. \n\n\n\n\n\n\nBased on our operating system, we want to use the Linux binary, which is labelled with the \nx64-linux\n suffix. \n\n\n\n\nAll the other links are either for source code or other operating systems. \n\n\n\n\n\n\nWhile logged into \nlogin05.osgconnect.net\n, create a directory for this exercise. Then download the appropriate \ntar.gz\n file and un-tar it. You can download the file directly from the BLAST website using \nwget\n or download our local copy with the command below: \n\n\nuser@login $\n wget http://proxy.chtc.wisc.edu/SQUID/osgschool19/ncbi-blast-2.10.1+-x64-linux.tar.gz\n\nuser@login $\n tar -xzf ncbi-blast-2.10.1+-x64-linux.tar.gz\n\n\n\n\n\n\n\n\n\nWe're going to be using the \nblastx\n binary in our job. Where is it in the directory you just downloaded?\n\n\n\n\n\n\nCopy the Input Files\n\u00b6\n\n\nTo run BLAST, we need an input file and reference database. For this example, we'll use the \"pdbaa\" database, which contains sequences for the protein structure from the Protein Data Bank. For our input file, we'll use an abbreviated fasta file with mouse genome information.\n\n\n\n\n\n\nDownload these files to your current directory: \n\n\nusername@login $\n wget http://proxy.chtc.wisc.edu/SQUID/osgschool20/pdbaa.tar.gz\n\nusername@login $\n wget http://proxy.chtc.wisc.edu/SQUID/osgschool20/mouse.fa\n\n\n\n\n\n\n\n\n\nUntar the \npdbaa\n database: \n\n\nusername@login $\n tar -xzf pdbaa.tar.gz\n\n\n\n\n\n\n\n\n\nSubmitting the Job\n\u00b6\n\n\nWe now have our program (the pre-compiled \nblastx\n binary) and our input files, so all that remains is to create the submit file. The form of a typical \nblastx\n command looks something like this:\n\n\nblastx -db <database_dir/prefix> -query <input_file> -out <output_file>\n\n\n\n\n\n\n\n\n\nCopy a submit file from one of the intro exercises to use for this exercise. \n\n\n\n\n\n\nThink about which lines you will need to change or add to your submit file in order to submit the job successfully. In particular:    \n\n\n\n\nWhat is the executable?\n\n\nHow can you indicate the entire command line sequence above?\n\n\nWhich files need to be transferred in addition to the executable?\n\n\nDoes this job require a certain type of operating system?\n\n\nDo you have any idea how much memory or disk to request?\n\n\n\n\n\n\n\n\nTry to answer these questions and modify your submit file appropriately.\n\n\n\n\n\n\nOnce you have done all you can, check your submit file against the lines below, which contain the exact components to run this particular job.\n\n\n\n\n\n\nThe executable is \nblastx\n, which is located in the \nbin\n directory of our downloaded BLAST directory. We need to use the \narguments\n line in the submit file to express the rest of the command. \n\n\nexecutable = ncbi-blast-2.10.1+/bin/blastx\narguments = -db pdbaa/pdbaa -query mouse.fa -out results.txt\n\n\n\n\n\n\n\n\n\nThe BLAST program requires our input file and database, so they must be transferred with \ntransfer_input_files\n. \n\n\ntransfer_input_files = pdbaa, mouse.fa\n\n\n\n\n\n\n\n\n\nLet's assume that we've run this program before, and we know that 1GB of disk and 1GB of memory will be MORE than enough (the 'log' file will tell us how accurate we are, after the job runs): \n\n\nrequest_memory = 1GB\nrequest_disk = 1GB\n\n\n\n\n\n\n\n\n\nBecause we downloaded a Linux-specific binary, we need to request machines that are running Linux. \n\n\nrequirements = (OSGVO_OS_STRING == \"RHEL 7\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubmit the blast job using \ncondor_submit\n. Once the job starts, it should run in just a few minutes and produce a file called \nresults.txt\n.",
            "title": "Exercise 1.1"
        },
        {
            "location": "/materials/sw/part1-ex1-download/#software-exercise-11-using-a-pre-compiled-binary",
            "text": "In this exercise, we will run a job using a downloaded, pre-compiled binary. This exercise should take 10-15 minutes.",
            "title": "Software Exercise 1.1: Using a Pre-compiled Binary"
        },
        {
            "location": "/materials/sw/part1-ex1-download/#background",
            "text": "This is the simplest scenario for using a particular software program on the Open Science Grid - downloading a pre-compiled binary and using it to run jobs.",
            "title": "Background"
        },
        {
            "location": "/materials/sw/part1-ex1-download/#our-software-example",
            "text": "The software we will be using for this example is a common tool for aligning genome and protein sequences against a\nreference database, the BLAST program.    Search the internet for the BLAST software.  Searches might include \"blast executable or \"download blast software\".  Hopefully these searches will lead you to a BLAST website page that looks like this:     Click on the title that says  \"Download BLAST\"  and then look for the link that has the  latest installation and source code .  You should end up on a page with a list of each version of BLAST that is available for different operating systems.    We could download the source and compile it ourselves, but instead, we're going to use one of the pre-built binaries.  Before proceeding, look at the list of downloads and try to determine which one you want.     Based on our operating system, we want to use the Linux binary, which is labelled with the  x64-linux  suffix.    All the other links are either for source code or other operating systems.     While logged into  login05.osgconnect.net , create a directory for this exercise. Then download the appropriate  tar.gz  file and un-tar it. You can download the file directly from the BLAST website using  wget  or download our local copy with the command below:   user@login $  wget http://proxy.chtc.wisc.edu/SQUID/osgschool19/ncbi-blast-2.10.1+-x64-linux.tar.gz user@login $  tar -xzf ncbi-blast-2.10.1+-x64-linux.tar.gz    We're going to be using the  blastx  binary in our job. Where is it in the directory you just downloaded?",
            "title": "Our Software Example"
        },
        {
            "location": "/materials/sw/part1-ex1-download/#copy-the-input-files",
            "text": "To run BLAST, we need an input file and reference database. For this example, we'll use the \"pdbaa\" database, which contains sequences for the protein structure from the Protein Data Bank. For our input file, we'll use an abbreviated fasta file with mouse genome information.    Download these files to your current directory:   username@login $  wget http://proxy.chtc.wisc.edu/SQUID/osgschool20/pdbaa.tar.gz username@login $  wget http://proxy.chtc.wisc.edu/SQUID/osgschool20/mouse.fa    Untar the  pdbaa  database:   username@login $  tar -xzf pdbaa.tar.gz",
            "title": "Copy the Input Files"
        },
        {
            "location": "/materials/sw/part1-ex1-download/#submitting-the-job",
            "text": "We now have our program (the pre-compiled  blastx  binary) and our input files, so all that remains is to create the submit file. The form of a typical  blastx  command looks something like this:  blastx -db <database_dir/prefix> -query <input_file> -out <output_file>    Copy a submit file from one of the intro exercises to use for this exercise.     Think about which lines you will need to change or add to your submit file in order to submit the job successfully. In particular:       What is the executable?  How can you indicate the entire command line sequence above?  Which files need to be transferred in addition to the executable?  Does this job require a certain type of operating system?  Do you have any idea how much memory or disk to request?     Try to answer these questions and modify your submit file appropriately.    Once you have done all you can, check your submit file against the lines below, which contain the exact components to run this particular job.    The executable is  blastx , which is located in the  bin  directory of our downloaded BLAST directory. We need to use the  arguments  line in the submit file to express the rest of the command.   executable = ncbi-blast-2.10.1+/bin/blastx\narguments = -db pdbaa/pdbaa -query mouse.fa -out results.txt    The BLAST program requires our input file and database, so they must be transferred with  transfer_input_files .   transfer_input_files = pdbaa, mouse.fa    Let's assume that we've run this program before, and we know that 1GB of disk and 1GB of memory will be MORE than enough (the 'log' file will tell us how accurate we are, after the job runs):   request_memory = 1GB\nrequest_disk = 1GB    Because we downloaded a Linux-specific binary, we need to request machines that are running Linux.   requirements = (OSGVO_OS_STRING == \"RHEL 7\")      Submit the blast job using  condor_submit . Once the job starts, it should run in just a few minutes and produce a file called  results.txt .",
            "title": "Submitting the Job"
        },
        {
            "location": "/materials/sw/part1-ex2-wrapper/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: #008; } \n\n\n\nSoftware Exercise 1.2: Writing a Wrapper Script\n\u00b6\n\n\nIn this exercise, you will create a wrapper script to run the same program (\nblastx\n) as the \nprevious exercise\n.\n\n\nBackground\n\u00b6\n\n\nWrapper scripts are a useful tool for running software that can't be compiled into one piece, needs to be installed with every job, or just for running extra steps.  A wrapper script can either install the software from the source code, or use an already existing software (as in this exercise). Not only does this portability technique work with almost any kind of software that can be locally installed, it also allows for a great deal of control and flexibility for what happens within your job. Once you can write a script to handle your software (and often your data as well), you can submit a large variety of workflows to a distributed computing system like the Open Science Grid.\n\n\nFor this exercise, we will write a wrapper script as an alternate way to run the same job as the previous exercise. \n\n\nWrapper Script, part 1\n\u00b6\n\n\nOur wrapper script will be a bash script that runs several commands.\n\n\n\n\n\n\nIn the same directory as the last exercise (still logged into \nlogin05.osgconnect.net\n) make a file called \nrun_blast.sh\n. \n\n\n\n\n\n\nThe first line we'll place in the script is the basic command for running blast. Based on our previous submit file, what command needs to go into the script? Once you have an idea, check against the example below:  \n\n\n#!/bin/bash\n\n\nncbi-blast-2.10.1+/bin/blastx -db pdbaa/pdbaa -query mouse.fa -out results.txt\n\n\n\n\n\n\n\nNote\n\n\nThe \"header\" of \n#!/bin/bash\n will tell the computer that this is a bash shell script and can be run in the same way that  you would run individual commands on the command line.\n\n\n\n\n\n\n\n\nSubmit File Changes\n\u00b6\n\n\nWe now need to make some changes to our submit file.\n\n\n\n\n\n\nMake a copy of your previous submit file and open it. \n\n\n\n\n\n\nSince we are now using a wrapper script, that will be our job's executable. Replace the original \nblastx\n exeuctable with the name of our wrapper script and comment out the arguments line.  \n\n\nexecutable = run_blast.sh \n#arguments =\n\n\n\n\n\n\n\n\n\nNote that since the \nblastx\n program is no longer listed as the executable, it will be need to be included in \ntransfer_input_files\n. Instead of transferring just that program, we will transfer the original downloaded \ntar.gz\n file. To achieve efficiency, we'll also transfer the pdbaa database as the original \ntar.gz\n file instead of as the unzipped folder: \n\n\ntransfer_input_files = \npdbaa.tar.gz\n, mouse.fa, ncbi-blast-2.9.0+-x64-linux.tar.gz\n\n\n\n\n\n\n\n\n\nIf you really want to be on top of things, look at the log file for the last exercise, and update your memory and disk requests to be just slightly above the actual \"Usage\" values in the log. \n\n\n\n\n\n\nBefore submitting, make sure to make the below additional changes to the wrapper script!\n\n\nWrapper Script, part 2\n\u00b6\n\n\nNow that our database and BLAST software are being transferred to the job as \ntar.gz\n files, our script needs to accommodate.\n\n\n\n\n\n\nOpening your \nrun_blast.sh\n script, add two commands at the start to un-tar the BLAST and pdbaa \ntar.gz\n files. See the \nprevious exercise\n if you're not sure what these commands looks like. \n\n\n\n\n\n\nIn order to distinguish this job from our previous job, change the output file name to something besides \nresults.txt\n. \n\n\n\n\n\n\nThe completed script \nrun_blast.sh\n should look like this: \n\n\n#/bin/bash\n\n\ntar -xzf ncbi-blast-2.10.1+-x64-linux.tar.gz \ntar -xzf pdbaa.tar.gz\n\nncbi-blast-2.10.1+/bin/blastx -db pdbaa/pdbaa -query mouse.fa -out results2.txt\n\n\n\n\n\n\n\n\n\nWhile not strictly necessary, it's a good idea to enable executable permissions on the wrapper script, like so: \n\n\nusername@login $\n chmod u+x run_blast.sh\n\n\n\n\n\n\n\n\n\nYour job is now ready to submit. Submit it using \ncondor_submit\n and monitor using \ncondor_q\n.",
            "title": "Exercise 1.2"
        },
        {
            "location": "/materials/sw/part1-ex2-wrapper/#software-exercise-12-writing-a-wrapper-script",
            "text": "In this exercise, you will create a wrapper script to run the same program ( blastx ) as the  previous exercise .",
            "title": "Software Exercise 1.2: Writing a Wrapper Script"
        },
        {
            "location": "/materials/sw/part1-ex2-wrapper/#background",
            "text": "Wrapper scripts are a useful tool for running software that can't be compiled into one piece, needs to be installed with every job, or just for running extra steps.  A wrapper script can either install the software from the source code, or use an already existing software (as in this exercise). Not only does this portability technique work with almost any kind of software that can be locally installed, it also allows for a great deal of control and flexibility for what happens within your job. Once you can write a script to handle your software (and often your data as well), you can submit a large variety of workflows to a distributed computing system like the Open Science Grid.  For this exercise, we will write a wrapper script as an alternate way to run the same job as the previous exercise.",
            "title": "Background"
        },
        {
            "location": "/materials/sw/part1-ex2-wrapper/#wrapper-script-part-1",
            "text": "Our wrapper script will be a bash script that runs several commands.    In the same directory as the last exercise (still logged into  login05.osgconnect.net ) make a file called  run_blast.sh .     The first line we'll place in the script is the basic command for running blast. Based on our previous submit file, what command needs to go into the script? Once you have an idea, check against the example below:    #!/bin/bash \n\nncbi-blast-2.10.1+/bin/blastx -db pdbaa/pdbaa -query mouse.fa -out results.txt   Note  The \"header\" of  #!/bin/bash  will tell the computer that this is a bash shell script and can be run in the same way that  you would run individual commands on the command line.",
            "title": "Wrapper Script, part 1"
        },
        {
            "location": "/materials/sw/part1-ex2-wrapper/#submit-file-changes",
            "text": "We now need to make some changes to our submit file.    Make a copy of your previous submit file and open it.     Since we are now using a wrapper script, that will be our job's executable. Replace the original  blastx  exeuctable with the name of our wrapper script and comment out the arguments line.    executable = run_blast.sh \n#arguments =    Note that since the  blastx  program is no longer listed as the executable, it will be need to be included in  transfer_input_files . Instead of transferring just that program, we will transfer the original downloaded  tar.gz  file. To achieve efficiency, we'll also transfer the pdbaa database as the original  tar.gz  file instead of as the unzipped folder:   transfer_input_files =  pdbaa.tar.gz , mouse.fa, ncbi-blast-2.9.0+-x64-linux.tar.gz    If you really want to be on top of things, look at the log file for the last exercise, and update your memory and disk requests to be just slightly above the actual \"Usage\" values in the log.     Before submitting, make sure to make the below additional changes to the wrapper script!",
            "title": "Submit File Changes"
        },
        {
            "location": "/materials/sw/part1-ex2-wrapper/#wrapper-script-part-2",
            "text": "Now that our database and BLAST software are being transferred to the job as  tar.gz  files, our script needs to accommodate.    Opening your  run_blast.sh  script, add two commands at the start to un-tar the BLAST and pdbaa  tar.gz  files. See the  previous exercise  if you're not sure what these commands looks like.     In order to distinguish this job from our previous job, change the output file name to something besides  results.txt .     The completed script  run_blast.sh  should look like this:   #/bin/bash \n\ntar -xzf ncbi-blast-2.10.1+-x64-linux.tar.gz \ntar -xzf pdbaa.tar.gz\n\nncbi-blast-2.10.1+/bin/blastx -db pdbaa/pdbaa -query mouse.fa -out results2.txt    While not strictly necessary, it's a good idea to enable executable permissions on the wrapper script, like so:   username@login $  chmod u+x run_blast.sh    Your job is now ready to submit. Submit it using  condor_submit  and monitor using  condor_q .",
            "title": "Wrapper Script, part 2"
        },
        {
            "location": "/materials/sw/part2-ex1-compiling/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nSoftware Exercise 2.1: Compile Statically Linked Code\n\u00b6\n\n\nThe goal of this exercise is to compile and statically link a piece of code and then submit it as a job. This exercise should take 5-10 minutes.\n\n\nBackground\n\u00b6\n\n\nThere is a large amount of scientific software that is available as source code. Source code is usually a group of text files (code) meant to be downloaded and then compiled into a \nbinary file\n which a computer can understand. Sometimes the source code depends on other pieces of code called libraries. If the source code is linked \nstatically\n, these libraries are bundled into the compilation with the source code, creating a \nstatic binary\n which can be run on any computer with the same operating system.\n\n\nOur Software Example\n\u00b6\n\n\nFor this compiling example, we will use a script written in C. C code depends on libraries and therefore will benefit from being statically linked.\n\n\nOur C code prints 7 rows of Pascal's triangle.\n\n\n\n\nLog into the OSG submit node \nlogin05.osgconnect.net\n. Create a directory for this exercise and \ncd\n into it.\n\n\nCopy and paste the following code into a file named \npascal.c\n.\n#include\n \n\"stdio.h\"\n\n\n\nlong\n \nfactorial\n(\nint\n);\n\n\n\nint\n \nmain\n()\n\n\n{\n\n\nint\n \ni\n,\n \nn\n,\n \nc\n;\n\n\nn\n=\n7\n;\n\n\nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n<\n \nn\n;\n \ni\n++\n){\n\n  \nfor\n \n(\nc\n \n=\n \n0\n;\n \nc\n \n<=\n \n(\nn\n \n-\n \ni\n \n-\n \n2\n);\n \nc\n++\n)\n\n  \nprintf\n(\n\" \"\n);\n\n      \nfor\n \n(\nc\n \n=\n \n0\n \n;\n \nc\n \n<=\n \ni\n;\n \nc\n++\n)\n\n         \nprintf\n(\n\"%ld \"\n,\nfactorial\n(\ni\n)\n/\n(\nfactorial\n(\nc\n)\n*\nfactorial\n(\ni\n-\nc\n)));\n\n      \nprintf\n(\n\"\n\\n\n\"\n);\n\n   \n}\n\n   \nreturn\n \n0\n;\n\n\n}\n\n\n\nlong\n \nfactorial\n(\nint\n \nn\n)\n\n\n{\n\n   \nint\n \nc\n;\n\n   \nlong\n \nresult\n \n=\n \n1\n;\n\n   \nfor\n \n(\nc\n \n=\n \n1\n;\n \nc\n \n<=\n \nn\n;\n \nc\n++\n)\n\n         \nresult\n \n=\n \nresult\n*\nc\n;\n\n   \nreturn\n \nresult\n;\n\n\n}\n\n\n\n\n\n\n\n\n\n\nCompiling\n\u00b6\n\n\nIn order to use this code in a job, we will first need to statically compile the code. Recall the slide from the lecture - where \ncan\n we compile and where \nshould\n we compile? In particular:\n\n\n\n\nWhere is the compiler available?\n\n\nHow computationally intensive will this compilation be?    \n\n\n\n\n\n\n\n\n\n\n\nThink about these questions before moving on. Where do you think we should compile?\n\n\n\n\n\n\nMost linux servers (including our submit node) have the \ngcc\n (GNU compiler collection) installed, so we already have a compiler on the submit node. Furthermore, this is a simple piece of C code, so the compilation will not be computationally intensive. Thus, we should be able to compile directly on the submit node. \n\n\n\n\n\n\nCompile the code, using the command: \n\n\nusername@login $\n gcc -static pascal.c -o pascal\n\n\n\n\n\nNote that we have added the \n-static\n option to make sure that the compiled binary includes the necessary libraries. This will allow the code to run on any Linux machine, no matter where those libraries are located. \n\n\n\n\n\n\nVerify that the compiled binary was statically linked:\n\n\nusername@login $\n file pascal\n\n\n\n\n\n\n\n\n\nThe Linux \nfile\n command provides information about the \ntype\n or \nkind\n of file that is given as an argument. In this case, you should get output like this:\n\n\nusername@host $\n file pascal\n\npascal: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux), \nstatically linked\n,\n\n\nfor GNU/Linux 2.6.18, not stripped\n\n\n\n\n\n\nNote the blue text, which clearly states that this executable (software) is statically linked. The same command run on a non-statically linked executable file would include the text \ndynamically linked (uses shared libs)\n instead. So with this simple verification step, which could even be run on files that you did not compile yourself, you have some further reassurance that it is safe to use on other Linux machines. (Bonus exercise: Try the \nfile\n command on lots of other files)\n\n\nSubmit the Job\n\u00b6\n\n\nNow that our code is compiled, we can use it to submit a job.\n\n\n\n\n\n\nThink about what submit file lines we need to use to run this job:\n\n\n\n\nAre there input files?\n\n\nAre there command line arguments?\n\n\nWhere is its output written?\n\n\n\n\n\n\n\n\nBased on what you thought about in 1., find a submit file from earlier that you can modify to run our compiled \npascal\n code.\n\n\n\n\n\n\nCopy it to the directory with the \npascal\n binary and make those changes. \n\n\n\n\n\n\nSubmit the job using \ncondor_submit\n. \n\n\n\n\n\n\nOnce the job has run and left the queue, you should be able to see the results (seven rows of Pascal's triangle) in the \n.out\n file created by the job.",
            "title": "Exercise 2.1"
        },
        {
            "location": "/materials/sw/part2-ex1-compiling/#software-exercise-21-compile-statically-linked-code",
            "text": "The goal of this exercise is to compile and statically link a piece of code and then submit it as a job. This exercise should take 5-10 minutes.",
            "title": "Software Exercise 2.1: Compile Statically Linked Code"
        },
        {
            "location": "/materials/sw/part2-ex1-compiling/#background",
            "text": "There is a large amount of scientific software that is available as source code. Source code is usually a group of text files (code) meant to be downloaded and then compiled into a  binary file  which a computer can understand. Sometimes the source code depends on other pieces of code called libraries. If the source code is linked  statically , these libraries are bundled into the compilation with the source code, creating a  static binary  which can be run on any computer with the same operating system.",
            "title": "Background"
        },
        {
            "location": "/materials/sw/part2-ex1-compiling/#our-software-example",
            "text": "For this compiling example, we will use a script written in C. C code depends on libraries and therefore will benefit from being statically linked.  Our C code prints 7 rows of Pascal's triangle.   Log into the OSG submit node  login05.osgconnect.net . Create a directory for this exercise and  cd  into it.  Copy and paste the following code into a file named  pascal.c . #include   \"stdio.h\"  long   factorial ( int );  int   main ()  {  int   i ,   n ,   c ;  n = 7 ;  for   ( i   =   0 ;   i   <   n ;   i ++ ){ \n   for   ( c   =   0 ;   c   <=   ( n   -   i   -   2 );   c ++ ) \n   printf ( \" \" ); \n       for   ( c   =   0   ;   c   <=   i ;   c ++ ) \n          printf ( \"%ld \" , factorial ( i ) / ( factorial ( c ) * factorial ( i - c ))); \n       printf ( \" \\n \" ); \n    } \n    return   0 ;  }  long   factorial ( int   n )  { \n    int   c ; \n    long   result   =   1 ; \n    for   ( c   =   1 ;   c   <=   n ;   c ++ ) \n          result   =   result * c ; \n    return   result ;  }",
            "title": "Our Software Example"
        },
        {
            "location": "/materials/sw/part2-ex1-compiling/#compiling",
            "text": "In order to use this code in a job, we will first need to statically compile the code. Recall the slide from the lecture - where  can  we compile and where  should  we compile? In particular:   Where is the compiler available?  How computationally intensive will this compilation be?          Think about these questions before moving on. Where do you think we should compile?    Most linux servers (including our submit node) have the  gcc  (GNU compiler collection) installed, so we already have a compiler on the submit node. Furthermore, this is a simple piece of C code, so the compilation will not be computationally intensive. Thus, we should be able to compile directly on the submit node.     Compile the code, using the command:   username@login $  gcc -static pascal.c -o pascal  Note that we have added the  -static  option to make sure that the compiled binary includes the necessary libraries. This will allow the code to run on any Linux machine, no matter where those libraries are located.     Verify that the compiled binary was statically linked:  username@login $  file pascal    The Linux  file  command provides information about the  type  or  kind  of file that is given as an argument. In this case, you should get output like this:  username@host $  file pascal pascal: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux),  statically linked ,  for GNU/Linux 2.6.18, not stripped   Note the blue text, which clearly states that this executable (software) is statically linked. The same command run on a non-statically linked executable file would include the text  dynamically linked (uses shared libs)  instead. So with this simple verification step, which could even be run on files that you did not compile yourself, you have some further reassurance that it is safe to use on other Linux machines. (Bonus exercise: Try the  file  command on lots of other files)",
            "title": "Compiling"
        },
        {
            "location": "/materials/sw/part2-ex1-compiling/#submit-the-job",
            "text": "Now that our code is compiled, we can use it to submit a job.    Think about what submit file lines we need to use to run this job:   Are there input files?  Are there command line arguments?  Where is its output written?     Based on what you thought about in 1., find a submit file from earlier that you can modify to run our compiled  pascal  code.    Copy it to the directory with the  pascal  binary and make those changes.     Submit the job using  condor_submit .     Once the job has run and left the queue, you should be able to see the results (seven rows of Pascal's triangle) in the  .out  file created by the job.",
            "title": "Submit the Job"
        },
        {
            "location": "/materials/sw/part2-ex2-prepackaged/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: #008; } \n\n\n\nSoftware Exercise 2.2: Pre-package a Research Code\n\u00b6\n\n\nIn this exercise, you will create an installation of a Bayesian inference package (OpenBUGS) and then create a wrapper script to unpack that installation to run jobs. It should take 30-35 minutes.\n\n\nBackground\n\u00b6\n\n\nSome software cannot be compiled into a single executable, whether you compile it yourself (as in \nSoftware Exercise 2.1\n) or download it already compiled (as in \nSoftware Exercise 1.1\n). In this case, it is necessary to download or create a portable copy of the software and then use a wrapper script (as in \nthis exercise\n) to \"install\" or run the software on a per job basis. This script can either install the software from the source code, or (as in this exercise), unpack a portable software package that you've pre-built yourself.\n\n\nOur Software Example\n\u00b6\n\n\nFor this exercise, we will be using the Bayseian inference package OpenBUGS. OpenBUGS is a good example of software that is not compiled to a single executable; it has multiple executables as well as a helper library.\n\n\n\n\n\n\nDo an internet search to find the Open BUGS software downloads page.\n\n\n\n\n\n\nCreate a directory for this exercise on the CHTC submit server \nlearn.chtc.wisc.edu\n (\nnot\n \ntraining.osgconnect.net\n), \n\n\n\n\n\n\nBecause you can't download the OpenBUGS source tarball directly, download it from our \"squid\" webserver: \n\n\nusername@learn $\n wget http://proxy.chtc.wisc.edu/SQUID/osgschool19/OpenBUGS-3.2.3.tar.gz\n\n\n\n\n\n\n\n\n\nWhere to Prepare\n\u00b6\n\n\nOur goal is to pre-build an OpenBUGS installation, and then write a script that will unpack that installation and run a simulation.\n\n\n\n\n\n\nWhere can we create this pre-built installation? Based on the end of the lecture, what are our options and which would be most appropriate? Make a guess before moving on.\n\n\n\n\n\n\nBecause we're on the CHTC-based submit node (\nlearn.chtc.wisc.edu\n), we have the option of using an interactive job to build the OpenBUGS installation. This is a good option because the submit server is already busy with lots of users and we don't know how long the OpenBUGS install will take. We'll also target specific build servers with extra tools by adding some special requirements to our interactive job. \n\n\n\n\n\n\nCopy the following lines into a file named \nbuild.submit\n\n\nlog = build.log\n\nshould_transfer_files = YES\nwhen_to_transfer_output = ON_EXIT\ntransfer_input_files =\n\n+IsBuildJob = true\nrequirements = (IsBuildSlot == true)\n\nrequest_cpus = 1\nrequest_disk = 2GB\nrequest_memory = 2GB\n\nqueue\n\n\n\n\n\n\n\n\n\nNote the lack of executable. Condor doesn't need an executable for this job because it will be interactive, meaning \nyou\n are running the commands instead of Condor.\n\n\n\n\n\n\nIn order to create the installation, we will need the source code to come with us. The \ntransfer_input_files\n line is blank - \nfill it in with the name of our Open BUGS source tarball\n.\n\n\n\n\n\n\nTo request an interactive job, we will add a \n-i\n flag to the \ncondor_submit\n command. The whole command you enter should look like this: \n\n\nusername@learn $\n condor_submit -i build.submit\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead Through Installation Documentation\n\u00b6\n\n\nWhile you're waiting for the interactive job to start, you can start reading the Open BUGS installation documentation online.\n\n\n\n\nFind the installation instructions for Open BUGS.\n\n\nOn the downloads page, there are short instructions for how to install Open BUGS. There are two options shown for installation -- which should we use?\n\n\nThe first installation option given uses \nsudo\n -- which is an administrative permission that you won't have as a normal user. Luckily, as described in the instructions, you can use the \n--prefix\n option to set where Open BUGS will be installed, which will allow us to install it without administrative permissions.\n\n\n\n\nInstallation\n\u00b6\n\n\nYour interactive job should have started by now and we've learned about installing our program. Let's test it out.\n\n\n\n\n\n\nBefore we follow the installation instructions, we should create a directory to hold our installation. You can create this in the current directory. \n\n\nusername@host $\n mkdir openbugs\n\n\n\n\n\n\n\n\n\nNow run the commands to unpack the source code: \n\n\nusername@host $\n tar -zxf OpenBUGS-3.2.3.tar.gz\n\nusername@host $\n \ncd\n OpenBUGS-3.2.3\n\n\n\n\n\n\n\n\n\nNow we can follow the second set of installation instructions. For the prefix, we'll use the variable \n$PWD\n to capture the name of our current working directory and then a relative path to the \nopenbugs\n directory we created in step 1: \n\n\nusername@host $\n ./configure --prefix\n=\n$PWD\n/../openbugs\n\nusername@host $\n make\n\nusername@host $\n make install\n\n\n\n\n\n\n\n\n\nGo back to the job's main working directory\n: \n\n\nusername@host $\n \ncd\n ..\n\n\n\n\n\nand confirm that our installation procedure created \nbin\n,  \nlib\n, and \nshare\n directories. \n\n\nusername@host $\n ls openbugs\n\nbin lib share\n\n\n\n\n\n\n\n\n\n\nNow we want to package up our installation, so we can use it in other jobs. We can do this by compressing any necessary directories into a single gzipped tarball. \n\n\nusername@host $\n tar -czf openbugs.tar.gz openbugs/\n\n\n\n\n\n\n\n\n\nOnce everything is complete, type \nexit\n to leave the interactive job. Make sure that your tarball is in the main working directory - it will be transferred back to the submit server automatically. \n\n\nusername@learn $\n \nexit\n\n\n\n\n\n\n\n\n\n\nNote that we now have two tarballs in our directory -- the \nsource\n tarball (\nOpenBUGS-3.2.3.tar.gz\n), which we will no longer need and our newly built installation (\nopenbugs.tar.gz\n) which is what we will actually be using to run jobs.\n\n\nWrapper Script\n\u00b6\n\n\nNow that we've created our portable installation, we need to write a script that opens and uses the installation, similar to the process we used in a \nprevious exercise\n. These steps should be performed back on the submit server (\nlearn.chtc.wisc.edu\n).\n\n\n\n\n\n\nCreate a script called \nrun_openbugs.sh\n. \n\n\n\n\n\n\nThe script will first need to untar our installation, so the script should start out like this:  \n\n\n#!/bin/bash\n\n\ntar -xzf openbugs.tar.gz\n\n\n\n\n\n\n\n\n\nWe're going to use the same \n$(pwd)\n trick from the installation in order to tell the computer how to find Open BUGS. We will do this by setting the \nPATH\n environment variable, to include the directory where Open BUGS is installed: \n\n\nexport\n \nPATH\n=\n$(\npwd\n)\n/openbugs/bin:\n$PATH\n\n\n\n\n\n\n\n\n\n\nFinally, the wrapper script needs to not only setup Open BUGS, but actually run the program. Add the following lines to your \nrun_openbugs.sh\n wrapper script. \n\n\nOpenBUGS < input.txt > results.txt\n\n\n\n\n\n\n\n\n\nMake sure the wrapper script has executable permissions: \n\n\nusername@learn $\n chmod u+x run_openbugs.sh\n\n\n\n\n\n\n\n\n\nRun a Open BUGS job\n\u00b6\n\n\nWe're almost ready! We need two more pieces to run a OpenBUGS job.\n\n\n\n\n\n\nDownload the necessary input files to your directory on the submit server and then untar them. \n\n\nusername@learn $\n wget http://proxy.chtc.wisc.edu/SQUID/osgschool19/openbugs_files.tar.gz\n\nusername@learn $\n tar -xzf openbugs_files.tar.gz\n\n\n\n\n\n\n\n\n\nOur last step is to create a submit file for our Open BUGS job. Think about which lines this submit file will need. Make a copy of a previous submit file (you could use the blast submit file from the \nprevious exercise\n as a base) and modify it as you think necessary.\n\n\n\n\n\n\nThe two most important lines to modify for this job are listed below; check them against your own submit file: \n\n\nexecutable = run_openbugs.sh\ntransfer_input_files = openbugs.tar.gz, openbugs_files/\n\n\n\n\n\nA wrapper script will always be a job's \nexecutable\n.\nWhen using a wrapper script, you must also always remember to transfer the software/source code using\n\ntransfer_input_files\n.\n\n\n\n\nNote\n\n\nThe \n/\n in the \ntransfer_input_files\n line indicates that we are transferring the \ncontents\n of that directory (which in this case, is what we want), rather than the directory itself.\n\n\n\n\n\n\n\n\nSubmit the job with \ncondor_submit\n.\n\n\n\n\n\n\nOnce the job completes, it should produce a \nresults.txt\n file.",
            "title": "Exercise 2.2"
        },
        {
            "location": "/materials/sw/part2-ex2-prepackaged/#software-exercise-22-pre-package-a-research-code",
            "text": "In this exercise, you will create an installation of a Bayesian inference package (OpenBUGS) and then create a wrapper script to unpack that installation to run jobs. It should take 30-35 minutes.",
            "title": "Software Exercise 2.2: Pre-package a Research Code"
        },
        {
            "location": "/materials/sw/part2-ex2-prepackaged/#background",
            "text": "Some software cannot be compiled into a single executable, whether you compile it yourself (as in  Software Exercise 2.1 ) or download it already compiled (as in  Software Exercise 1.1 ). In this case, it is necessary to download or create a portable copy of the software and then use a wrapper script (as in  this exercise ) to \"install\" or run the software on a per job basis. This script can either install the software from the source code, or (as in this exercise), unpack a portable software package that you've pre-built yourself.",
            "title": "Background"
        },
        {
            "location": "/materials/sw/part2-ex2-prepackaged/#our-software-example",
            "text": "For this exercise, we will be using the Bayseian inference package OpenBUGS. OpenBUGS is a good example of software that is not compiled to a single executable; it has multiple executables as well as a helper library.    Do an internet search to find the Open BUGS software downloads page.    Create a directory for this exercise on the CHTC submit server  learn.chtc.wisc.edu  ( not   training.osgconnect.net ),     Because you can't download the OpenBUGS source tarball directly, download it from our \"squid\" webserver:   username@learn $  wget http://proxy.chtc.wisc.edu/SQUID/osgschool19/OpenBUGS-3.2.3.tar.gz",
            "title": "Our Software Example"
        },
        {
            "location": "/materials/sw/part2-ex2-prepackaged/#where-to-prepare",
            "text": "Our goal is to pre-build an OpenBUGS installation, and then write a script that will unpack that installation and run a simulation.    Where can we create this pre-built installation? Based on the end of the lecture, what are our options and which would be most appropriate? Make a guess before moving on.    Because we're on the CHTC-based submit node ( learn.chtc.wisc.edu ), we have the option of using an interactive job to build the OpenBUGS installation. This is a good option because the submit server is already busy with lots of users and we don't know how long the OpenBUGS install will take. We'll also target specific build servers with extra tools by adding some special requirements to our interactive job.     Copy the following lines into a file named  build.submit  log = build.log\n\nshould_transfer_files = YES\nwhen_to_transfer_output = ON_EXIT\ntransfer_input_files =\n\n+IsBuildJob = true\nrequirements = (IsBuildSlot == true)\n\nrequest_cpus = 1\nrequest_disk = 2GB\nrequest_memory = 2GB\n\nqueue    Note the lack of executable. Condor doesn't need an executable for this job because it will be interactive, meaning  you  are running the commands instead of Condor.    In order to create the installation, we will need the source code to come with us. The  transfer_input_files  line is blank -  fill it in with the name of our Open BUGS source tarball .    To request an interactive job, we will add a  -i  flag to the  condor_submit  command. The whole command you enter should look like this:   username@learn $  condor_submit -i build.submit",
            "title": "Where to Prepare"
        },
        {
            "location": "/materials/sw/part2-ex2-prepackaged/#read-through-installation-documentation",
            "text": "While you're waiting for the interactive job to start, you can start reading the Open BUGS installation documentation online.   Find the installation instructions for Open BUGS.  On the downloads page, there are short instructions for how to install Open BUGS. There are two options shown for installation -- which should we use?  The first installation option given uses  sudo  -- which is an administrative permission that you won't have as a normal user. Luckily, as described in the instructions, you can use the  --prefix  option to set where Open BUGS will be installed, which will allow us to install it without administrative permissions.",
            "title": "Read Through Installation Documentation"
        },
        {
            "location": "/materials/sw/part2-ex2-prepackaged/#installation",
            "text": "Your interactive job should have started by now and we've learned about installing our program. Let's test it out.    Before we follow the installation instructions, we should create a directory to hold our installation. You can create this in the current directory.   username@host $  mkdir openbugs    Now run the commands to unpack the source code:   username@host $  tar -zxf OpenBUGS-3.2.3.tar.gz username@host $   cd  OpenBUGS-3.2.3    Now we can follow the second set of installation instructions. For the prefix, we'll use the variable  $PWD  to capture the name of our current working directory and then a relative path to the  openbugs  directory we created in step 1:   username@host $  ./configure --prefix = $PWD /../openbugs username@host $  make username@host $  make install    Go back to the job's main working directory :   username@host $   cd  ..  and confirm that our installation procedure created  bin ,   lib , and  share  directories.   username@host $  ls openbugs bin lib share     Now we want to package up our installation, so we can use it in other jobs. We can do this by compressing any necessary directories into a single gzipped tarball.   username@host $  tar -czf openbugs.tar.gz openbugs/    Once everything is complete, type  exit  to leave the interactive job. Make sure that your tarball is in the main working directory - it will be transferred back to the submit server automatically.   username@learn $   exit     Note that we now have two tarballs in our directory -- the  source  tarball ( OpenBUGS-3.2.3.tar.gz ), which we will no longer need and our newly built installation ( openbugs.tar.gz ) which is what we will actually be using to run jobs.",
            "title": "Installation"
        },
        {
            "location": "/materials/sw/part2-ex2-prepackaged/#wrapper-script",
            "text": "Now that we've created our portable installation, we need to write a script that opens and uses the installation, similar to the process we used in a  previous exercise . These steps should be performed back on the submit server ( learn.chtc.wisc.edu ).    Create a script called  run_openbugs.sh .     The script will first need to untar our installation, so the script should start out like this:    #!/bin/bash \n\ntar -xzf openbugs.tar.gz    We're going to use the same  $(pwd)  trick from the installation in order to tell the computer how to find Open BUGS. We will do this by setting the  PATH  environment variable, to include the directory where Open BUGS is installed:   export   PATH = $( pwd ) /openbugs/bin: $PATH     Finally, the wrapper script needs to not only setup Open BUGS, but actually run the program. Add the following lines to your  run_openbugs.sh  wrapper script.   OpenBUGS < input.txt > results.txt    Make sure the wrapper script has executable permissions:   username@learn $  chmod u+x run_openbugs.sh",
            "title": "Wrapper Script"
        },
        {
            "location": "/materials/sw/part2-ex2-prepackaged/#run-a-open-bugs-job",
            "text": "We're almost ready! We need two more pieces to run a OpenBUGS job.    Download the necessary input files to your directory on the submit server and then untar them.   username@learn $  wget http://proxy.chtc.wisc.edu/SQUID/osgschool19/openbugs_files.tar.gz username@learn $  tar -xzf openbugs_files.tar.gz    Our last step is to create a submit file for our Open BUGS job. Think about which lines this submit file will need. Make a copy of a previous submit file (you could use the blast submit file from the  previous exercise  as a base) and modify it as you think necessary.    The two most important lines to modify for this job are listed below; check them against your own submit file:   executable = run_openbugs.sh\ntransfer_input_files = openbugs.tar.gz, openbugs_files/  A wrapper script will always be a job's  executable .\nWhen using a wrapper script, you must also always remember to transfer the software/source code using transfer_input_files .   Note  The  /  in the  transfer_input_files  line indicates that we are transferring the  contents  of that directory (which in this case, is what we want), rather than the directory itself.     Submit the job with  condor_submit .    Once the job completes, it should produce a  results.txt  file.",
            "title": "Run a Open BUGS job"
        },
        {
            "location": "/materials/sw/part2-ex3-python/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: #008; } \n\n\n\nSoftware Exercise 2.3: Using Python, Pre-Built\n\u00b6\n\n\nIn this exercise, you will install Python, package your installation, and then use it to run jobs. It should take about 20 minutes.\n\n\nBackground\n\u00b6\n\n\nWe chose Python as the language for this example because: a) it is a common language used for scientific computing and b) it has a straightforward installation process and is fairly portable.\n\n\nRunning any Python script requires an installation of the Python interpreter. The Python interpreter is what we're using when we type \npython\n at the command line. In order to run Python jobs on a distributed system, you will need to install the Python interpreter (what we often refer to as just \"installing Python\"), within the job, then run your Python script.\n\n\nThere are two installation approaches. The approach we will cover in this exercise is that of \"pre-building\" the installation. We will install Python to a specific directory, and then create a tarball of that installation directory. We can then use our tarball within jobs to run Python scripts.\n\n\nInteractive Job for Pre-Building\n\u00b6\n\n\nThe first step in our job process is building a Python installation that we can package up.\n\n\n\n\nCreate a directory for this exercise on \nlearn.chtc.wisc.edu\n and \ncd\n into it.\n\n\n\n\nDownload the Python source code from \nhttps://www.python.org/\n. \n\n\nusername@learn $\n wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tgz\n\n\n\n\n\n\n\n\n\nOf our options - submit server, interactive job, personal computer - which should we use for this installation/packaging process? Once you have a guess, move to the next step.\n\n\n\n\n\n\nDue to the number of people on our submit server, we shouldn't use the submit server. Your own computer probably doesn't have the right operating system. The best place to install will be an interactive job. For this job, we can use the same interactive submit file as Exercise 3.4, with one change. What is it?\n\n\n\n\n\n\nMake a copy of the interactive submit file from \nExercise 3.4\n and change the \ntransfer_input_files\n line to the Python tarball you just downloaded. Then submit it using the \n-i\n flag. \n\n\nusername@learn $\n condor_submit -i build.submit\n\n\n\n\n\n\n\n\n\nOnce the interactive job begins, we can start our installation process. First, we have to determine how to install Python to a specific location in our working directory.\n\n\n\n\nUntar the Python source tarball and look at the \nREADME.rst\n file in the \nPython-3.7.0\n directory.  You'll want to look for the \"Build Instructions\" header.  What will the main installation steps be?  What command is required for the final installation?  Once you've tried to answer these questions, move to the next step.\n\n\n\n\nThere are some basic installation instructions near the top of the \nREADME\n. Based on that short introduction, we can see the main steps of installation will be: \n\n\n./configure\nmake\nmake test\nsudo make install\n\n\n\n\n\nThis three-stage process (configure, make, make install) is a common  way to install many software packages.   The default installation  location for Python requires \nsudo\n (administrative privileges) to install. However, we'd like to install to a specific location in the working directory  so that we can compress that installation directory into a tarball. \n\n\n\n\n\n\nYou can often use an option called \n-prefix\n with the \nconfigure\n script to change the default installation directory. Let's see if the Python \nconfigure\n script has this option by using the \"help\" option (as suggested in the \nREADME.rst\n file): \n\n\nusername@host $\n ./configure --help\n\n\n\n\n\nSure enough, there's a list of all the different options that can be passed to the \nconfigure\n script, which includes \n--prefix\n.  (To see the \n--prefix\n option, you may need to scroll towards the top of the output.)  Therefore, we can use the  \n$PWD\n command in order to set the path correctly to a custom installation directory. \n\n\n\n\n\n\n\n\n\n\nNow let's actually install Python!\n\n\n\n\n\n\nFrom the job's main working directory\n, create a directory to hold the installation. \n\n\nusername@host $\n \ncd\n \n$_CONDOR_SCRATCH_DIR\n\n\nusername@host $\n mkdir python\n\n\n\n\n\n\n\n\n\nMove into the \nPython-3.7.0\n directory and run the installation commands. These may take a few minutes each. \n\n\nusername@host $\n \ncd\n Python-3.7.0\n\nusername@host $\n ./configure --prefix\n=\n$PWD\n/../python\n\nusername@host $\n make\n\nusername@host $\n make install\n\n\n\n\n\n\n\nNote\n\n\nThe installation instructions in the \nREADME.rst\n file have a \nmake test\n step \nbetween the \nmake\n and \nmake install\n steps.  As this step isn't strictly necessary (and takes a long time), it's been omitted above.  \n\n\n\n\n\n\n\n\nIf I move back to the main job working directory, and look in the \npython\n subdirectory, I should see a Python installation. \n\n\nusername@host $\n \ncd\n ..\n\nusername@host $\n ls python/\n\nbin  include  lib  share\n\n\n\n\n\n\n\n\n\n\nI have successfully created a self-contained Python installation. Now it just needs to be tarred up! \n\n\nusername@host $\n tar -czf prebuilt_python.tar.gz python/\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore exiting, we might want to know how we installed Python for later reference.  Enter the following commands to save our history to a file: \n\n\nusername@host $\n \nhistory\n > python_install.txt\n\n\n\n\n\n\n\n\n\nExit the interactive job. \n\n\nusername@host $\n \nexit\n\n\n\n\n\n\n\n\n\n\nPython Script\n\u00b6\n\n\n\n\n\n\nCreate a script with the following lines called \nfib.py\n. \n\n\nimport\n \nsys\n\n\nimport\n \nos\n\n\n\nif\n \nlen\n(\nsys\n.\nargv\n)\n \n!=\n \n2\n:\n\n    \nprint\n(\n'Usage: \n%s\n MAXIMUM'\n \n%\n \n(\nos\n.\npath\n.\nbasename\n(\nsys\n.\nargv\n[\n0\n])))\n\n    \nsys\n.\nexit\n(\n1\n)\n\n\nmaximum\n \n=\n \nint\n(\nsys\n.\nargv\n[\n1\n])\n\n\nn1\n \n=\n \nn2\n \n=\n \n1\n\n\nwhile\n \nn2\n \n<=\n \nmaximum\n:\n\n    \nn1\n,\n \nn2\n \n=\n \nn2\n,\n \nn1\n \n+\n \nn2\n\n\nprint\n(\n'The greatest Fibonacci number up to \n%d\n is \n%d\n'\n \n%\n \n(\nmaximum\n,\n \nn1\n))\n\n\n\n\n\n\n\n\n\n\nWhat command line arguments does this script take? Try running it on the submit server.\n\n\n\n\n\n\nWrapper Script\n\u00b6\n\n\nWe now have our Python installation and our Python script - we just need to write a wrapper script to run them.\n\n\n\n\nWhat steps do you think the wrapper script needs to perform? Create a file called \nrun_fib.sh\n and write them out in plain English before moving to the next step.\n\n\nOur script will need to\n\n\nuntar our \nprebuilt_python.tar.gz\n file\n\n\naccess the \npython\n command from our installation to run our \nfib.py\n script\n\n\n\n\n\n\nTry turning your plain English steps into commands that the computer can run.\n\n\n\n\nYour final \nrun_fib.sh\n script should look something like this: \n\n\n#!/bin/bash\n\n\ntar xzf prebuilt_python.tar.gz \npython/bin/python3 fib.py \n90\n\n\n\n\n\n\nor\n\n\n#!/bin/bash\n\n\ntar xzf prebuilt_python.tar.gz \n\nexport\n \nPATH\n=\n$(\npwd\n)\n/python/bin:\n$PATH\n \npython3 fib.py \n90\n\n\n\n\n\n\n\n\n\n\nMake sure your \nrun_fib.sh\n script is executable.\n\n\n\n\n\n\nSubmit File\n\u00b6\n\n\n\n\n\n\nMake a copy of a previous submit file in your local directory (the OpenBugs submit file could be a good starting point). What changes need to be made to run this Python job? \n\n\n\n\n\n\nModify your submit file, then make sure you've included the key lines below: \n\n\nexecutable = run_fib.sh\ntransfer_input_files = fib.py, prebuilt_python.tar.gz\n\n\n\n\n\n\n\n\n\nSubmit the job using \ncondor_submit\n. \n\n\n\n\n\n\nCheck the \n.out\n file to see if the job completed.",
            "title": "Exercise 2.3"
        },
        {
            "location": "/materials/sw/part2-ex3-python/#software-exercise-23-using-python-pre-built",
            "text": "In this exercise, you will install Python, package your installation, and then use it to run jobs. It should take about 20 minutes.",
            "title": "Software Exercise 2.3: Using Python, Pre-Built"
        },
        {
            "location": "/materials/sw/part2-ex3-python/#background",
            "text": "We chose Python as the language for this example because: a) it is a common language used for scientific computing and b) it has a straightforward installation process and is fairly portable.  Running any Python script requires an installation of the Python interpreter. The Python interpreter is what we're using when we type  python  at the command line. In order to run Python jobs on a distributed system, you will need to install the Python interpreter (what we often refer to as just \"installing Python\"), within the job, then run your Python script.  There are two installation approaches. The approach we will cover in this exercise is that of \"pre-building\" the installation. We will install Python to a specific directory, and then create a tarball of that installation directory. We can then use our tarball within jobs to run Python scripts.",
            "title": "Background"
        },
        {
            "location": "/materials/sw/part2-ex3-python/#interactive-job-for-pre-building",
            "text": "The first step in our job process is building a Python installation that we can package up.   Create a directory for this exercise on  learn.chtc.wisc.edu  and  cd  into it.   Download the Python source code from  https://www.python.org/ .   username@learn $  wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tgz    Of our options - submit server, interactive job, personal computer - which should we use for this installation/packaging process? Once you have a guess, move to the next step.    Due to the number of people on our submit server, we shouldn't use the submit server. Your own computer probably doesn't have the right operating system. The best place to install will be an interactive job. For this job, we can use the same interactive submit file as Exercise 3.4, with one change. What is it?    Make a copy of the interactive submit file from  Exercise 3.4  and change the  transfer_input_files  line to the Python tarball you just downloaded. Then submit it using the  -i  flag.   username@learn $  condor_submit -i build.submit    Once the interactive job begins, we can start our installation process. First, we have to determine how to install Python to a specific location in our working directory.   Untar the Python source tarball and look at the  README.rst  file in the  Python-3.7.0  directory.  You'll want to look for the \"Build Instructions\" header.  What will the main installation steps be?  What command is required for the final installation?  Once you've tried to answer these questions, move to the next step.   There are some basic installation instructions near the top of the  README . Based on that short introduction, we can see the main steps of installation will be:   ./configure\nmake\nmake test\nsudo make install  This three-stage process (configure, make, make install) is a common  way to install many software packages.   The default installation  location for Python requires  sudo  (administrative privileges) to install. However, we'd like to install to a specific location in the working directory  so that we can compress that installation directory into a tarball.     You can often use an option called  -prefix  with the  configure  script to change the default installation directory. Let's see if the Python  configure  script has this option by using the \"help\" option (as suggested in the  README.rst  file):   username@host $  ./configure --help  Sure enough, there's a list of all the different options that can be passed to the  configure  script, which includes  --prefix .  (To see the  --prefix  option, you may need to scroll towards the top of the output.)  Therefore, we can use the   $PWD  command in order to set the path correctly to a custom installation directory.       Now let's actually install Python!    From the job's main working directory , create a directory to hold the installation.   username@host $   cd   $_CONDOR_SCRATCH_DIR  username@host $  mkdir python    Move into the  Python-3.7.0  directory and run the installation commands. These may take a few minutes each.   username@host $   cd  Python-3.7.0 username@host $  ./configure --prefix = $PWD /../python username@host $  make username@host $  make install   Note  The installation instructions in the  README.rst  file have a  make test  step \nbetween the  make  and  make install  steps.  As this step isn't strictly necessary (and takes a long time), it's been omitted above.       If I move back to the main job working directory, and look in the  python  subdirectory, I should see a Python installation.   username@host $   cd  .. username@host $  ls python/ bin  include  lib  share     I have successfully created a self-contained Python installation. Now it just needs to be tarred up!   username@host $  tar -czf prebuilt_python.tar.gz python/      Before exiting, we might want to know how we installed Python for later reference.  Enter the following commands to save our history to a file:   username@host $   history  > python_install.txt    Exit the interactive job.   username@host $   exit",
            "title": "Interactive Job for Pre-Building"
        },
        {
            "location": "/materials/sw/part2-ex3-python/#python-script",
            "text": "Create a script with the following lines called  fib.py .   import   sys  import   os  if   len ( sys . argv )   !=   2 : \n     print ( 'Usage:  %s  MAXIMUM'   %   ( os . path . basename ( sys . argv [ 0 ]))) \n     sys . exit ( 1 )  maximum   =   int ( sys . argv [ 1 ])  n1   =   n2   =   1  while   n2   <=   maximum : \n     n1 ,   n2   =   n2 ,   n1   +   n2  print ( 'The greatest Fibonacci number up to  %d  is  %d '   %   ( maximum ,   n1 ))     What command line arguments does this script take? Try running it on the submit server.",
            "title": "Python Script"
        },
        {
            "location": "/materials/sw/part2-ex3-python/#wrapper-script",
            "text": "We now have our Python installation and our Python script - we just need to write a wrapper script to run them.   What steps do you think the wrapper script needs to perform? Create a file called  run_fib.sh  and write them out in plain English before moving to the next step.  Our script will need to  untar our  prebuilt_python.tar.gz  file  access the  python  command from our installation to run our  fib.py  script    Try turning your plain English steps into commands that the computer can run.   Your final  run_fib.sh  script should look something like this:   #!/bin/bash \n\ntar xzf prebuilt_python.tar.gz \npython/bin/python3 fib.py  90   or  #!/bin/bash \n\ntar xzf prebuilt_python.tar.gz  export   PATH = $( pwd ) /python/bin: $PATH  \npython3 fib.py  90     Make sure your  run_fib.sh  script is executable.",
            "title": "Wrapper Script"
        },
        {
            "location": "/materials/sw/part2-ex3-python/#submit-file",
            "text": "Make a copy of a previous submit file in your local directory (the OpenBugs submit file could be a good starting point). What changes need to be made to run this Python job?     Modify your submit file, then make sure you've included the key lines below:   executable = run_fib.sh\ntransfer_input_files = fib.py, prebuilt_python.tar.gz    Submit the job using  condor_submit .     Check the  .out  file to see if the job completed.",
            "title": "Submit File"
        },
        {
            "location": "/materials/sw/part2-ex4-matlab/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: #008; } \n\n\n\nSoftware Exercise 2.4: Running Compiled Matlab\n\u00b6\n\n\nThe goal of this exercise is to compile Matlab code and run it. This exercise will draw on the idea of writing a wrapper script to install and run code, first introduced in \nExercise 1.2\n and should take 25-30 minutes.\n\n\nBackground\n\u00b6\n\n\nMatlab is licensed; however, unlike most licensed software, it has the ability to be compiled and the compiled code can be run without a license. We will be compiling Matlab \n.m\n files into a binary file and running that binary using a set of files called the Matlab runtime.\n\n\nMatlab Code\n\u00b6\n\n\n\n\nLog in to the CHTC submit server (\nlearn.chtc.wisc.edu\n).\n\n\nCreate a directory for this exercise and \ncd\n into it . \n\n\nCopy the following code into a file called \nmatrix.m\n \nA = randi(100,4,4)\nb = randi(100,4,1);\nx = A*b\nsave results.txt x -ascii\n\n\n\n\n\n\n\n\n\nCompiling Matlab Code\n\u00b6\n\n\nThe first step in making Matlab portable is compiling our Matlab script.\nTo compile this code, we need to access the machines with the Matlab compiler installed.\nFor this exercise, we will use the compilers installed on special CHTC build machines.\nIn the CHTC pool, you can't use \nssh\n to directly connect to these machines.\nInstead, you must submit an interactive job (similar to \nExercise 2.2\n) that\nspecifically requests these build machines.\n\n\n\n\n\n\nCreate a file called \ncompile.submit\n with the lines below: \n\n\nlog = compile.log\n\nshould_transfer_files = YES\nwhen_to_transfer_output = ON_EXIT\ntransfer_input_files = matrix.m\n\n+IsBuildJob = true\nrequest_memory = 1GB\nrequest_disk = 512MB\n\nqueue\n\n\n\n\n\n\n\n\n\nYou can initiate the interactive job by using \ncondor_submit\n 's \n-i\n option. Enter the following command: \n\n\nusername@learn $\n condor_submit -i compile.submit\n\n\n\n\n\nMake sure you've submitted this command from \nlearn.chtc.wisc.edu\n! Once the job starts, continue with the following instructions.\n\n\n\n\n\n\nSince you are a guest user on our system, you will need to set your \nHOME\n directory by running this command: \n\n\nusername@build $\n \nexport\n \nHOME\n=\n$PWD\n\n\n\n\n\n\n\n\n\n\nThe Matlab software on these build servers is accessible via modules, just like the software installed on OSG Connect. Check which modules are available and then load the older version of Matlab. \n\n\nusername@build $\n module load MATLAB/R2015b\n\n\n\n\n\n\n\n\n\nOnce the module is loaded (you can check by running \nmodule list\n), compile the \nmatrix.m\n file with this command: \n\n\nusername@build $\n mcc -m -R -singleCompThread -R -nodisplay -R -nojvm matrix.m\n\n\n\n\n\nThe extra arguments to the \nmcc\n command are very important here. Matlab, by default, will run on as many CPUs as it can find. This can be a big problem  when running on someone else's computers, because your Matlab code might interfere with what the owner wants. The \n-singleCompThread\n option  compiles the code to run on a single CPU, avoiding this problem. In addition, the \n-nodisplay\n and \n-nojvm\n options turn off the display (which won't exist  where the code runs). \n\n\n\n\n\n\nTo exit the interactive session, type \nexit\n\n\n\n\n\n\nNow that you're back on the submit server, look at the files that were created by the Matlab compiler. Which one is the compiled binary?\n\n\n\n\n\n\nMatlab Runtime\n\u00b6\n\n\nThe newly compiled binary will require the 2015b Matlab runtime to run. You can download the runtime from the Mathworks website and build it yourself, but to save time, for this exercise you can use the pre-built runtimes hosted by CHTC.\n\n\n\n\nDownload the 2015b Matlab runtime hosted by CHTC: \nusername@learn $\n wget http://proxy.chtc.wisc.edu/SQUID/r2015b.tar.gz\n\n\n\n\n\n\n\n\n\nWrapper Script\n\u00b6\n\n\nWe will need a wrapper script to open the Matlab runtime and then run our compiled Matlab code. Our wrapper script will need to accomplish the following steps:\n\n\n\n\nUnpack the transferred runtime\n\n\nSet the environment variables\n\n\nRun our compiled matlab code\n\n\n\n\nFortunately, the Matlab compiler has pre-written most of this wrapper script for us!\n\n\n\n\n\n\nTake a look at \nrun_matrix.sh\n. Which of the above steps do we need to add? Once you have an idea, move to the next step.\n\n\n\n\n\n\nWe'll need to add commands to unpack the runtime (which will have been transferred with the job). Add this line to the beginning of the \nrun_matrix.sh\n file, after \n#!/bin/bash\n and the comments, but before \nexe_name=$0\n : \n\n\ntar -xzf r2015b.tar.gz\n\n\n\n\n\n\n\n\n\nLook at \nreadme.txt\n to determine what arguments our wrapper script requires. Once you have an idea, move to the next step.\n\n\n\n\n\n\nThe name of the Matlab runtime directory is a required argument to the wrapper script \nrun_matrix.sh\n. We'll have to do a little extra work to find out the name of that directory. Run this command\n\n\ntar -tf r2015b.tar.gz\n\n\n\n\n\n\n\n\n\n\nThe output of the previous command is a list of all the files in the tar.gz file. What is the name of the first folder of the path for each file? This is the name of the runtime directory, and the argument you should pass to \nrun_matrix.sh\n.  \n\n\n\n\n\n\nSubmitting the Job\n\u00b6\n\n\n\n\n\n\nCopy an existing submit file into your current directory. The submit file we used for  \nExercise 1.2\n example would be a good candidate, as that example also used a wrapper script. \n\n\n\n\n\n\nModify your submit file for this job. \n\n\n\n\n\n\nCheck your changes against the list below.\n\n\n\n\n\n\nThe \nexecutable\n for this job is going to be our wrapper script \nrun_matrix.sh\n. \n\n\nexecutable = run_matrix.sh\n\n\n\n\n\n\n\n\n\nYou need to transfer the compiled binary \nmatrix\n, as well as the runtime \n.tar.gz\n file, using \ntransfer_input_files\n. \n\n\ntransfer_input_files = matrix, r2015b.tar.gz\n\n\n\n\n\n\n\n\n\nThe argument for the executable (\nrun_matrix.sh\n) is \"v90\", as that is the name of the un-tarred runtime directory. \n\n\narguments = v90\n\n\n\n\n\n\n\n\n\nWe need to request plenty of disk space for the runtime. \n\n\nrequest_disk = 2GB\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubmit the job using \ncondor_submit\n.  \n\n\n\n\n\n\nAfter it completes, the job should have produced a file called \nresults.txt\n.",
            "title": "Exercise 2.4"
        },
        {
            "location": "/materials/sw/part2-ex4-matlab/#software-exercise-24-running-compiled-matlab",
            "text": "The goal of this exercise is to compile Matlab code and run it. This exercise will draw on the idea of writing a wrapper script to install and run code, first introduced in  Exercise 1.2  and should take 25-30 minutes.",
            "title": "Software Exercise 2.4: Running Compiled Matlab"
        },
        {
            "location": "/materials/sw/part2-ex4-matlab/#background",
            "text": "Matlab is licensed; however, unlike most licensed software, it has the ability to be compiled and the compiled code can be run without a license. We will be compiling Matlab  .m  files into a binary file and running that binary using a set of files called the Matlab runtime.",
            "title": "Background"
        },
        {
            "location": "/materials/sw/part2-ex4-matlab/#matlab-code",
            "text": "Log in to the CHTC submit server ( learn.chtc.wisc.edu ).  Create a directory for this exercise and  cd  into it .   Copy the following code into a file called  matrix.m   A = randi(100,4,4)\nb = randi(100,4,1);\nx = A*b\nsave results.txt x -ascii",
            "title": "Matlab Code"
        },
        {
            "location": "/materials/sw/part2-ex4-matlab/#compiling-matlab-code",
            "text": "The first step in making Matlab portable is compiling our Matlab script.\nTo compile this code, we need to access the machines with the Matlab compiler installed.\nFor this exercise, we will use the compilers installed on special CHTC build machines.\nIn the CHTC pool, you can't use  ssh  to directly connect to these machines.\nInstead, you must submit an interactive job (similar to  Exercise 2.2 ) that\nspecifically requests these build machines.    Create a file called  compile.submit  with the lines below:   log = compile.log\n\nshould_transfer_files = YES\nwhen_to_transfer_output = ON_EXIT\ntransfer_input_files = matrix.m\n\n+IsBuildJob = true\nrequest_memory = 1GB\nrequest_disk = 512MB\n\nqueue    You can initiate the interactive job by using  condor_submit  's  -i  option. Enter the following command:   username@learn $  condor_submit -i compile.submit  Make sure you've submitted this command from  learn.chtc.wisc.edu ! Once the job starts, continue with the following instructions.    Since you are a guest user on our system, you will need to set your  HOME  directory by running this command:   username@build $   export   HOME = $PWD     The Matlab software on these build servers is accessible via modules, just like the software installed on OSG Connect. Check which modules are available and then load the older version of Matlab.   username@build $  module load MATLAB/R2015b    Once the module is loaded (you can check by running  module list ), compile the  matrix.m  file with this command:   username@build $  mcc -m -R -singleCompThread -R -nodisplay -R -nojvm matrix.m  The extra arguments to the  mcc  command are very important here. Matlab, by default, will run on as many CPUs as it can find. This can be a big problem  when running on someone else's computers, because your Matlab code might interfere with what the owner wants. The  -singleCompThread  option  compiles the code to run on a single CPU, avoiding this problem. In addition, the  -nodisplay  and  -nojvm  options turn off the display (which won't exist  where the code runs).     To exit the interactive session, type  exit    Now that you're back on the submit server, look at the files that were created by the Matlab compiler. Which one is the compiled binary?",
            "title": "Compiling Matlab Code"
        },
        {
            "location": "/materials/sw/part2-ex4-matlab/#matlab-runtime",
            "text": "The newly compiled binary will require the 2015b Matlab runtime to run. You can download the runtime from the Mathworks website and build it yourself, but to save time, for this exercise you can use the pre-built runtimes hosted by CHTC.   Download the 2015b Matlab runtime hosted by CHTC:  username@learn $  wget http://proxy.chtc.wisc.edu/SQUID/r2015b.tar.gz",
            "title": "Matlab Runtime"
        },
        {
            "location": "/materials/sw/part2-ex4-matlab/#wrapper-script",
            "text": "We will need a wrapper script to open the Matlab runtime and then run our compiled Matlab code. Our wrapper script will need to accomplish the following steps:   Unpack the transferred runtime  Set the environment variables  Run our compiled matlab code   Fortunately, the Matlab compiler has pre-written most of this wrapper script for us!    Take a look at  run_matrix.sh . Which of the above steps do we need to add? Once you have an idea, move to the next step.    We'll need to add commands to unpack the runtime (which will have been transferred with the job). Add this line to the beginning of the  run_matrix.sh  file, after  #!/bin/bash  and the comments, but before  exe_name=$0  :   tar -xzf r2015b.tar.gz    Look at  readme.txt  to determine what arguments our wrapper script requires. Once you have an idea, move to the next step.    The name of the Matlab runtime directory is a required argument to the wrapper script  run_matrix.sh . We'll have to do a little extra work to find out the name of that directory. Run this command  tar -tf r2015b.tar.gz     The output of the previous command is a list of all the files in the tar.gz file. What is the name of the first folder of the path for each file? This is the name of the runtime directory, and the argument you should pass to  run_matrix.sh .",
            "title": "Wrapper Script"
        },
        {
            "location": "/materials/sw/part2-ex4-matlab/#submitting-the-job",
            "text": "Copy an existing submit file into your current directory. The submit file we used for   Exercise 1.2  example would be a good candidate, as that example also used a wrapper script.     Modify your submit file for this job.     Check your changes against the list below.    The  executable  for this job is going to be our wrapper script  run_matrix.sh .   executable = run_matrix.sh    You need to transfer the compiled binary  matrix , as well as the runtime  .tar.gz  file, using  transfer_input_files .   transfer_input_files = matrix, r2015b.tar.gz    The argument for the executable ( run_matrix.sh ) is \"v90\", as that is the name of the un-tarred runtime directory.   arguments = v90    We need to request plenty of disk space for the runtime.   request_disk = 2GB      Submit the job using  condor_submit .      After it completes, the job should have produced a file called  results.txt .",
            "title": "Submitting the Job"
        },
        {
            "location": "/materials/sw/part3-ex1-singularity/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: \\#008; } \n\n\n\nSoftware Exercise 3.1: Use Singularity from OSG Connect\n\u00b6\n\n\nBackground\n\u00b6\n\n\nContainers are another way to manage software installations. We don't have the time to go fully into the details of building and using containers, but can use pre-existing containers to run jobs. \n\n\nOne caveat for using containers: not all systems will support them. HTCondor has built-in features for using Docker and many Open Science Grid resources have Singularity installed, but they are not always available everywhere. \n\n\nSetup\n\u00b6\n\n\nMake sure you are logged into \nlogin05.osgconnect.net\n (the OSG Connect submit server for this workshop).  For this exercise we will be using Singularity containers that are hosted by OSG Connect, in a very similar way to the software modules. \n\n\nTo get an idea on what container images are available on the OSG, take a look at the directory path \n/cvmfs/singularity.opensciencegrid.org/opensciencegrid\n.  \n\n\nJob Submission\n\u00b6\n\n\nFor this job, we will use the OSG Connect Ubuntu \"Xenial\" image. Copy a submit file you used for a previous exercise on OSG Connect and add the following lines: \n\n\nrequirements = HAS_SINGULARITY == true\n+SingularityImage = \"/cvmfs/singularity.opensciencegrid.org/opensciencegrid/osgvo-ubuntu-xenial:latest\"\n\n\n\n\n\nIf you had other requirements in the submit file, remove them. These options will do two things: \n\n\n\n\nrequire that your job runs on servers that have Singularity installed and can access the OSG Connect repository of Singularity containers\n\n\ntells the job which Singularity container to use\n\n\n\n\nTo test and see if our job is really running in Ubuntu, use this script for the job's executable: \n\n\n#!/bin/bash\n\n\nhostname\nlsb_release -a\n\n\n\n\n\nSubmit the job and look at the output file.",
            "title": "Exercise 3.1"
        },
        {
            "location": "/materials/sw/part3-ex1-singularity/#software-exercise-31-use-singularity-from-osg-connect",
            "text": "",
            "title": "Software Exercise 3.1: Use Singularity from OSG Connect"
        },
        {
            "location": "/materials/sw/part3-ex1-singularity/#background",
            "text": "Containers are another way to manage software installations. We don't have the time to go fully into the details of building and using containers, but can use pre-existing containers to run jobs.   One caveat for using containers: not all systems will support them. HTCondor has built-in features for using Docker and many Open Science Grid resources have Singularity installed, but they are not always available everywhere.",
            "title": "Background"
        },
        {
            "location": "/materials/sw/part3-ex1-singularity/#setup",
            "text": "Make sure you are logged into  login05.osgconnect.net  (the OSG Connect submit server for this workshop).  For this exercise we will be using Singularity containers that are hosted by OSG Connect, in a very similar way to the software modules.   To get an idea on what container images are available on the OSG, take a look at the directory path  /cvmfs/singularity.opensciencegrid.org/opensciencegrid .",
            "title": "Setup"
        },
        {
            "location": "/materials/sw/part3-ex1-singularity/#job-submission",
            "text": "For this job, we will use the OSG Connect Ubuntu \"Xenial\" image. Copy a submit file you used for a previous exercise on OSG Connect and add the following lines:   requirements = HAS_SINGULARITY == true\n+SingularityImage = \"/cvmfs/singularity.opensciencegrid.org/opensciencegrid/osgvo-ubuntu-xenial:latest\"  If you had other requirements in the submit file, remove them. These options will do two things:    require that your job runs on servers that have Singularity installed and can access the OSG Connect repository of Singularity containers  tells the job which Singularity container to use   To test and see if our job is really running in Ubuntu, use this script for the job's executable:   #!/bin/bash \n\nhostname\nlsb_release -a  Submit the job and look at the output file.",
            "title": "Job Submission"
        },
        {
            "location": "/materials/sw/part4-ex1-arguments/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: #008; } \n\n\n\nSoftware Exercise 4.1: Passing Arguments Through the Wrapper Script\n\u00b6\n\n\nIn this exercise, you will change the wrapper script and submit file from a previous exercise to use arguments. It builds on \nExercise 2.2\n from earlier, so only do this exercise if you've already done Exercise 2.2.\n\n\nBackground\n\u00b6\n\n\nIn Exercise 2.2, the wrapper scripts had all files and options written out explicitly. However, imagine if you wanted to run the same job multiple times, or even just try out one or two different options or inputs. Instead of writing new wrapper scripts for each job, you can modify the script so that some of the values are set by \narguments\n. Using script arguments will allow you to use the same script for multiple jobs, by providing different inputs or parameters. These arguments are normally passed on the command line:\n\n\nBut in our world of job submission, the arguments will be listed in the submit file, in the arguments line.\n\n\nIdentifying Potential Arguments\n\u00b6\n\n\n\n\nFind the directory you used to submit Open BUGS jobs and open your \nrun_openbugs.sh\n wrapper script.\n\n\nWhat values might we want to input to the script via arguments? Hint: anything that we might want to change if we were to run the script many times.\n\n\n\n\nIn this example, some values we might want to change are the name of the input and output file. These will be the arguments for our script.\n\n\nModifying Files\n\u00b6\n\n\n\n\n\n\nNote the name of the input and output files and open the submit file. Add an arguments line if it doesn't already exist, and fill it with our two chosen arguments: the name of the input file and the name of the output file: \n\n\narguments = input.txt results.txt\n\n\n\n\n\n\n\n\n\nNow go back to the wrapper script. Each scripting language (bash, perl, python, R, etc.) will have its own particular syntax for capturing command line arguments. For bash (the language of our current wrapper script), the variables \n$1\n and \n$2\n represent  the first and second arguments, respectively. (If our script needed three arguments, we would use \n$3\n for the third one). Thus, in  the main command of the script, replace the file names with these variables: \n\n\nOpenBUGS < $1 > $2\n\n\n\n\n\n\n\n\n\nOnce these changes are made, submit your jobs with \ncondor_submit\n. Use \ncondor_q -nobatch\n to see what the job command looks like to HTCondor.",
            "title": "Exercise 4.1"
        },
        {
            "location": "/materials/sw/part4-ex1-arguments/#software-exercise-41-passing-arguments-through-the-wrapper-script",
            "text": "In this exercise, you will change the wrapper script and submit file from a previous exercise to use arguments. It builds on  Exercise 2.2  from earlier, so only do this exercise if you've already done Exercise 2.2.",
            "title": "Software Exercise 4.1: Passing Arguments Through the Wrapper Script"
        },
        {
            "location": "/materials/sw/part4-ex1-arguments/#background",
            "text": "In Exercise 2.2, the wrapper scripts had all files and options written out explicitly. However, imagine if you wanted to run the same job multiple times, or even just try out one or two different options or inputs. Instead of writing new wrapper scripts for each job, you can modify the script so that some of the values are set by  arguments . Using script arguments will allow you to use the same script for multiple jobs, by providing different inputs or parameters. These arguments are normally passed on the command line:  But in our world of job submission, the arguments will be listed in the submit file, in the arguments line.",
            "title": "Background"
        },
        {
            "location": "/materials/sw/part4-ex1-arguments/#identifying-potential-arguments",
            "text": "Find the directory you used to submit Open BUGS jobs and open your  run_openbugs.sh  wrapper script.  What values might we want to input to the script via arguments? Hint: anything that we might want to change if we were to run the script many times.   In this example, some values we might want to change are the name of the input and output file. These will be the arguments for our script.",
            "title": "Identifying Potential Arguments"
        },
        {
            "location": "/materials/sw/part4-ex1-arguments/#modifying-files",
            "text": "Note the name of the input and output files and open the submit file. Add an arguments line if it doesn't already exist, and fill it with our two chosen arguments: the name of the input file and the name of the output file:   arguments = input.txt results.txt    Now go back to the wrapper script. Each scripting language (bash, perl, python, R, etc.) will have its own particular syntax for capturing command line arguments. For bash (the language of our current wrapper script), the variables  $1  and  $2  represent  the first and second arguments, respectively. (If our script needed three arguments, we would use  $3  for the third one). Thus, in  the main command of the script, replace the file names with these variables:   OpenBUGS < $1 > $2    Once these changes are made, submit your jobs with  condor_submit . Use  condor_q -nobatch  to see what the job command looks like to HTCondor.",
            "title": "Modifying Files"
        },
        {
            "location": "/materials/sw/part4-ex2-python-extras/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: #008; } \n\n\n\nSoftware Exercise 4.2: More Python Job Features\n\u00b6\n\n\nIf you have time and  did the previous Python exercise (\nExercise 2.3\n), try one (or more) of these exercises. \n\n\nArguments\n\u00b6\n\n\nSimilar to what was shown in a \nprevious bonus exercise\n, \ncan you modify your submit file and shell script so that the number provided to the \nfib.py\n script is an argument from the submit file? \n\n\nMultiple Jobs\n\u00b6\n\n\nGiven this list of numbers:\n\n\n0\n25\n80\n110\n250\n3000\n\n\n\n\n\nCan you submit a job for each number? \n\n\nPackages\n\u00b6\n\n\nWe haven't talked about adding Python packages (like \nnumpy\n or \nmatplotlib\n) to the Python installation. Where would that go in the installation process? Try creating a Python installation that includes the \nnumpy\n package.",
            "title": "Exercise 4.2"
        },
        {
            "location": "/materials/sw/part4-ex2-python-extras/#software-exercise-42-more-python-job-features",
            "text": "If you have time and  did the previous Python exercise ( Exercise 2.3 ), try one (or more) of these exercises.",
            "title": "Software Exercise 4.2: More Python Job Features"
        },
        {
            "location": "/materials/sw/part4-ex2-python-extras/#arguments",
            "text": "Similar to what was shown in a  previous bonus exercise , \ncan you modify your submit file and shell script so that the number provided to the  fib.py  script is an argument from the submit file?",
            "title": "Arguments"
        },
        {
            "location": "/materials/sw/part4-ex2-python-extras/#multiple-jobs",
            "text": "Given this list of numbers:  0\n25\n80\n110\n250\n3000  Can you submit a job for each number?",
            "title": "Multiple Jobs"
        },
        {
            "location": "/materials/sw/part4-ex2-python-extras/#packages",
            "text": "We haven't talked about adding Python packages (like  numpy  or  matplotlib ) to the Python installation. Where would that go in the installation process? Try creating a Python installation that includes the  numpy  package.",
            "title": "Packages"
        },
        {
            "location": "/materials/sw/part4-ex3-docker/",
            "text": "pre em { font-style: normal; background-color: yellow; } pre strong { font-style: normal; font-weight: bold; color: #008; } \n\n\n\nSoftware Exercise 4.3: Using Docker\n\u00b6\n\n\nIn this exercise, you will run the same Python script as the other Python exercises, but using a Docker container.\n\n\nSetup\n\u00b6\n\n\nFor this exercise, you will need to be logged into \nlearn.chtc.wisc.edu\n, not \nlogin.osgconnect.net\n. If you haven't done one of the previous Python exercises, \nmake sure to get a copy of the script and recommended commands \nhere\n. \n\n\nSubmit File Changes\n\u00b6\n\n\n\n\nMake a copy of your submit file from the \nprevious Python exercise\n or build from an existing submit file. \n\n\n\n\nAdd the following lines to the submit file or modify existing lines to match the lines below: \n\n\nuniverse = docker\ndocker_image = python:3.7.0-stretch\n\n\n\n\n\nHere we are requesting HTCondor's Docker universe and using a pre-built python image that, by default, will be pulled from a public website of Docker images called DockerHub.  The requirements line will ensure that we run on computers whose operating system can support Docker.\n\n\n\n\n\n\nAdjust the executable and arguments lines. The executable can now be the Python script itself, with the appropriate arguments: \n\n\nexecutable = fib.py\narguments = 90\n\n\n\n\n\n\n\n\n\nFinally, we no longer need to transfer a Python tarball (whether source code or pre-built) or our Python script. You can remove both from the \ntransfer_input_files\n line of the submit file if it's already present. \n\n\n\n\n\n\nPython Script\n\u00b6\n\n\n\n\n\n\nOpen the Python script and add the following line at the top: \n\n\n#!/usr/bin/env python3\n\n\n\n\n\nThis will ensure that the script uses the version of Python that comes in the Docker container.\n\n\n\n\n\n\nOnce these steps are done, submit the job.",
            "title": "Exercise 4.3"
        },
        {
            "location": "/materials/sw/part4-ex3-docker/#software-exercise-43-using-docker",
            "text": "In this exercise, you will run the same Python script as the other Python exercises, but using a Docker container.",
            "title": "Software Exercise 4.3: Using Docker"
        },
        {
            "location": "/materials/sw/part4-ex3-docker/#setup",
            "text": "For this exercise, you will need to be logged into  learn.chtc.wisc.edu , not  login.osgconnect.net . If you haven't done one of the previous Python exercises, \nmake sure to get a copy of the script and recommended commands  here .",
            "title": "Setup"
        },
        {
            "location": "/materials/sw/part4-ex3-docker/#submit-file-changes",
            "text": "Make a copy of your submit file from the  previous Python exercise  or build from an existing submit file.    Add the following lines to the submit file or modify existing lines to match the lines below:   universe = docker\ndocker_image = python:3.7.0-stretch  Here we are requesting HTCondor's Docker universe and using a pre-built python image that, by default, will be pulled from a public website of Docker images called DockerHub.  The requirements line will ensure that we run on computers whose operating system can support Docker.    Adjust the executable and arguments lines. The executable can now be the Python script itself, with the appropriate arguments:   executable = fib.py\narguments = 90    Finally, we no longer need to transfer a Python tarball (whether source code or pre-built) or our Python script. You can remove both from the  transfer_input_files  line of the submit file if it's already present.",
            "title": "Submit File Changes"
        },
        {
            "location": "/materials/sw/part4-ex3-docker/#python-script",
            "text": "Open the Python script and add the following line at the top:   #!/usr/bin/env python3  This will ensure that the script uses the version of Python that comes in the Docker container.    Once these steps are done, submit the job.",
            "title": "Python Script"
        },
        {
            "location": "/materials/data/temp/",
            "text": "OSG-VSP Exercises Coming Soon!\n\u00b6\n\n\nThis is just a placeholder document for OSG Virtual School Pilot 2020 exercises,\nwhich will be posted soon.",
            "title": "Placeholder"
        },
        {
            "location": "/materials/data/temp/#osg-vsp-exercises-coming-soon",
            "text": "This is just a placeholder document for OSG Virtual School Pilot 2020 exercises,\nwhich will be posted soon.",
            "title": "OSG-VSP Exercises Coming Soon!"
        },
        {
            "location": "/staff/",
            "text": "OSGVSP20 \u2013 Staff\n\u00b6\n\n\n\nimg { margin: 5px 0; }\ntr { vertical-align: top; }\n\n\n\n\n\n  \n\n    \n\n      \n\n      \n\n        \nTim Cartwright\n\n        \n\n          Tim founded the OSG School in 2010 and has led it since.\n          When not involved in training, he mostly works for OSG in management,\n          where he helps the project as a whole in a variety of capacities.\n          Tim started working with OSG in 2005, originally focusing on software integration.\n        \n\n      \n\n    \n\n    \n\n      \n\n      \n\n        \nLauren Michael\n\n        \n\n          Lauren serves as co-Director of the OSG School program.\n          She leads Research Computing Facilitation teams for the OSG and at UW-Madison,\n          where she has worked since 2013,\n          and leverages research background in Biophysics and Life Sciences Communication.\n        \n\n      \n\n    \n\n    \n\n      \n\n      \n\n        \nBrian Lin\n\n        \n\n          Brian is the OSG Software Team manager\n          and is responsible for maintaining the software catalog used by OSG resource providers.\n          He has worked for the CHTC at the University of Wisconsin\u2013Madison since 2013.\n        \n\n      \n\n    \n\n    \n\n      \n\n      \n\n        \nChristina Koch\n\n        \n\n          Christina is a Research Computing Facilitator at the University of Wisconsin\u2013Madison,\n          where she helps researchers transition their big computational problems to large-scale computing resources.\n          She facilitates use of both local resources at UW\u2013Madison and access to the national Open Science Grid. \n        \n\n      \n\n    \n\n    \n\n      \n\n      \n\n        \nDerek Weitzel\n\n        \n\n          Derek is a research assistant professor at the University of Nebraska\u2013Lincoln.\n          He is a member of the OSG Technology and Operations teams\n          and has worked with the OSG since graduate school in 2009.\n          (Note: Derek is unavailable during Week 2.)\n        \n\n      \n\n    \n\n    \n\n      \n\n      \n\n        \nEmelie Fuchs\n\n        \n\n          Emelie is an HPC Applications Specialist and OSG Research Facilitator\n          at the University of Nebraska\u2013Lincoln Holland Computing Center.\n        \n\n      \n\n    \n\n    \n\n      \n\n      \n\n        \nIan Ross\n\n        \n\n          Ian works as a developer in the Center for High Throughput Computing,\n          coupling high-throughput workflows with systems to enable text data-mining\n          across millions of scientific documents.\n          He has worked in the group since 2014, after completing his Ph.D. in high energy particle physics.\n        \n\n      \n\n    \n\n    \n\n      \n\n      \n\n        \nJason Patton\n\n        \n\n          Jason is a Software Integration Scientist for the CHTC.\n          He assists researchers and system administrators to get their applications working with the HTCondor software.\n          He has worked for the CHTC at the University of Wisconsin\u2013Madison since 2016.\n        \n\n      \n\n    \n\n    \n\n      \n\n      \n\n        \nJess Vera\n\n        \n\n          Jess is a Research Computing Facilitator for the OSG and at the University of Wisconsin\u2013Madison,\n          where she has worked since 2019 and has extensive research experience in\n          bioinformatics, genomics, and transcriptomics.\n        \n\n      \n\n    \n\n    \n\n      \n\n      \n\n        \nJosh Karpel\n\n        \n\n          Josh is a Postdoctoral Researcher at the Morgridge Institute for Research,\n          focusing on high-throughput computing techniques.\n          Josh is experienced with running Python and Docker-based programs on HTCondor pools,\n          and his background is in computational quantum mechanics.",
            "title": "Staff"
        },
        {
            "location": "/staff/#osgvsp20-staff",
            "text": "img { margin: 5px 0; }\ntr { vertical-align: top; }  \n   \n     \n       \n       \n         Tim Cartwright \n         \n          Tim founded the OSG School in 2010 and has led it since.\n          When not involved in training, he mostly works for OSG in management,\n          where he helps the project as a whole in a variety of capacities.\n          Tim started working with OSG in 2005, originally focusing on software integration.\n         \n       \n     \n     \n       \n       \n         Lauren Michael \n         \n          Lauren serves as co-Director of the OSG School program.\n          She leads Research Computing Facilitation teams for the OSG and at UW-Madison,\n          where she has worked since 2013,\n          and leverages research background in Biophysics and Life Sciences Communication.\n         \n       \n     \n     \n       \n       \n         Brian Lin \n         \n          Brian is the OSG Software Team manager\n          and is responsible for maintaining the software catalog used by OSG resource providers.\n          He has worked for the CHTC at the University of Wisconsin\u2013Madison since 2013.\n         \n       \n     \n     \n       \n       \n         Christina Koch \n         \n          Christina is a Research Computing Facilitator at the University of Wisconsin\u2013Madison,\n          where she helps researchers transition their big computational problems to large-scale computing resources.\n          She facilitates use of both local resources at UW\u2013Madison and access to the national Open Science Grid. \n         \n       \n     \n     \n       \n       \n         Derek Weitzel \n         \n          Derek is a research assistant professor at the University of Nebraska\u2013Lincoln.\n          He is a member of the OSG Technology and Operations teams\n          and has worked with the OSG since graduate school in 2009.\n          (Note: Derek is unavailable during Week 2.)\n         \n       \n     \n     \n       \n       \n         Emelie Fuchs \n         \n          Emelie is an HPC Applications Specialist and OSG Research Facilitator\n          at the University of Nebraska\u2013Lincoln Holland Computing Center.\n         \n       \n     \n     \n       \n       \n         Ian Ross \n         \n          Ian works as a developer in the Center for High Throughput Computing,\n          coupling high-throughput workflows with systems to enable text data-mining\n          across millions of scientific documents.\n          He has worked in the group since 2014, after completing his Ph.D. in high energy particle physics.\n         \n       \n     \n     \n       \n       \n         Jason Patton \n         \n          Jason is a Software Integration Scientist for the CHTC.\n          He assists researchers and system administrators to get their applications working with the HTCondor software.\n          He has worked for the CHTC at the University of Wisconsin\u2013Madison since 2016.\n         \n       \n     \n     \n       \n       \n         Jess Vera \n         \n          Jess is a Research Computing Facilitator for the OSG and at the University of Wisconsin\u2013Madison,\n          where she has worked since 2019 and has extensive research experience in\n          bioinformatics, genomics, and transcriptomics.\n         \n       \n     \n     \n       \n       \n         Josh Karpel \n         \n          Josh is a Postdoctoral Researcher at the Morgridge Institute for Research,\n          focusing on high-throughput computing techniques.\n          Josh is experienced with running Python and Docker-based programs on HTCondor pools,\n          and his background is in computational quantum mechanics.",
            "title": "OSGVSP20 \u2013 Staff"
        }
    ]
}